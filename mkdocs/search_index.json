{
    "docs": [
        {
            "location": "/CompilerTools.AliasAnalysis/", 
            "text": "CompilerTools.AliasAnalysis", 
            "title": "CompilerTools.AliasAnalysis"
        }, 
        {
            "location": "/CompilerTools.AliasAnalysis/#compilertoolsaliasanalysis", 
            "text": "", 
            "title": "CompilerTools.AliasAnalysis"
        }, 
        {
            "location": "/CompilerTools.AstWalker/", 
            "text": "CompilerTools.AstWalker\n\n\nExported\n\n\n\n\n\n\nAstWalk(ast::ANY,  callback,  cbdata::ANY) \n\u00b6\n\n\nEntry point into the code to perform an AST walk.\nYou generally pass a lambda expression as the first argument.\nThe third argument is an object that is opaque to AstWalk but that is passed to every callback.\nYou can use this object to collect data about the AST as it is walked or to hold information on\nhow to change the AST as you are walking over it.\nThe second argument is a callback function.  For each AST node, AstWalk will invoke this callback.\nThe signature of the callback must be (Any, Any, Int64, Bool, Bool).  The arguments to the callback\nare as follows:\n    1) The current node of the AST being walked.\n    2) The callback data object that you originally passed as the first argument to AstWalk.\n    3) Specifies the index of the body's statement that is currently being processed.\n    4) True if the current AST node being walked is the root of a top-level statement, false if the AST node is a sub-tree of a top-level statement.\n    5) True if the AST node is being read, false if it is being written.\nThe callback should return an array of items.  It does this because in some cases it makes sense to return multiple things so\nall callbacks have to to keep the interface consistent.\n\n\nsource:\n\n\nCompilerTools/src/ast_walk.jl:188\n\n\nInternal\n\n\n\n\n\n\nfrom_assignment(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read) \n\u00b6\n\n\nAstWalk through an assignment expression.\nRecursively process the left and right hand sides with AstWalk.\n\n\nsource:\n\n\nCompilerTools/src/ast_walk.jl:128\n\n\n\n\n\n\nfrom_body(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read) \n\u00b6\n\n\nAstWalk through a function body.\n\n\nsource:\n\n\nCompilerTools/src/ast_walk.jl:81\n\n\n\n\n\n\nfrom_call(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read) \n\u00b6\n\n\nAstWalk through a call expression.\nRecursively process the name of the function and each of its arguments.\n\n\nsource:\n\n\nCompilerTools/src/ast_walk.jl:141\n\n\n\n\n\n\nfrom_expr(ast::ANY,  depth,  callback,  cbdata::ANY,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nThe main routine that switches on all the various AST node types.\nThe internal nodes of the AST are of type Expr with various different Expr.head field values such as :lambda, :body, :block, etc.\nThe leaf nodes of the AST all have different types.\nThere are some node types we don't currently recurse into.  Maybe this needs to be extended.\n\n\nsource:\n\n\nCompilerTools/src/ast_walk.jl:187\n\n\n\n\n\n\nfrom_exprs(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read) \n\u00b6\n\n\nAstWalk through an array of expressions.\n\n\nsource:\n\n\nCompilerTools/src/ast_walk.jl:104\n\n\n\n\n\n\nfrom_lambda(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read) \n\u00b6\n\n\nAstWalk through a lambda expression.\nWalk through each input parameters and the body of the lambda.\n\n\nsource:\n\n\nCompilerTools/src/ast_walk.jl:50\n\n\n\n\n\n\nuncompressed_ast(l::LambdaStaticData) \n\u00b6\n\n\nConvert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nsource:\n\n\nCompilerTools/src/ast_walk.jl:42", 
            "title": "CompilerTools.AstWalker"
        }, 
        {
            "location": "/CompilerTools.AstWalker/#compilertoolsastwalker", 
            "text": "", 
            "title": "CompilerTools.AstWalker"
        }, 
        {
            "location": "/CompilerTools.AstWalker/#exported", 
            "text": "AstWalk(ast::ANY,  callback,  cbdata::ANY)  \u00b6  Entry point into the code to perform an AST walk.\nYou generally pass a lambda expression as the first argument.\nThe third argument is an object that is opaque to AstWalk but that is passed to every callback.\nYou can use this object to collect data about the AST as it is walked or to hold information on\nhow to change the AST as you are walking over it.\nThe second argument is a callback function.  For each AST node, AstWalk will invoke this callback.\nThe signature of the callback must be (Any, Any, Int64, Bool, Bool).  The arguments to the callback\nare as follows:\n    1) The current node of the AST being walked.\n    2) The callback data object that you originally passed as the first argument to AstWalk.\n    3) Specifies the index of the body's statement that is currently being processed.\n    4) True if the current AST node being walked is the root of a top-level statement, false if the AST node is a sub-tree of a top-level statement.\n    5) True if the AST node is being read, false if it is being written.\nThe callback should return an array of items.  It does this because in some cases it makes sense to return multiple things so\nall callbacks have to to keep the interface consistent.  source:  CompilerTools/src/ast_walk.jl:188", 
            "title": "Exported"
        }, 
        {
            "location": "/CompilerTools.AstWalker/#internal", 
            "text": "from_assignment(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)  \u00b6  AstWalk through an assignment expression.\nRecursively process the left and right hand sides with AstWalk.  source:  CompilerTools/src/ast_walk.jl:128    from_body(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)  \u00b6  AstWalk through a function body.  source:  CompilerTools/src/ast_walk.jl:81    from_call(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)  \u00b6  AstWalk through a call expression.\nRecursively process the name of the function and each of its arguments.  source:  CompilerTools/src/ast_walk.jl:141    from_expr(ast::ANY,  depth,  callback,  cbdata::ANY,  top_level_number,  is_top_level,  read)  \u00b6  The main routine that switches on all the various AST node types.\nThe internal nodes of the AST are of type Expr with various different Expr.head field values such as :lambda, :body, :block, etc.\nThe leaf nodes of the AST all have different types.\nThere are some node types we don't currently recurse into.  Maybe this needs to be extended.  source:  CompilerTools/src/ast_walk.jl:187    from_exprs(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)  \u00b6  AstWalk through an array of expressions.  source:  CompilerTools/src/ast_walk.jl:104    from_lambda(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)  \u00b6  AstWalk through a lambda expression.\nWalk through each input parameters and the body of the lambda.  source:  CompilerTools/src/ast_walk.jl:50    uncompressed_ast(l::LambdaStaticData)  \u00b6  Convert a compressed LambdaStaticData format into the uncompressed AST format.  source:  CompilerTools/src/ast_walk.jl:42", 
            "title": "Internal"
        }, 
        {
            "location": "/CompilerTools.CFGs/", 
            "text": "CompilerTools.CFGs\n\n\nExported\n\n\n\n\n\n\nfind_bb_for_statement(top_number::Int64,  bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nFind the basic block that contains a given statement number.\nReturns the basic block label of the basic block that contains the given statement number or \"nothing\" if the statement number is not found.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:718\n\n\n\n\n\n\nfrom_exprs(ast::Array{Any, 1},  depth,  state,  callback,  cbdata) \n\u00b6\n\n\nProcess an array of expressions.\nWe know that the first array of expressions we will find is for the lambda body.\ntop_level_number starts out 0 and if we find it to be 0 then we know that we're processing the array of expr for the body\nand so we keep track of the index into body so that we can number the statements in the basic blocks by this top level number.\nRecursively process each element of the array of expressions.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:841\n\n\n\n\n\n\nshow(io::IO,  bb::CompilerTools.CFGs.BasicBlock) \n\u00b6\n\n\nOverload of Base.show to pretty-print a CFGS.BasicBlock object.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:124\n\n\n\n\n\n\nshow(io::IO,  bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nOverload of Base.show to pretty-print a CFG object.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:204\n\n\n\n\n\n\nshow(io::IO,  tls::CompilerTools.CFGs.TopLevelStatement) \n\u00b6\n\n\nOverload of Base.show to pretty-print a TopLevelStatement.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:63\n\n\nInternal\n\n\n\n\n\n\nTypedExpr(typ,  rest...) \n\u00b6\n\n\nCreates a typed Expr AST node.\nConvenence function that takes a type as first argument and the varargs thereafter.\nThe varargs are used to form an Expr AST node and the type parameter is used to fill in the \"typ\" field of the Expr.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:43\n\n\n\n\n\n\naddStatement(top_level,  state,  ast::ANY) \n\u00b6\n\n\nAdds a top-level statement just encountered during a partial walk of the AST.\nFirst argument indicates if this statement is a top-level statement.\nSecond argument is a object collecting information about the CFG as we go along.\nThird argument is some sub-tree of the AST.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:107\n\n\n\n\n\n\naddStatementToEndOfBlock(bl::CompilerTools.CFGs.CFG,  block,  stmt) \n\u00b6\n\n\nGiven a CFG \"bl\" and a basic \"block\", add statement \"stmt\" to the end of that block.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:622\n\n\n\n\n\n\nchangeEndingLabel(bb,  after::CompilerTools.CFGs.BasicBlock,  new_bb::CompilerTools.CFGs.BasicBlock) \n\u00b6\n\n\nBasicBlock bb currently is known to contain a jump to the BasicBlock after.\nThis function changes bb so that it no longer jumps to after but to \"new_bb\" instead.\nThe jump has to be in the last statement of the BasicBlock.\nAstWalk on the last statement of the BasicBlock is used with the update_label callback function.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:310\n\n\n\n\n\n\ncompute_dfn(basic_blocks) \n\u00b6\n\n\nComputes the depth first numbering of the basic block graph.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:757\n\n\n\n\n\n\ncompute_dfn_internal(basic_blocks,  cur_bb,  cur_dfn,  visited,  bbs_df_order) \n\u00b6\n\n\nThe recursive heart of depth first numbering.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:736\n\n\n\n\n\n\ncompute_dominators(bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nCompute the dominators of the CFG.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:1182\n\n\n\n\n\n\ncompute_inverse_dominators(bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nCompute the inverse dominators of the CFG.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:1246\n\n\n\n\n\n\nconnect(from,  to,  fallthrough) \n\u00b6\n\n\nConnect the \"from\" input argument basic block to the \"to\" input argument basic block.\nIf the third argument \"fallthrough\" is true then the \"to\" block is also set as the \"from\" basic block's fallthrough successor.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:153\n\n\n\n\n\n\nconnect_finish(state) \n\u00b6\n\n\nConnect the current basic block as a fallthrough to the final invisible basic block (-2).\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:775\n\n\n\n\n\n\ncreateFunctionBody(bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nCreate the array of statements that go in a :body Expr given a CFG \"bl\".\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:667\n\n\n\n\n\n\ndump_bb(bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nPrints a CFG \"bl\" with varying degrees of verbosity from debug level 2 up to 4.\nAdditionally, at debug level 4 and graphviz bbs.dot file is generated that can be used to visualize the basic block structure of the function.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:784\n\n\n\n\n\n\nfindReachable(reachable,  cur::Int64,  bbs::Dict{Int64, CompilerTools.CFGs.BasicBlock}) \n\u00b6\n\n\nProcess a basic block and add its successors to the set of reachable blocks\nif it isn't already there.  If it is freshly added then recurse to adds its successors.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:877\n\n\n\n\n\n\nfind_top_number(top_number::Int64,  bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nSearch for a statement with the given number in the CFG \"bl\".\nReturns the statement corresponding to the given number or \"nothing\" if the statement number is not found.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:700\n\n\n\n\n\n\nfrom_ast(ast) \n\u00b6\n\n\nThe main entry point to construct a control-flow graph.\nTypically you would pass in a :lambda Expr here.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:1004\n\n\n\n\n\n\nfrom_expr(ast,  callback,  cbdata) \n\u00b6\n\n\nAnother entry point to construct a control-flow graph but one that allows you to pass a callback and some opaque object\nso that non-standard node types can be processed.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:1013\n\n\n\n\n\n\nfrom_expr(ast::LambdaStaticData,  depth,  state,  top_level,  callback,  cbdata) \n\u00b6\n\n\nThe main routine that switches on all the various AST node types.\nThe internal nodes of the AST are of type Expr with various different Expr.head field values such as :lambda, :body, :block, etc.\nThe leaf nodes of the AST all have different types.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:1123\n\n\n\n\n\n\nfrom_goto(label,  state,  callback,  cbdata) \n\u00b6\n\n\nProcess a GotoNode for CFG construction.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:1052\n\n\n\n\n\n\nfrom_if(args,  depth,  state,  callback,  cbdata) \n\u00b6\n\n\nProcess a :gotoifnot Expr not for CFG construction.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:1082\n\n\n\n\n\n\nfrom_label(label,  state,  callback,  cbdata) \n\u00b6\n\n\nProcess LabelNode for CFG construction.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:1036\n\n\n\n\n\n\nfrom_lambda(ast::Array{Any, 1},  depth,  state,  callback,  cbdata) \n\u00b6\n\n\nTo help construct the CFG given a lambda, we recursively process the body of the lambda.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:820\n\n\n\n\n\n\nfrom_return(args,  depth,  state,  callback,  cbdata) \n\u00b6\n\n\nProcess a :return Expr for CFG construction.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:1069\n\n\n\n\n\n\ngetBbBodyOrder(bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nDetermine a valid and reasonable order of basic blocks in which to reconstruct a :body Expr.\nAlso useful for printing in a reasonable order.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:639\n\n\n\n\n\n\ngetDistinctStatementNum(bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nGet a possible new statement number by finding the maximum statement value in any BasicBlock in the given CFG and adding 1.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:407\n\n\n\n\n\n\ngetMaxBB(bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nReturns the maximum basic block label for the given CFG.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:217\n\n\n\n\n\n\ngetMaxStatementNum(bb::CompilerTools.CFGs.BasicBlock) \n\u00b6\n\n\nGet the maximum statement index for a given BasicBlock.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:394\n\n\n\n\n\n\ngetMinBB(bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nReturns the minimum basic block label for the given CFG.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:225\n\n\n\n\n\n\ninsertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64) \n\u00b6\n\n\nGiven a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,\ninsert a new basic block into the CFG before block \"after\".\n\nReturns a tuple of the new basic block created and if needed a GotoNode AST node to be inserted at the end of the new\nbasic block so that it will jump to the \"after\" basic block.  The user of this function is expected to insert\nat the end of the new basic block once they are done inserting their other code.\nIf \"after\" is the head of a loop, you can stop the basic block containing the loop's back edge from being added to \nthe new basic block by setting excludeBackEdge to true and setting back_edge to the loop's basic block containing\nthe back edge.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:332\n\n\n\n\n\n\ninsertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64,  excludeBackEdge::Bool) \n\u00b6\n\n\nGiven a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,\ninsert a new basic block into the CFG before block \"after\".\n\nReturns a tuple of the new basic block created and if needed a GotoNode AST node to be inserted at the end of the new\nbasic block so that it will jump to the \"after\" basic block.  The user of this function is expected to insert\nat the end of the new basic block once they are done inserting their other code.\nIf \"after\" is the head of a loop, you can stop the basic block containing the loop's back edge from being added to \nthe new basic block by setting excludeBackEdge to true and setting back_edge to the loop's basic block containing\nthe back edge.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:332\n\n\n\n\n\n\ninsertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64,  excludeBackEdge::Bool,  back_edge) \n\u00b6\n\n\nGiven a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,\ninsert a new basic block into the CFG before block \"after\".\n\nReturns a tuple of the new basic block created and if needed a GotoNode AST node to be inserted at the end of the new\nbasic block so that it will jump to the \"after\" basic block.  The user of this function is expected to insert\nat the end of the new basic block once they are done inserting their other code.\nIf \"after\" is the head of a loop, you can stop the basic block containing the loop's back edge from being added to \nthe new basic block by setting excludeBackEdge to true and setting back_edge to the loop's basic block containing\nthe back edge.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:332\n\n\n\n\n\n\ninsertBetween(bl::CompilerTools.CFGs.CFG,  before::Int64,  after::Int64) \n\u00b6\n\n\nInsert a new basic block into the CFG \"bl\" between the basic blocks whose labels are \"before\" and \"after\".\nReturns a tuple of the new basic block created and if needed a GotoNode AST node to be inserted at the end of the new\nbasic block so that it will jump to the \"after\" basic block.  The user of this function is expected to insert\nat the end of the new basic block once they are done inserting their other code.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:515\n\n\n\n\n\n\ninsertStatementAfter(bl::CompilerTools.CFGs.CFG,  block,  stmt_idx,  new_stmt) \n\u00b6\n\n\nFor a given CFG \"bl\" and a \"block\" in that CFG, add a new statement \"new_stmt\" to the basic block\nafter statement index \"stmt_idx\".\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:580\n\n\n\n\n\n\ninsertStatementBefore(bl::CompilerTools.CFGs.CFG,  block,  stmt_idx,  new_stmt) \n\u00b6\n\n\nFor a given CFG \"bl\" and a \"block\" in that CFG, add a new statement \"new_stmt\" to the basic block\nbefore statement index \"stmt_idx\".\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:588\n\n\n\n\n\n\ninsertat!(a,  value,  idx) \n\u00b6\n\n\nInsert into an array \"a\" with a given \"value\" at the specified index \"idx\".\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:571\n\n\n\n\n\n\nnot_handled(a,  b) \n\u00b6\n\n\nA default callback that handles no extra AST node types.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:995\n\n\n\n\n\n\nremoveUselessBlocks(bbs::Dict{Int64, CompilerTools.CFGs.BasicBlock}) \n\u00b6\n\n\nThis function simplifies the dict of basic blocks \"bbs\".\nOne such simplification that is necessary for depth first numbering not to fail is the removal of dead blocks.\nOther simplifications can be seen commented out below and while they may make the graph nicer to look at they\ndon't really add anything in terms of functionality.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:896\n\n\n\n\n\n\nreplaceSucc(cur_bb::CompilerTools.CFGs.BasicBlock,  orig_succ::CompilerTools.CFGs.BasicBlock,  new_succ::CompilerTools.CFGs.BasicBlock) \n\u00b6\n\n\nFor a given basic block \"cur_bb\", replace one of its successors \"orig_succ\" with a different successor \"new_succ\".\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:858\n\n\n\n\n\n\nuncompressed_ast(l::LambdaStaticData) \n\u00b6\n\n\nConvert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:814\n\n\n\n\n\n\nupdate_label(x::Expr,  state::CompilerTools.CFGs.UpdateLabelState,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAn AstWalk callback that pattern matches GotoNode's and :gotoifnot Expr nodes and determines if the\nlabel specified in this nodes is equal to the \"old_label\" in the UpdateLabelState and if so replaces\nthe \"old_label\" with \"new_label\" and sets the \"changed\" flag to true to indicate that update_label\nwas successful.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:255\n\n\n\n\n\n\nwrapInConditional(bl::CompilerTools.CFGs.CFG,  cond_gotoifnot::Expr,  first::Int64,  merge::Int64) \n\u00b6\n\n\nModifies the CFG to create a conditional (i.e., if statement) that wraps a certain region of the CFG whose entry block is\n\"first\" and whose last block is \"last\".\nTakes a parameters:\n1) bl - the CFG to modify\n2) cond_gotoifnot - a :gotoifnot Expr whose label is equal to \"first\"\n3) first - the existing starting block of the code to be included in the conditional\n4) merge - the existing block to be executed after the conditional\nTo be eligible for wrapping, first and merge must be in the same scope of source code.\nThis restriction is validated by confirming that \"first\" dominates \"merge\" and that \"merge\" inverse dominates \"first\".\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:436\n\n\n\n\n\n\nwrapInConditional(bl::CompilerTools.CFGs.CFG,  cond_gotoifnot::Expr,  first::Int64,  merge::Int64,  back_edge::Union{CompilerTools.CFGs.BasicBlock, Void}) \n\u00b6\n\n\nModifies the CFG to create a conditional (i.e., if statement) that wraps a certain region of the CFG whose entry block is\n\"first\" and whose last block is \"last\".\nTakes a parameters:\n1) bl - the CFG to modify\n2) cond_gotoifnot - a :gotoifnot Expr whose label is equal to \"first\"\n3) first - the existing starting block of the code to be included in the conditional\n4) merge - the existing block to be executed after the conditional\nTo be eligible for wrapping, first and merge must be in the same scope of source code.\nThis restriction is validated by confirming that \"first\" dominates \"merge\" and that \"merge\" inverse dominates \"first\".\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:436\n\n\n\n\n\n\nCompilerTools.CFGs.BasicBlock \n\u00b6\n\n\nData structure to hold information about one basic block in the control-flow graph.\nThis structure contains the following fields:\n1) label - an Int.  If positive, this basic block corresponds to a basic block declared in the AST through a label node.\n                    The special label value -1 corresponds to the starting basic blocks.  The special value -2\n                    corresponds to the final basic block (to which everything must flow).  Negative values correspond to\n                    implicit basic blocks following gotoifnot nodes.  There nodes may goto some (positive) label but if\n                    that branch is not taken they fall-through into an unlabelled basic (in the AST at least) but we\n                    give such blocks negative labels.\n2) preds - a set of basic blocks from which control may reach the current basic block\n3) succs - a set of basic blocks to which control may flow from the current basic block\n4) fallthrough_succ - if not \"nothing\", this indicates which of the basic block successors is reached via falling through from\n                    the current basic block rather than a jump (goto or gotoifnot)\n5) depth_first_number - a depth first numbering of the basic block graph is performed and this basic block's number is stored here\n6) statements - an array of the statements in this basic block.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:100\n\n\n\n\n\n\nCompilerTools.CFGs.CFG \n\u00b6\n\n\nThe main data structure to hold information about the control flow graph.\nThe basic_blocks field is a dictionary from basic block label to BasicBlock object.\nThe depth_first_numbering is an array of length the number of basic blocks.\n\n   Entry N in this array is the label of the basic block with depth-first numbering N.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:195\n\n\n\n\n\n\nCompilerTools.CFGs.TopLevelStatement \n\u00b6\n\n\nData structure to hold the index (relative to the beginning of the body of the function) of a top-level statement\nand the top-level statement itself.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:54\n\n\n\n\n\n\nCompilerTools.CFGs.UpdateLabelState \n\u00b6\n\n\nThe opaque callback data type for the update_label callback.\nIt holds the old_label that should be changed to the new_label.\nIt also holds a \"changed\" field that starts as false and gets set to true when the callback actually\nfinds the old label and replaces it with the new one.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:239\n\n\n\n\n\n\nCompilerTools.CFGs.expr_state \n\u00b6\n\n\nCollects information about the CFG as it is being constructed.\nContains a dictionary of the currently known basic blocks that maps the label to a BasicBlock object.\ncur_bb is the currently active BasicBlock to which the next statement encountered should be added.\nnext_if contains the next negative label number to be used for the next needed implicit basic block label.\ntop_level_number is the last top-level statement added.\n\n\nsource:\n\n\nCompilerTools/src/CFGs.jl:173", 
            "title": "CompilerTools.CFGs"
        }, 
        {
            "location": "/CompilerTools.CFGs/#compilertoolscfgs", 
            "text": "", 
            "title": "CompilerTools.CFGs"
        }, 
        {
            "location": "/CompilerTools.CFGs/#exported", 
            "text": "find_bb_for_statement(top_number::Int64,  bl::CompilerTools.CFGs.CFG)  \u00b6  Find the basic block that contains a given statement number.\nReturns the basic block label of the basic block that contains the given statement number or \"nothing\" if the statement number is not found.  source:  CompilerTools/src/CFGs.jl:718    from_exprs(ast::Array{Any, 1},  depth,  state,  callback,  cbdata)  \u00b6  Process an array of expressions.\nWe know that the first array of expressions we will find is for the lambda body.\ntop_level_number starts out 0 and if we find it to be 0 then we know that we're processing the array of expr for the body\nand so we keep track of the index into body so that we can number the statements in the basic blocks by this top level number.\nRecursively process each element of the array of expressions.  source:  CompilerTools/src/CFGs.jl:841    show(io::IO,  bb::CompilerTools.CFGs.BasicBlock)  \u00b6  Overload of Base.show to pretty-print a CFGS.BasicBlock object.  source:  CompilerTools/src/CFGs.jl:124    show(io::IO,  bl::CompilerTools.CFGs.CFG)  \u00b6  Overload of Base.show to pretty-print a CFG object.  source:  CompilerTools/src/CFGs.jl:204    show(io::IO,  tls::CompilerTools.CFGs.TopLevelStatement)  \u00b6  Overload of Base.show to pretty-print a TopLevelStatement.  source:  CompilerTools/src/CFGs.jl:63", 
            "title": "Exported"
        }, 
        {
            "location": "/CompilerTools.CFGs/#internal", 
            "text": "TypedExpr(typ,  rest...)  \u00b6  Creates a typed Expr AST node.\nConvenence function that takes a type as first argument and the varargs thereafter.\nThe varargs are used to form an Expr AST node and the type parameter is used to fill in the \"typ\" field of the Expr.  source:  CompilerTools/src/CFGs.jl:43    addStatement(top_level,  state,  ast::ANY)  \u00b6  Adds a top-level statement just encountered during a partial walk of the AST.\nFirst argument indicates if this statement is a top-level statement.\nSecond argument is a object collecting information about the CFG as we go along.\nThird argument is some sub-tree of the AST.  source:  CompilerTools/src/CFGs.jl:107    addStatementToEndOfBlock(bl::CompilerTools.CFGs.CFG,  block,  stmt)  \u00b6  Given a CFG \"bl\" and a basic \"block\", add statement \"stmt\" to the end of that block.  source:  CompilerTools/src/CFGs.jl:622    changeEndingLabel(bb,  after::CompilerTools.CFGs.BasicBlock,  new_bb::CompilerTools.CFGs.BasicBlock)  \u00b6  BasicBlock bb currently is known to contain a jump to the BasicBlock after.\nThis function changes bb so that it no longer jumps to after but to \"new_bb\" instead.\nThe jump has to be in the last statement of the BasicBlock.\nAstWalk on the last statement of the BasicBlock is used with the update_label callback function.  source:  CompilerTools/src/CFGs.jl:310    compute_dfn(basic_blocks)  \u00b6  Computes the depth first numbering of the basic block graph.  source:  CompilerTools/src/CFGs.jl:757    compute_dfn_internal(basic_blocks,  cur_bb,  cur_dfn,  visited,  bbs_df_order)  \u00b6  The recursive heart of depth first numbering.  source:  CompilerTools/src/CFGs.jl:736    compute_dominators(bl::CompilerTools.CFGs.CFG)  \u00b6  Compute the dominators of the CFG.  source:  CompilerTools/src/CFGs.jl:1182    compute_inverse_dominators(bl::CompilerTools.CFGs.CFG)  \u00b6  Compute the inverse dominators of the CFG.  source:  CompilerTools/src/CFGs.jl:1246    connect(from,  to,  fallthrough)  \u00b6  Connect the \"from\" input argument basic block to the \"to\" input argument basic block.\nIf the third argument \"fallthrough\" is true then the \"to\" block is also set as the \"from\" basic block's fallthrough successor.  source:  CompilerTools/src/CFGs.jl:153    connect_finish(state)  \u00b6  Connect the current basic block as a fallthrough to the final invisible basic block (-2).  source:  CompilerTools/src/CFGs.jl:775    createFunctionBody(bl::CompilerTools.CFGs.CFG)  \u00b6  Create the array of statements that go in a :body Expr given a CFG \"bl\".  source:  CompilerTools/src/CFGs.jl:667    dump_bb(bl::CompilerTools.CFGs.CFG)  \u00b6  Prints a CFG \"bl\" with varying degrees of verbosity from debug level 2 up to 4.\nAdditionally, at debug level 4 and graphviz bbs.dot file is generated that can be used to visualize the basic block structure of the function.  source:  CompilerTools/src/CFGs.jl:784    findReachable(reachable,  cur::Int64,  bbs::Dict{Int64, CompilerTools.CFGs.BasicBlock})  \u00b6  Process a basic block and add its successors to the set of reachable blocks\nif it isn't already there.  If it is freshly added then recurse to adds its successors.  source:  CompilerTools/src/CFGs.jl:877    find_top_number(top_number::Int64,  bl::CompilerTools.CFGs.CFG)  \u00b6  Search for a statement with the given number in the CFG \"bl\".\nReturns the statement corresponding to the given number or \"nothing\" if the statement number is not found.  source:  CompilerTools/src/CFGs.jl:700    from_ast(ast)  \u00b6  The main entry point to construct a control-flow graph.\nTypically you would pass in a :lambda Expr here.  source:  CompilerTools/src/CFGs.jl:1004    from_expr(ast,  callback,  cbdata)  \u00b6  Another entry point to construct a control-flow graph but one that allows you to pass a callback and some opaque object\nso that non-standard node types can be processed.  source:  CompilerTools/src/CFGs.jl:1013    from_expr(ast::LambdaStaticData,  depth,  state,  top_level,  callback,  cbdata)  \u00b6  The main routine that switches on all the various AST node types.\nThe internal nodes of the AST are of type Expr with various different Expr.head field values such as :lambda, :body, :block, etc.\nThe leaf nodes of the AST all have different types.  source:  CompilerTools/src/CFGs.jl:1123    from_goto(label,  state,  callback,  cbdata)  \u00b6  Process a GotoNode for CFG construction.  source:  CompilerTools/src/CFGs.jl:1052    from_if(args,  depth,  state,  callback,  cbdata)  \u00b6  Process a :gotoifnot Expr not for CFG construction.  source:  CompilerTools/src/CFGs.jl:1082    from_label(label,  state,  callback,  cbdata)  \u00b6  Process LabelNode for CFG construction.  source:  CompilerTools/src/CFGs.jl:1036    from_lambda(ast::Array{Any, 1},  depth,  state,  callback,  cbdata)  \u00b6  To help construct the CFG given a lambda, we recursively process the body of the lambda.  source:  CompilerTools/src/CFGs.jl:820    from_return(args,  depth,  state,  callback,  cbdata)  \u00b6  Process a :return Expr for CFG construction.  source:  CompilerTools/src/CFGs.jl:1069    getBbBodyOrder(bl::CompilerTools.CFGs.CFG)  \u00b6  Determine a valid and reasonable order of basic blocks in which to reconstruct a :body Expr.\nAlso useful for printing in a reasonable order.  source:  CompilerTools/src/CFGs.jl:639    getDistinctStatementNum(bl::CompilerTools.CFGs.CFG)  \u00b6  Get a possible new statement number by finding the maximum statement value in any BasicBlock in the given CFG and adding 1.  source:  CompilerTools/src/CFGs.jl:407    getMaxBB(bl::CompilerTools.CFGs.CFG)  \u00b6  Returns the maximum basic block label for the given CFG.  source:  CompilerTools/src/CFGs.jl:217    getMaxStatementNum(bb::CompilerTools.CFGs.BasicBlock)  \u00b6  Get the maximum statement index for a given BasicBlock.  source:  CompilerTools/src/CFGs.jl:394    getMinBB(bl::CompilerTools.CFGs.CFG)  \u00b6  Returns the minimum basic block label for the given CFG.  source:  CompilerTools/src/CFGs.jl:225    insertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64)  \u00b6  Given a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,\ninsert a new basic block into the CFG before block \"after\". \nReturns a tuple of the new basic block created and if needed a GotoNode AST node to be inserted at the end of the new\nbasic block so that it will jump to the \"after\" basic block.  The user of this function is expected to insert\nat the end of the new basic block once they are done inserting their other code.\nIf \"after\" is the head of a loop, you can stop the basic block containing the loop's back edge from being added to \nthe new basic block by setting excludeBackEdge to true and setting back_edge to the loop's basic block containing\nthe back edge.  source:  CompilerTools/src/CFGs.jl:332    insertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64,  excludeBackEdge::Bool)  \u00b6  Given a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,\ninsert a new basic block into the CFG before block \"after\". \nReturns a tuple of the new basic block created and if needed a GotoNode AST node to be inserted at the end of the new\nbasic block so that it will jump to the \"after\" basic block.  The user of this function is expected to insert\nat the end of the new basic block once they are done inserting their other code.\nIf \"after\" is the head of a loop, you can stop the basic block containing the loop's back edge from being added to \nthe new basic block by setting excludeBackEdge to true and setting back_edge to the loop's basic block containing\nthe back edge.  source:  CompilerTools/src/CFGs.jl:332    insertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64,  excludeBackEdge::Bool,  back_edge)  \u00b6  Given a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,\ninsert a new basic block into the CFG before block \"after\". \nReturns a tuple of the new basic block created and if needed a GotoNode AST node to be inserted at the end of the new\nbasic block so that it will jump to the \"after\" basic block.  The user of this function is expected to insert\nat the end of the new basic block once they are done inserting their other code.\nIf \"after\" is the head of a loop, you can stop the basic block containing the loop's back edge from being added to \nthe new basic block by setting excludeBackEdge to true and setting back_edge to the loop's basic block containing\nthe back edge.  source:  CompilerTools/src/CFGs.jl:332    insertBetween(bl::CompilerTools.CFGs.CFG,  before::Int64,  after::Int64)  \u00b6  Insert a new basic block into the CFG \"bl\" between the basic blocks whose labels are \"before\" and \"after\".\nReturns a tuple of the new basic block created and if needed a GotoNode AST node to be inserted at the end of the new\nbasic block so that it will jump to the \"after\" basic block.  The user of this function is expected to insert\nat the end of the new basic block once they are done inserting their other code.  source:  CompilerTools/src/CFGs.jl:515    insertStatementAfter(bl::CompilerTools.CFGs.CFG,  block,  stmt_idx,  new_stmt)  \u00b6  For a given CFG \"bl\" and a \"block\" in that CFG, add a new statement \"new_stmt\" to the basic block\nafter statement index \"stmt_idx\".  source:  CompilerTools/src/CFGs.jl:580    insertStatementBefore(bl::CompilerTools.CFGs.CFG,  block,  stmt_idx,  new_stmt)  \u00b6  For a given CFG \"bl\" and a \"block\" in that CFG, add a new statement \"new_stmt\" to the basic block\nbefore statement index \"stmt_idx\".  source:  CompilerTools/src/CFGs.jl:588    insertat!(a,  value,  idx)  \u00b6  Insert into an array \"a\" with a given \"value\" at the specified index \"idx\".  source:  CompilerTools/src/CFGs.jl:571    not_handled(a,  b)  \u00b6  A default callback that handles no extra AST node types.  source:  CompilerTools/src/CFGs.jl:995    removeUselessBlocks(bbs::Dict{Int64, CompilerTools.CFGs.BasicBlock})  \u00b6  This function simplifies the dict of basic blocks \"bbs\".\nOne such simplification that is necessary for depth first numbering not to fail is the removal of dead blocks.\nOther simplifications can be seen commented out below and while they may make the graph nicer to look at they\ndon't really add anything in terms of functionality.  source:  CompilerTools/src/CFGs.jl:896    replaceSucc(cur_bb::CompilerTools.CFGs.BasicBlock,  orig_succ::CompilerTools.CFGs.BasicBlock,  new_succ::CompilerTools.CFGs.BasicBlock)  \u00b6  For a given basic block \"cur_bb\", replace one of its successors \"orig_succ\" with a different successor \"new_succ\".  source:  CompilerTools/src/CFGs.jl:858    uncompressed_ast(l::LambdaStaticData)  \u00b6  Convert a compressed LambdaStaticData format into the uncompressed AST format.  source:  CompilerTools/src/CFGs.jl:814    update_label(x::Expr,  state::CompilerTools.CFGs.UpdateLabelState,  top_level_number,  is_top_level,  read)  \u00b6  An AstWalk callback that pattern matches GotoNode's and :gotoifnot Expr nodes and determines if the\nlabel specified in this nodes is equal to the \"old_label\" in the UpdateLabelState and if so replaces\nthe \"old_label\" with \"new_label\" and sets the \"changed\" flag to true to indicate that update_label\nwas successful.  source:  CompilerTools/src/CFGs.jl:255    wrapInConditional(bl::CompilerTools.CFGs.CFG,  cond_gotoifnot::Expr,  first::Int64,  merge::Int64)  \u00b6  Modifies the CFG to create a conditional (i.e., if statement) that wraps a certain region of the CFG whose entry block is\n\"first\" and whose last block is \"last\".\nTakes a parameters:\n1) bl - the CFG to modify\n2) cond_gotoifnot - a :gotoifnot Expr whose label is equal to \"first\"\n3) first - the existing starting block of the code to be included in the conditional\n4) merge - the existing block to be executed after the conditional\nTo be eligible for wrapping, first and merge must be in the same scope of source code.\nThis restriction is validated by confirming that \"first\" dominates \"merge\" and that \"merge\" inverse dominates \"first\".  source:  CompilerTools/src/CFGs.jl:436    wrapInConditional(bl::CompilerTools.CFGs.CFG,  cond_gotoifnot::Expr,  first::Int64,  merge::Int64,  back_edge::Union{CompilerTools.CFGs.BasicBlock, Void})  \u00b6  Modifies the CFG to create a conditional (i.e., if statement) that wraps a certain region of the CFG whose entry block is\n\"first\" and whose last block is \"last\".\nTakes a parameters:\n1) bl - the CFG to modify\n2) cond_gotoifnot - a :gotoifnot Expr whose label is equal to \"first\"\n3) first - the existing starting block of the code to be included in the conditional\n4) merge - the existing block to be executed after the conditional\nTo be eligible for wrapping, first and merge must be in the same scope of source code.\nThis restriction is validated by confirming that \"first\" dominates \"merge\" and that \"merge\" inverse dominates \"first\".  source:  CompilerTools/src/CFGs.jl:436    CompilerTools.CFGs.BasicBlock  \u00b6  Data structure to hold information about one basic block in the control-flow graph.\nThis structure contains the following fields:\n1) label - an Int.  If positive, this basic block corresponds to a basic block declared in the AST through a label node.\n                    The special label value -1 corresponds to the starting basic blocks.  The special value -2\n                    corresponds to the final basic block (to which everything must flow).  Negative values correspond to\n                    implicit basic blocks following gotoifnot nodes.  There nodes may goto some (positive) label but if\n                    that branch is not taken they fall-through into an unlabelled basic (in the AST at least) but we\n                    give such blocks negative labels.\n2) preds - a set of basic blocks from which control may reach the current basic block\n3) succs - a set of basic blocks to which control may flow from the current basic block\n4) fallthrough_succ - if not \"nothing\", this indicates which of the basic block successors is reached via falling through from\n                    the current basic block rather than a jump (goto or gotoifnot)\n5) depth_first_number - a depth first numbering of the basic block graph is performed and this basic block's number is stored here\n6) statements - an array of the statements in this basic block.  source:  CompilerTools/src/CFGs.jl:100    CompilerTools.CFGs.CFG  \u00b6  The main data structure to hold information about the control flow graph.\nThe basic_blocks field is a dictionary from basic block label to BasicBlock object.\nThe depth_first_numbering is an array of length the number of basic blocks. \n   Entry N in this array is the label of the basic block with depth-first numbering N.  source:  CompilerTools/src/CFGs.jl:195    CompilerTools.CFGs.TopLevelStatement  \u00b6  Data structure to hold the index (relative to the beginning of the body of the function) of a top-level statement\nand the top-level statement itself.  source:  CompilerTools/src/CFGs.jl:54    CompilerTools.CFGs.UpdateLabelState  \u00b6  The opaque callback data type for the update_label callback.\nIt holds the old_label that should be changed to the new_label.\nIt also holds a \"changed\" field that starts as false and gets set to true when the callback actually\nfinds the old label and replaces it with the new one.  source:  CompilerTools/src/CFGs.jl:239    CompilerTools.CFGs.expr_state  \u00b6  Collects information about the CFG as it is being constructed.\nContains a dictionary of the currently known basic blocks that maps the label to a BasicBlock object.\ncur_bb is the currently active BasicBlock to which the next statement encountered should be added.\nnext_if contains the next negative label number to be used for the next needed implicit basic block label.\ntop_level_number is the last top-level statement added.  source:  CompilerTools/src/CFGs.jl:173", 
            "title": "Internal"
        }, 
        {
            "location": "/CompilerTools.DebugMsg/", 
            "text": "CompilerTools.DebugMsg\n\n\nExported\n\n\n\n\n\n\ninit() \n\u00b6\n\n\nA module using DebugMsg must call DebugMsg.init(), which expands to several local definitions\nthat provide three functions: set_debug_level, dprint, dprintln.\n\n\nsource:\n\n\nCompilerTools/src/debug.jl:40\n\n\nInternal\n\n\n\n\n\n\nPROSPECT_DEV_MODE \n\u00b6\n\n\nWhen this module is first loaded, we check if PROSPECT_DEV_MODE is set in environment.\nIf it is not, then all debug messages will be surpressed.\n\n\nsource:\n\n\nCompilerTools/src/debug.jl:34", 
            "title": "CompilerTools.DebugMsg"
        }, 
        {
            "location": "/CompilerTools.DebugMsg/#compilertoolsdebugmsg", 
            "text": "", 
            "title": "CompilerTools.DebugMsg"
        }, 
        {
            "location": "/CompilerTools.DebugMsg/#exported", 
            "text": "init()  \u00b6  A module using DebugMsg must call DebugMsg.init(), which expands to several local definitions\nthat provide three functions: set_debug_level, dprint, dprintln.  source:  CompilerTools/src/debug.jl:40", 
            "title": "Exported"
        }, 
        {
            "location": "/CompilerTools.DebugMsg/#internal", 
            "text": "PROSPECT_DEV_MODE  \u00b6  When this module is first loaded, we check if PROSPECT_DEV_MODE is set in environment.\nIf it is not, then all debug messages will be surpressed.  source:  CompilerTools/src/debug.jl:34", 
            "title": "Internal"
        }, 
        {
            "location": "/CompilerTools.LambdaHandling/", 
            "text": "CompilerTools.LambdaHandling\n\n\nExported\n\n\n\n\n\n\naddEscapingVariable(s::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdds a new escaping variable with the given Symbol \"s\", type \"typ\", descriptor \"desc\" in LambdaInfo \"li\".\nReturns true if the variable already existed and its type and descriptor were updated, false otherwise.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:365\n\n\n\n\n\n\naddEscapingVariable(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdds a new escaping variable from a VarDef in parameter \"vd\" into LambdaInfo \"li\".\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:384\n\n\n\n\n\n\naddGenSym(typ,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdd a new GenSym to the LambdaInfo in \"li\" with the given type in \"typ\".\nReturns the new GenSym.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:393\n\n\n\n\n\n\naddLocalVariable(s::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdds a new local variable with the given Symbol \"s\", type \"typ\", descriptor \"desc\" in LambdaInfo \"li\".\nReturns true if the variable already existed and its type and descriptor were updated, false otherwise.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:345\n\n\n\n\n\n\naddLocalVariable(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdds a local variable from a VarDef to the given LambdaInfo.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:323\n\n\n\n\n\n\ngetBody(lambda::Expr) \n\u00b6\n\n\nReturns the body expression part of a lambda expression.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:705\n\n\n\n\n\n\ngetDesc(x::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nReturns the descriptor for a local variable or input parameter \"x\" from LambdaInfo in \"li\".\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:265\n\n\n\n\n\n\ngetRefParams(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nReturns an array of Symbols corresponding to those parameters to the method that are going to be passed by reference.\nIn short, isbits() types are passed by value and !isbits() types are passed by reference.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:715\n\n\n\n\n\n\ngetReturnType(li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nReturns the type of the lambda as stored in LambdaInfo \"li\" and as extracted during lambdaExprToLambdaInfo.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:626\n\n\n\n\n\n\ngetType(x::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nReturns the type of a Symbol or GenSym in \"x\" from LambdaInfo in \"li\".\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:235\n\n\n\n\n\n\ngetVarDef(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nReturns the VarDef for a Symbol in LambdaInfo in \"li\"\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:272\n\n\n\n\n\n\nisEscapingVariable(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nReturns true if the Symbol in \"s\" is an escaping variable in LambdaInfo in \"li\".\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:300\n\n\n\n\n\n\nisInputParameter(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nReturns true if the Symbol in \"s\" is an input parameter in LambdaInfo in \"li\".\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:279\n\n\n\n\n\n\nisLocalGenSym(s::GenSym,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nReturns true if the GenSym in \"s\" is a GenSym in LambdaInfo in \"li\".\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:307\n\n\n\n\n\n\nisLocalVariable(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nReturns true if the Symbol in \"s\" is a local variable in LambdaInfo in \"li\".\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:286\n\n\n\n\n\n\nlambdaExprToLambdaInfo(lambda::Expr) \n\u00b6\n\n\nConvert a lambda expression into our internal storage format, LambdaInfo.\nThe input is asserted to be an expression whose head is :lambda.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:586\n\n\n\n\n\n\nlambdaInfoToLambdaExpr(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo,  body) \n\u00b6\n\n\nConvert our internal storage format, LambdaInfo, back into a lambda expression.\nThis takes a LambdaInfo and a body as input parameters.\nThis body can be a body expression or you can pass \"nothing\" if you want but then you will probably need to set the body in args[3] manually by yourself.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:673\n\n\n\n\n\n\nlambdaTypeinf(lambda::LambdaStaticData,  typs::Tuple) \n\u00b6\n\n\nForce type inference on a LambdaStaticData object.\nReturn both the inferred AST that is to a \"code_typed(Function, (type,...))\" call, \nand the inferred return type of the input method.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:637\n\n\n\n\n\n\nreplaceExprWithDict!(expr::ANY,  dict::Dict{Union{GenSym, Symbol}, Any}) \n\u00b6\n\n\nReplace the symbols in an expression \"expr\" with those defined in the\ndictionary \"dict\".  Return the result expression, which may share part of the\ninput expression, and the input \"expr\" may be modified inplace and shall not be used\nafter this call. Note that unlike \"replaceExprWithDict\", the traversal here is\ndone by ASTWalker, which has the ability to traverse non-Expr data.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:511\n\n\n\n\n\n\nreplaceExprWithDict!(expr::ANY,  dict::Dict{Union{GenSym, Symbol}, Any},  AstWalkFunc) \n\u00b6\n\n\nReplace the symbols in an expression \"expr\" with those defined in the\ndictionary \"dict\".  Return the result expression, which may share part of the\ninput expression, and the input \"expr\" may be modified inplace and shall not be used\nafter this call. Note that unlike \"replaceExprWithDict\", the traversal here is\ndone by ASTWalker, which has the ability to traverse non-Expr data.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:511\n\n\n\n\n\n\nreplaceExprWithDict(expr,  dict::Dict{Union{GenSym, Symbol}, Any}) \n\u00b6\n\n\nReplace the symbols in an expression \"expr\" with those defined in the\ndictionary \"dict\".  Return the result expression, which may share part of the\ninput expression, but the input \"expr\" remains intact and is not modified.\n\n\nNote that unlike \"replaceExprWithDict!\", we do not recurse down nested lambda\nexpressions (i.e., LambdaStaticData or DomainLambda or any other none Expr\nobjects are left unchanged). If such lambdas have escaping names that are to be\nreplaced, then the result will be wrong.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:473\n\n\n\n\n\n\nupdateAssignedDesc(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo,  symbol_assigns::Dict{Symbol, Int64}) \n\u00b6\n\n\nUpdate the descriptor part of the VarDef dealing with whether the variable is assigned or not in the function.\nTakes the lambdaInfo and a dictionary that maps symbols names to the number of times they are statically assigned in the function.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:682\n\n\n\n\n\n\nCompilerTools.LambdaHandling.LambdaInfo \n\u00b6\n\n\nAn internal format for storing a lambda expression's args[1] and args[2].\nThe input parameters are stored as a Set since they must be unique and it makes for faster searching.\nThe VarDefs are stored as a dictionary from symbol to VarDef since type lookups are reasonably frequent and need to be fast.\nThe GenSym part (args[2][3]) is stored as an array since GenSym's are indexed.\nCaptured_outer_vars and static_parameter_names are stored as arrays for now since we don't expect them to be changed much.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:86\n\n\n\n\n\n\nCompilerTools.LambdaHandling.VarDef \n\u00b6\n\n\nRepresents the triple stored in a lambda's args[2][1].\nThe triple is 1) the Symbol of an input parameter or local variable, 2) the type of that Symbol, and 3) a descriptor for that symbol.\nThe descriptor can be 0 if the variable is an input parameter, 1 if it is captured, 2 if it is assigned within the function, 4 if\nit is assigned by an inner function, 8 if it is const, and 16 if it is assigned to statically only once by the function.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:68\n\n\n\n\n\n\nSymGen \n\u00b6\n\n\nType aliases for different unions of Symbol, SymbolNode, and GenSym.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:54\n\n\nInternal\n\n\n\n\n\n\naddDescFlag(s::Symbol,  desc_flag::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdd one or more bitfields in \"desc_flag\" to the descriptor for a variable.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:330\n\n\n\n\n\n\naddInputParameter(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdd Symbol \"s\" as input parameter to LambdaInfo \"li\".\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:218\n\n\n\n\n\n\naddInputParameters(collection,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdd all variable in \"collection\" as input parameters to LambdaInfo \"li\".\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:226\n\n\n\n\n\n\naddLocalVar(name::AbstractString,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdd a local variable to the function corresponding to LambdaInfo in \"li\" with name (as String), type and descriptor.\nReturns true if variable already existed and was updated, false otherwise.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:402\n\n\n\n\n\n\naddLocalVar(name::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdd a local variable to the function corresponding to LambdaInfo in \"li\" with name (as Symbol), type and descriptor.\nReturns true if variable already existed and was updated, false otherwise.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:410\n\n\n\n\n\n\naddLocalVariables(collection,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nAdd multiple local variables from some collection type.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:314\n\n\n\n\n\n\ncount_symbols(x::Symbol,  state::CompilerTools.LambdaHandling.CountSymbolState,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAdds symbols and gensyms to their corresponding sets in CountSymbolState when they are seen in the AST.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:141\n\n\n\n\n\n\ncreateMeta(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nCreate the args[2] part of a lambda expression given an object of our internal storage format LambdaInfo.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:655\n\n\n\n\n\n\ncreateVarDict(x::Array{Any, 1}) \n\u00b6\n\n\nConvert the lambda expression's args[2][1] from Array{Array{Any,1},1} to a Dict{Symbol,VarDef}.\nThe internal triples are extracted and asserted that name and desc are of the appropriate type.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:439\n\n\n\n\n\n\ndictToArray(x::Dict{Symbol, CompilerTools.LambdaHandling.VarDef}) \n\u00b6\n\n\nConvert the Dict{Symbol,VarDef} internal storage format from a dictionary back into an array of Any triples.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:644\n\n\n\n\n\n\neliminateUnusedLocals!(li::CompilerTools.LambdaHandling.LambdaInfo,  body::Expr) \n\u00b6\n\n\nEliminates unused symbols from the LambdaInfo var_defs.\nTakes a LambdaInfo to modify, the body to scan using AstWalk and an optional callback to AstWalk for custom AST types.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:181\n\n\n\n\n\n\neliminateUnusedLocals!(li::CompilerTools.LambdaHandling.LambdaInfo,  body::Expr,  AstWalkFunc) \n\u00b6\n\n\nEliminates unused symbols from the LambdaInfo var_defs.\nTakes a LambdaInfo to modify, the body to scan using AstWalk and an optional callback to AstWalk for custom AST types.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:181\n\n\n\n\n\n\ngetLocalVariables(li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nReturns an array of Symbols for local variables.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:293\n\n\n\n\n\n\nmergeLambdaInfo(outer::CompilerTools.LambdaHandling.LambdaInfo,  inner::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nMerge \"inner\" lambdaInfo into \"outer\", and \"outer\" is changed as result.  Note\nthat the input_params, static_parameter_names, and escaping_defs of \"outer\" do\nnot change, other fields are merged. The GenSyms in \"inner\" will need to adjust\ntheir indices as a result of this merge. We return a dictionary that maps from\nold GenSym to new GenSym for \"inner\", which can be used to adjust the body Expr\nof \"inner\" lambda using \"replaceExprWithDict\" or \"replaceExprWithDict!\".\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:557\n\n\n\n\n\n\nremoveLocalVar(name::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nRemove a local variable from lambda \"li\" given the variable's \"name\".\nReturns true if the variable existed and it was removed, false otherwise.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:426\n\n\n\n\n\n\nshow(io::IO,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nPretty print a LambdaInfo.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:98\n\n\n\n\n\n\nCompilerTools.LambdaHandling.CountSymbolState \n\u00b6\n\n\nHolds symbols and gensyms that are seen in a given AST when using the specified callback to handle non-standard Julia AST types.\n\n\nsource:\n\n\nCompilerTools/src/lambda.jl:129", 
            "title": "CompilerTools.LambdaHandling"
        }, 
        {
            "location": "/CompilerTools.LambdaHandling/#compilertoolslambdahandling", 
            "text": "", 
            "title": "CompilerTools.LambdaHandling"
        }, 
        {
            "location": "/CompilerTools.LambdaHandling/#exported", 
            "text": "addEscapingVariable(s::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Adds a new escaping variable with the given Symbol \"s\", type \"typ\", descriptor \"desc\" in LambdaInfo \"li\".\nReturns true if the variable already existed and its type and descriptor were updated, false otherwise.  source:  CompilerTools/src/lambda.jl:365    addEscapingVariable(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Adds a new escaping variable from a VarDef in parameter \"vd\" into LambdaInfo \"li\".  source:  CompilerTools/src/lambda.jl:384    addGenSym(typ,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Add a new GenSym to the LambdaInfo in \"li\" with the given type in \"typ\".\nReturns the new GenSym.  source:  CompilerTools/src/lambda.jl:393    addLocalVariable(s::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Adds a new local variable with the given Symbol \"s\", type \"typ\", descriptor \"desc\" in LambdaInfo \"li\".\nReturns true if the variable already existed and its type and descriptor were updated, false otherwise.  source:  CompilerTools/src/lambda.jl:345    addLocalVariable(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Adds a local variable from a VarDef to the given LambdaInfo.  source:  CompilerTools/src/lambda.jl:323    getBody(lambda::Expr)  \u00b6  Returns the body expression part of a lambda expression.  source:  CompilerTools/src/lambda.jl:705    getDesc(x::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Returns the descriptor for a local variable or input parameter \"x\" from LambdaInfo in \"li\".  source:  CompilerTools/src/lambda.jl:265    getRefParams(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Returns an array of Symbols corresponding to those parameters to the method that are going to be passed by reference.\nIn short, isbits() types are passed by value and !isbits() types are passed by reference.  source:  CompilerTools/src/lambda.jl:715    getReturnType(li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Returns the type of the lambda as stored in LambdaInfo \"li\" and as extracted during lambdaExprToLambdaInfo.  source:  CompilerTools/src/lambda.jl:626    getType(x::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Returns the type of a Symbol or GenSym in \"x\" from LambdaInfo in \"li\".  source:  CompilerTools/src/lambda.jl:235    getVarDef(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Returns the VarDef for a Symbol in LambdaInfo in \"li\"  source:  CompilerTools/src/lambda.jl:272    isEscapingVariable(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Returns true if the Symbol in \"s\" is an escaping variable in LambdaInfo in \"li\".  source:  CompilerTools/src/lambda.jl:300    isInputParameter(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Returns true if the Symbol in \"s\" is an input parameter in LambdaInfo in \"li\".  source:  CompilerTools/src/lambda.jl:279    isLocalGenSym(s::GenSym,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Returns true if the GenSym in \"s\" is a GenSym in LambdaInfo in \"li\".  source:  CompilerTools/src/lambda.jl:307    isLocalVariable(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Returns true if the Symbol in \"s\" is a local variable in LambdaInfo in \"li\".  source:  CompilerTools/src/lambda.jl:286    lambdaExprToLambdaInfo(lambda::Expr)  \u00b6  Convert a lambda expression into our internal storage format, LambdaInfo.\nThe input is asserted to be an expression whose head is :lambda.  source:  CompilerTools/src/lambda.jl:586    lambdaInfoToLambdaExpr(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo,  body)  \u00b6  Convert our internal storage format, LambdaInfo, back into a lambda expression.\nThis takes a LambdaInfo and a body as input parameters.\nThis body can be a body expression or you can pass \"nothing\" if you want but then you will probably need to set the body in args[3] manually by yourself.  source:  CompilerTools/src/lambda.jl:673    lambdaTypeinf(lambda::LambdaStaticData,  typs::Tuple)  \u00b6  Force type inference on a LambdaStaticData object.\nReturn both the inferred AST that is to a \"code_typed(Function, (type,...))\" call, \nand the inferred return type of the input method.  source:  CompilerTools/src/lambda.jl:637    replaceExprWithDict!(expr::ANY,  dict::Dict{Union{GenSym, Symbol}, Any})  \u00b6  Replace the symbols in an expression \"expr\" with those defined in the\ndictionary \"dict\".  Return the result expression, which may share part of the\ninput expression, and the input \"expr\" may be modified inplace and shall not be used\nafter this call. Note that unlike \"replaceExprWithDict\", the traversal here is\ndone by ASTWalker, which has the ability to traverse non-Expr data.  source:  CompilerTools/src/lambda.jl:511    replaceExprWithDict!(expr::ANY,  dict::Dict{Union{GenSym, Symbol}, Any},  AstWalkFunc)  \u00b6  Replace the symbols in an expression \"expr\" with those defined in the\ndictionary \"dict\".  Return the result expression, which may share part of the\ninput expression, and the input \"expr\" may be modified inplace and shall not be used\nafter this call. Note that unlike \"replaceExprWithDict\", the traversal here is\ndone by ASTWalker, which has the ability to traverse non-Expr data.  source:  CompilerTools/src/lambda.jl:511    replaceExprWithDict(expr,  dict::Dict{Union{GenSym, Symbol}, Any})  \u00b6  Replace the symbols in an expression \"expr\" with those defined in the\ndictionary \"dict\".  Return the result expression, which may share part of the\ninput expression, but the input \"expr\" remains intact and is not modified.  Note that unlike \"replaceExprWithDict!\", we do not recurse down nested lambda\nexpressions (i.e., LambdaStaticData or DomainLambda or any other none Expr\nobjects are left unchanged). If such lambdas have escaping names that are to be\nreplaced, then the result will be wrong.  source:  CompilerTools/src/lambda.jl:473    updateAssignedDesc(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo,  symbol_assigns::Dict{Symbol, Int64})  \u00b6  Update the descriptor part of the VarDef dealing with whether the variable is assigned or not in the function.\nTakes the lambdaInfo and a dictionary that maps symbols names to the number of times they are statically assigned in the function.  source:  CompilerTools/src/lambda.jl:682    CompilerTools.LambdaHandling.LambdaInfo  \u00b6  An internal format for storing a lambda expression's args[1] and args[2].\nThe input parameters are stored as a Set since they must be unique and it makes for faster searching.\nThe VarDefs are stored as a dictionary from symbol to VarDef since type lookups are reasonably frequent and need to be fast.\nThe GenSym part (args[2][3]) is stored as an array since GenSym's are indexed.\nCaptured_outer_vars and static_parameter_names are stored as arrays for now since we don't expect them to be changed much.  source:  CompilerTools/src/lambda.jl:86    CompilerTools.LambdaHandling.VarDef  \u00b6  Represents the triple stored in a lambda's args[2][1].\nThe triple is 1) the Symbol of an input parameter or local variable, 2) the type of that Symbol, and 3) a descriptor for that symbol.\nThe descriptor can be 0 if the variable is an input parameter, 1 if it is captured, 2 if it is assigned within the function, 4 if\nit is assigned by an inner function, 8 if it is const, and 16 if it is assigned to statically only once by the function.  source:  CompilerTools/src/lambda.jl:68    SymGen  \u00b6  Type aliases for different unions of Symbol, SymbolNode, and GenSym.  source:  CompilerTools/src/lambda.jl:54", 
            "title": "Exported"
        }, 
        {
            "location": "/CompilerTools.LambdaHandling/#internal", 
            "text": "addDescFlag(s::Symbol,  desc_flag::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Add one or more bitfields in \"desc_flag\" to the descriptor for a variable.  source:  CompilerTools/src/lambda.jl:330    addInputParameter(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Add Symbol \"s\" as input parameter to LambdaInfo \"li\".  source:  CompilerTools/src/lambda.jl:218    addInputParameters(collection,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Add all variable in \"collection\" as input parameters to LambdaInfo \"li\".  source:  CompilerTools/src/lambda.jl:226    addLocalVar(name::AbstractString,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Add a local variable to the function corresponding to LambdaInfo in \"li\" with name (as String), type and descriptor.\nReturns true if variable already existed and was updated, false otherwise.  source:  CompilerTools/src/lambda.jl:402    addLocalVar(name::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Add a local variable to the function corresponding to LambdaInfo in \"li\" with name (as Symbol), type and descriptor.\nReturns true if variable already existed and was updated, false otherwise.  source:  CompilerTools/src/lambda.jl:410    addLocalVariables(collection,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Add multiple local variables from some collection type.  source:  CompilerTools/src/lambda.jl:314    count_symbols(x::Symbol,  state::CompilerTools.LambdaHandling.CountSymbolState,  top_level_number,  is_top_level,  read)  \u00b6  Adds symbols and gensyms to their corresponding sets in CountSymbolState when they are seen in the AST.  source:  CompilerTools/src/lambda.jl:141    createMeta(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Create the args[2] part of a lambda expression given an object of our internal storage format LambdaInfo.  source:  CompilerTools/src/lambda.jl:655    createVarDict(x::Array{Any, 1})  \u00b6  Convert the lambda expression's args[2][1] from Array{Array{Any,1},1} to a Dict{Symbol,VarDef}.\nThe internal triples are extracted and asserted that name and desc are of the appropriate type.  source:  CompilerTools/src/lambda.jl:439    dictToArray(x::Dict{Symbol, CompilerTools.LambdaHandling.VarDef})  \u00b6  Convert the Dict{Symbol,VarDef} internal storage format from a dictionary back into an array of Any triples.  source:  CompilerTools/src/lambda.jl:644    eliminateUnusedLocals!(li::CompilerTools.LambdaHandling.LambdaInfo,  body::Expr)  \u00b6  Eliminates unused symbols from the LambdaInfo var_defs.\nTakes a LambdaInfo to modify, the body to scan using AstWalk and an optional callback to AstWalk for custom AST types.  source:  CompilerTools/src/lambda.jl:181    eliminateUnusedLocals!(li::CompilerTools.LambdaHandling.LambdaInfo,  body::Expr,  AstWalkFunc)  \u00b6  Eliminates unused symbols from the LambdaInfo var_defs.\nTakes a LambdaInfo to modify, the body to scan using AstWalk and an optional callback to AstWalk for custom AST types.  source:  CompilerTools/src/lambda.jl:181    getLocalVariables(li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Returns an array of Symbols for local variables.  source:  CompilerTools/src/lambda.jl:293    mergeLambdaInfo(outer::CompilerTools.LambdaHandling.LambdaInfo,  inner::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Merge \"inner\" lambdaInfo into \"outer\", and \"outer\" is changed as result.  Note\nthat the input_params, static_parameter_names, and escaping_defs of \"outer\" do\nnot change, other fields are merged. The GenSyms in \"inner\" will need to adjust\ntheir indices as a result of this merge. We return a dictionary that maps from\nold GenSym to new GenSym for \"inner\", which can be used to adjust the body Expr\nof \"inner\" lambda using \"replaceExprWithDict\" or \"replaceExprWithDict!\".  source:  CompilerTools/src/lambda.jl:557    removeLocalVar(name::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Remove a local variable from lambda \"li\" given the variable's \"name\".\nReturns true if the variable existed and it was removed, false otherwise.  source:  CompilerTools/src/lambda.jl:426    show(io::IO,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Pretty print a LambdaInfo.  source:  CompilerTools/src/lambda.jl:98    CompilerTools.LambdaHandling.CountSymbolState  \u00b6  Holds symbols and gensyms that are seen in a given AST when using the specified callback to handle non-standard Julia AST types.  source:  CompilerTools/src/lambda.jl:129", 
            "title": "Internal"
        }, 
        {
            "location": "/CompilerTools.LivenessAnalysis/", 
            "text": "CompilerTools.LivenessAnalysis\n\n\nExported\n\n\n\n\n\n\nfind_bb_for_statement(top_number::Int64,  bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nSearch for a basic block containing a statement with the given top-level number in the liveness information.\nReturns a basic block label of a block having that top-level number or \"nothing\" if no such statement could be found.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:395\n\n\n\n\n\n\nshow(io::IO,  bb::CompilerTools.LivenessAnalysis.BasicBlock) \n\u00b6\n\n\nOverload of Base.show to pretty-print a LivenessAnalysis.BasicBlock.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:137\n\n\n\n\n\n\nshow(io::IO,  bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nOverload of Base.show to pretty-print BlockLiveness type.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:349\n\n\n\n\n\n\nshow(io::IO,  tls::CompilerTools.LivenessAnalysis.TopLevelStatement) \n\u00b6\n\n\nOverload of Base.show to pretty-print a LivenessAnalysis.TopLevelStatement.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:76\n\n\n\n\n\n\nCompilerTools.LivenessAnalysis.BlockLiveness \n\u00b6\n\n\nThe main return type from LivenessAnalysis.\nContains a dictionary that maps CFG basic block to liveness basic blocks.\nAlso contains the corresponding CFG.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:281\n\n\nInternal\n\n\n\n\n\n\nTypedExpr(typ,  rest...) \n\u00b6\n\n\nConvenience function to create an Expr and make sure the type is filled in as well.\nThe first arg is the type of the Expr and the rest of the args are the constructors args to Expr.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:43\n\n\n\n\n\n\naddUnmodifiedParams(func,  signature::Array{DataType, 1},  unmodifieds,  state::CompilerTools.LivenessAnalysis.expr_state) \n\u00b6\n\n\nAdd an entry the dictionary of which arguments can be modified by which functions.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:591\n\n\n\n\n\n\nadd_access(bb,  sym,  read) \n\u00b6\n\n\nCalled when AST traversal finds some Symbol \"sym\" in a basic block \"bb\".\n\"read\" is true if the symbol is being used and false if it is being defined.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:191\n\n\n\n\n\n\ncompute_live_ranges(state::CompilerTools.LivenessAnalysis.expr_state,  dfn) \n\u00b6\n\n\nCompute the live_in and live_out information for each basic block and statement.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:432\n\n\n\n\n\n\ncountSymbolDefs(s,  lives) \n\u00b6\n\n\nCount the number of times that the symbol in \"s\" is defined in all the basic blocks.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:837\n\n\n\n\n\n\ncreate_unmodified_args_dict() \n\u00b6\n\n\nConvert the function_descriptions table into a dictionary that can be passed to\nLivenessAnalysis to indicate which args are unmodified by which functions.\n\n\nsource:\n\n\nCompilerTools/src/function-descriptions.jl:257\n\n\n\n\n\n\ndef(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nGet the def information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:335\n\n\n\n\n\n\ndump_bb(bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nDump a bunch of debugging information about BlockLiveness.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:501\n\n\n\n\n\n\nfind_top_number(top_number::Int64,  bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nSearch for a statement with the given top-level number in the liveness information.\nReturns a LivenessAnalysis.TopLevelStatement having that top-level number or \"nothing\" if no such statement could be found.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:376\n\n\n\n\n\n\nfromCFG(live_res,  cfg::CompilerTools.CFGs.CFG,  callback::Function,  cbdata::ANY) \n\u00b6\n\n\nExtract liveness information from the CFG.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:878\n\n\n\n\n\n\nfrom_assignment(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY) \n\u00b6\n\n\nWalk through an assignment expression.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:566\n\n\n\n\n\n\nfrom_call(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY) \n\u00b6\n\n\nWalk through a call expression.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:780\n\n\n\n\n\n\nfrom_expr(ast::Expr) \n\u00b6\n\n\nThis function gives you the option of calling the ENTRY point from_expr with an ast and several optional named arguments.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:871\n\n\n\n\n\n\nfrom_expr(ast::Expr,  callback) \n\u00b6\n\n\nENTRY point to liveness analysis.\nYou must pass a :lambda Expr as \"ast\".\nIf you have non-standard AST nodes, you may pass a callback that will be given a chance to process the non-standard node first.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:859\n\n\n\n\n\n\nfrom_expr(ast::Expr,  callback,  cbdata::ANY) \n\u00b6\n\n\nENTRY point to liveness analysis.\nYou must pass a :lambda Expr as \"ast\".\nIf you have non-standard AST nodes, you may pass a callback that will be given a chance to process the non-standard node first.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:859\n\n\n\n\n\n\nfrom_expr(ast::Expr,  callback,  cbdata::ANY,  no_mod) \n\u00b6\n\n\nENTRY point to liveness analysis.\nYou must pass a :lambda Expr as \"ast\".\nIf you have non-standard AST nodes, you may pass a callback that will be given a chance to process the non-standard node first.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:859\n\n\n\n\n\n\nfrom_expr(ast::LambdaStaticData,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY) \n\u00b6\n\n\nGeneric routine for how to walk most AST node types.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:932\n\n\n\n\n\n\nfrom_exprs(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY) \n\u00b6\n\n\nWalk through an array of expressions.\nJust recursively call from_expr for each expression in the array.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:552\n\n\n\n\n\n\nfrom_if(args,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY) \n\u00b6\n\n\nProcess a gotoifnot which is just a recursive processing of its first arg which is the conditional.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:918\n\n\n\n\n\n\nfrom_lambda(ast::Expr,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY) \n\u00b6\n\n\nWalk through a lambda expression.\nWe just need to extract the ref_params because liveness needs to keep those ref_params live at the end of the function.\nWe don't recurse into the body here because from_expr handles that with fromCFG.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:542\n\n\n\n\n\n\nfrom_return(args,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY) \n\u00b6\n\n\nProcess a return Expr node which is just a recursive processing of all of its args.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:909\n\n\n\n\n\n\ngetUnmodifiedArgs(func::ANY,  args,  arg_type_tuple::Array{DataType, 1},  state::CompilerTools.LivenessAnalysis.expr_state) \n\u00b6\n\n\nFor a given function and signature, return which parameters can be modified by the function.\nIf we have cached this information previously then return that, else cache the information for some\nwell-known functions or default to presuming that all arguments could be modified.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:707\n\n\n\n\n\n\nget_function_from_string(mod::AbstractString,  func::AbstractString) \n\u00b6\n\n\nTakes a module and a function both as Strings. Looks up the specified module as\npart of the \"Main\" module and then looks and returns the Function object\ncorresponding to the \"func\" String in that module.\n\n\nsource:\n\n\nCompilerTools/src/function-descriptions.jl:239\n\n\n\n\n\n\nget_info_internal(x::Union{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.LivenessAnalysis.TopLevelStatement},  bl::CompilerTools.LivenessAnalysis.BlockLiveness,  field) \n\u00b6\n\n\nThe live_in, live_out, def, and use routines are all effectively the same but just extract a different field name.\nHere we extract this common behavior where x can be a liveness or CFG basic block or a liveness or CFG statement.\nbl is BlockLiveness type as returned by a previous LivenessAnalysis.\nfield is the name of the field requested.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:297\n\n\n\n\n\n\nisDef(x::Union{GenSym, Symbol},  live_info) \n\u00b6\n\n\nQuery if the symbol in argument \"x\" is defined in live_info which can be a BasicBlock or TopLevelStatement.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:367\n\n\n\n\n\n\nisPassedByRef(x,  state::CompilerTools.LivenessAnalysis.expr_state) \n\u00b6\n\n\nReturns true if a parameter is passed by reference.\nisbits types are not passed by ref but everything else is (is this always true..any exceptions?)\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:639\n\n\n\n\n\n\nlive_in(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nGet the live_in information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:321\n\n\n\n\n\n\nlive_out(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nGet the live_out information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:328\n\n\n\n\n\n\nnot_handled(a,  b) \n\u00b6\n\n\nThe default callback that processes no non-standard Julia AST nodes.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:830\n\n\n\n\n\n\nrecompute_live_ranges(state,  dfn) \n\u00b6\n\n\nClear the live_in and live_out data corresponding to all basic blocks and statements and then recompute liveness information.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:414\n\n\n\n\n\n\ntypeOfOpr(x::ANY,  li::CompilerTools.LambdaHandling.LambdaInfo) \n\u00b6\n\n\nGet the type of some AST node.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:598\n\n\n\n\n\n\nuncompressed_ast(l::LambdaStaticData) \n\u00b6\n\n\nConvert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:532\n\n\n\n\n\n\nuse(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nGet the use information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:342\n\n\n\n\n\n\nCompilerTools.LivenessAnalysis.AccessSummary \n\u00b6\n\n\nSometimes if new AST nodes are introduced then we need to ask for their def and use set as a whole\nand then incorporate that into our liveness analysis directly.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:111\n\n\n\n\n\n\nCompilerTools.LivenessAnalysis.BasicBlock \n\u00b6\n\n\nLiveness information for a BasicBlock.\nContains a pointer to the corresponding CFG BasicBlock.\nContains def, use, live_in, and live_out for this basic block.\nContains an array of liveness information for the top level statements in this block.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:124\n\n\n\n\n\n\nCompilerTools.LivenessAnalysis.TopLevelStatement \n\u00b6\n\n\nLiveness information for a TopLevelStatement in the CFG.\nContains a pointer to the corresponding CFG TopLevelStatement.\nContains def, use, live_in, and live_out for the current statement.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:64\n\n\n\n\n\n\nCompilerTools.LivenessAnalysis.expr_state \n\u00b6\n\n\nHolds the state during the AST traversal.\ncfg = the control flow graph from the CFGs module.\nmap = our own map of CFG basic blocks to our own basic block information with liveness in it.\ncur_bb = the current basic block in which we are processing AST nodes.\nread = whether the sub-tree we are currently processing is being read or written.\nref_params = those arguments to the function that are passed by reference.\n\n\nsource:\n\n\nCompilerTools/src/liveness.jl:265", 
            "title": "CompilerTools.LivenessAnalysis"
        }, 
        {
            "location": "/CompilerTools.LivenessAnalysis/#compilertoolslivenessanalysis", 
            "text": "", 
            "title": "CompilerTools.LivenessAnalysis"
        }, 
        {
            "location": "/CompilerTools.LivenessAnalysis/#exported", 
            "text": "find_bb_for_statement(top_number::Int64,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  Search for a basic block containing a statement with the given top-level number in the liveness information.\nReturns a basic block label of a block having that top-level number or \"nothing\" if no such statement could be found.  source:  CompilerTools/src/liveness.jl:395    show(io::IO,  bb::CompilerTools.LivenessAnalysis.BasicBlock)  \u00b6  Overload of Base.show to pretty-print a LivenessAnalysis.BasicBlock.  source:  CompilerTools/src/liveness.jl:137    show(io::IO,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  Overload of Base.show to pretty-print BlockLiveness type.  source:  CompilerTools/src/liveness.jl:349    show(io::IO,  tls::CompilerTools.LivenessAnalysis.TopLevelStatement)  \u00b6  Overload of Base.show to pretty-print a LivenessAnalysis.TopLevelStatement.  source:  CompilerTools/src/liveness.jl:76    CompilerTools.LivenessAnalysis.BlockLiveness  \u00b6  The main return type from LivenessAnalysis.\nContains a dictionary that maps CFG basic block to liveness basic blocks.\nAlso contains the corresponding CFG.  source:  CompilerTools/src/liveness.jl:281", 
            "title": "Exported"
        }, 
        {
            "location": "/CompilerTools.LivenessAnalysis/#internal", 
            "text": "TypedExpr(typ,  rest...)  \u00b6  Convenience function to create an Expr and make sure the type is filled in as well.\nThe first arg is the type of the Expr and the rest of the args are the constructors args to Expr.  source:  CompilerTools/src/liveness.jl:43    addUnmodifiedParams(func,  signature::Array{DataType, 1},  unmodifieds,  state::CompilerTools.LivenessAnalysis.expr_state)  \u00b6  Add an entry the dictionary of which arguments can be modified by which functions.  source:  CompilerTools/src/liveness.jl:591    add_access(bb,  sym,  read)  \u00b6  Called when AST traversal finds some Symbol \"sym\" in a basic block \"bb\".\n\"read\" is true if the symbol is being used and false if it is being defined.  source:  CompilerTools/src/liveness.jl:191    compute_live_ranges(state::CompilerTools.LivenessAnalysis.expr_state,  dfn)  \u00b6  Compute the live_in and live_out information for each basic block and statement.  source:  CompilerTools/src/liveness.jl:432    countSymbolDefs(s,  lives)  \u00b6  Count the number of times that the symbol in \"s\" is defined in all the basic blocks.  source:  CompilerTools/src/liveness.jl:837    create_unmodified_args_dict()  \u00b6  Convert the function_descriptions table into a dictionary that can be passed to\nLivenessAnalysis to indicate which args are unmodified by which functions.  source:  CompilerTools/src/function-descriptions.jl:257    def(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  Get the def information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.  source:  CompilerTools/src/liveness.jl:335    dump_bb(bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  Dump a bunch of debugging information about BlockLiveness.  source:  CompilerTools/src/liveness.jl:501    find_top_number(top_number::Int64,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  Search for a statement with the given top-level number in the liveness information.\nReturns a LivenessAnalysis.TopLevelStatement having that top-level number or \"nothing\" if no such statement could be found.  source:  CompilerTools/src/liveness.jl:376    fromCFG(live_res,  cfg::CompilerTools.CFGs.CFG,  callback::Function,  cbdata::ANY)  \u00b6  Extract liveness information from the CFG.  source:  CompilerTools/src/liveness.jl:878    from_assignment(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)  \u00b6  Walk through an assignment expression.  source:  CompilerTools/src/liveness.jl:566    from_call(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)  \u00b6  Walk through a call expression.  source:  CompilerTools/src/liveness.jl:780    from_expr(ast::Expr)  \u00b6  This function gives you the option of calling the ENTRY point from_expr with an ast and several optional named arguments.  source:  CompilerTools/src/liveness.jl:871    from_expr(ast::Expr,  callback)  \u00b6  ENTRY point to liveness analysis.\nYou must pass a :lambda Expr as \"ast\".\nIf you have non-standard AST nodes, you may pass a callback that will be given a chance to process the non-standard node first.  source:  CompilerTools/src/liveness.jl:859    from_expr(ast::Expr,  callback,  cbdata::ANY)  \u00b6  ENTRY point to liveness analysis.\nYou must pass a :lambda Expr as \"ast\".\nIf you have non-standard AST nodes, you may pass a callback that will be given a chance to process the non-standard node first.  source:  CompilerTools/src/liveness.jl:859    from_expr(ast::Expr,  callback,  cbdata::ANY,  no_mod)  \u00b6  ENTRY point to liveness analysis.\nYou must pass a :lambda Expr as \"ast\".\nIf you have non-standard AST nodes, you may pass a callback that will be given a chance to process the non-standard node first.  source:  CompilerTools/src/liveness.jl:859    from_expr(ast::LambdaStaticData,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)  \u00b6  Generic routine for how to walk most AST node types.  source:  CompilerTools/src/liveness.jl:932    from_exprs(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)  \u00b6  Walk through an array of expressions.\nJust recursively call from_expr for each expression in the array.  source:  CompilerTools/src/liveness.jl:552    from_if(args,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)  \u00b6  Process a gotoifnot which is just a recursive processing of its first arg which is the conditional.  source:  CompilerTools/src/liveness.jl:918    from_lambda(ast::Expr,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)  \u00b6  Walk through a lambda expression.\nWe just need to extract the ref_params because liveness needs to keep those ref_params live at the end of the function.\nWe don't recurse into the body here because from_expr handles that with fromCFG.  source:  CompilerTools/src/liveness.jl:542    from_return(args,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)  \u00b6  Process a return Expr node which is just a recursive processing of all of its args.  source:  CompilerTools/src/liveness.jl:909    getUnmodifiedArgs(func::ANY,  args,  arg_type_tuple::Array{DataType, 1},  state::CompilerTools.LivenessAnalysis.expr_state)  \u00b6  For a given function and signature, return which parameters can be modified by the function.\nIf we have cached this information previously then return that, else cache the information for some\nwell-known functions or default to presuming that all arguments could be modified.  source:  CompilerTools/src/liveness.jl:707    get_function_from_string(mod::AbstractString,  func::AbstractString)  \u00b6  Takes a module and a function both as Strings. Looks up the specified module as\npart of the \"Main\" module and then looks and returns the Function object\ncorresponding to the \"func\" String in that module.  source:  CompilerTools/src/function-descriptions.jl:239    get_info_internal(x::Union{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.LivenessAnalysis.TopLevelStatement},  bl::CompilerTools.LivenessAnalysis.BlockLiveness,  field)  \u00b6  The live_in, live_out, def, and use routines are all effectively the same but just extract a different field name.\nHere we extract this common behavior where x can be a liveness or CFG basic block or a liveness or CFG statement.\nbl is BlockLiveness type as returned by a previous LivenessAnalysis.\nfield is the name of the field requested.  source:  CompilerTools/src/liveness.jl:297    isDef(x::Union{GenSym, Symbol},  live_info)  \u00b6  Query if the symbol in argument \"x\" is defined in live_info which can be a BasicBlock or TopLevelStatement.  source:  CompilerTools/src/liveness.jl:367    isPassedByRef(x,  state::CompilerTools.LivenessAnalysis.expr_state)  \u00b6  Returns true if a parameter is passed by reference.\nisbits types are not passed by ref but everything else is (is this always true..any exceptions?)  source:  CompilerTools/src/liveness.jl:639    live_in(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  Get the live_in information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.  source:  CompilerTools/src/liveness.jl:321    live_out(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  Get the live_out information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.  source:  CompilerTools/src/liveness.jl:328    not_handled(a,  b)  \u00b6  The default callback that processes no non-standard Julia AST nodes.  source:  CompilerTools/src/liveness.jl:830    recompute_live_ranges(state,  dfn)  \u00b6  Clear the live_in and live_out data corresponding to all basic blocks and statements and then recompute liveness information.  source:  CompilerTools/src/liveness.jl:414    typeOfOpr(x::ANY,  li::CompilerTools.LambdaHandling.LambdaInfo)  \u00b6  Get the type of some AST node.  source:  CompilerTools/src/liveness.jl:598    uncompressed_ast(l::LambdaStaticData)  \u00b6  Convert a compressed LambdaStaticData format into the uncompressed AST format.  source:  CompilerTools/src/liveness.jl:532    use(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  Get the use information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.  source:  CompilerTools/src/liveness.jl:342    CompilerTools.LivenessAnalysis.AccessSummary  \u00b6  Sometimes if new AST nodes are introduced then we need to ask for their def and use set as a whole\nand then incorporate that into our liveness analysis directly.  source:  CompilerTools/src/liveness.jl:111    CompilerTools.LivenessAnalysis.BasicBlock  \u00b6  Liveness information for a BasicBlock.\nContains a pointer to the corresponding CFG BasicBlock.\nContains def, use, live_in, and live_out for this basic block.\nContains an array of liveness information for the top level statements in this block.  source:  CompilerTools/src/liveness.jl:124    CompilerTools.LivenessAnalysis.TopLevelStatement  \u00b6  Liveness information for a TopLevelStatement in the CFG.\nContains a pointer to the corresponding CFG TopLevelStatement.\nContains def, use, live_in, and live_out for the current statement.  source:  CompilerTools/src/liveness.jl:64    CompilerTools.LivenessAnalysis.expr_state  \u00b6  Holds the state during the AST traversal.\ncfg = the control flow graph from the CFGs module.\nmap = our own map of CFG basic blocks to our own basic block information with liveness in it.\ncur_bb = the current basic block in which we are processing AST nodes.\nread = whether the sub-tree we are currently processing is being read or written.\nref_params = those arguments to the function that are passed by reference.  source:  CompilerTools/src/liveness.jl:265", 
            "title": "Internal"
        }, 
        {
            "location": "/CompilerTools.Loops/", 
            "text": "CompilerTools.Loops\n\n\nExported\n\n\n\n\n\n\nCompilerTools.Loops.DomLoops \n\u00b6\n\n\nA type that holds information about which basic blocks dominate which other blocks.\nIt also contains an array \"loops\" of all the loops discovered within the function.\nThe same basic block may occur as a member in multiple loop entries if those loops are nested.\nThis module doesn't currently help identify these nesting levels but by looking at loop members it is easy enough to figure out.\n\n\nsource:\n\n\nCompilerTools/src/loops.jl:59\n\n\n\n\n\n\nCompilerTools.Loops.Loop \n\u00b6\n\n\nA type to hold information about a loop.\nA loop has a \"head\" that dominates all the other blocks in the loop.\nA loop has a back_edge which is a block that has \"head\" as one of its successors.\nIt also contains \"members\" which is a set of basic block labels of all the basic blocks that are a part of this loop.\n\n\nsource:\n\n\nCompilerTools/src/loops.jl:43\n\n\nInternal\n\n\n\n\n\n\ncompute_dom_loops(bl::CompilerTools.CFGs.CFG) \n\u00b6\n\n\nFind the loops in a CFGs.CFG in \"bl\".\n\n\nsource:\n\n\nCompilerTools/src/loops.jl:211\n\n\n\n\n\n\nfindLoopInvariants(l::CompilerTools.Loops.Loop,  udinfo::Dict{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.UDChains.UDInfo},  bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nFinds those computations within a loop that are iteration invariant.\nTakes as input:\n   l - the Loop to find invariants in\n   udinfo - UDChains (use-definition chains) for the basic blocks of the function.\n   bl - LivenessAnalysis.BlockLiveness with liveness information for variables within the function.\n\n\nsource:\n\n\nCompilerTools/src/loops.jl:86\n\n\n\n\n\n\nfindLoopMembers(head,  back_edge,  bbs) \n\u00b6\n\n\nFind all the members of the loop as specified by the \"head\" basic block and the \"back_edge\" basic block.\nAlso takes the dictionary of labels to basic blocks.\nStart with just the head of the loop as a member and then starts recursing with the back_edge using flm_internal.\n\n\nsource:\n\n\nCompilerTools/src/loops.jl:205\n\n\n\n\n\n\nflm_internal(cur_bb,  members,  bbs) \n\u00b6\n\n\nAdd to the \"members\" of the loop being accumulated given \"cur_bb\" which is known to be a member of the loop.\n\n\nsource:\n\n\nCompilerTools/src/loops.jl:183\n\n\n\n\n\n\nisInLoop(dl::CompilerTools.Loops.DomLoops,  bb::Int64) \n\u00b6\n\n\nTakes a DomLoops object containing loop information about the function.\nReturns true if the given basic block label \"bb\" is in some loop in the function.\n\n\nsource:\n\n\nCompilerTools/src/loops.jl:66", 
            "title": "CompilerTools.Loops"
        }, 
        {
            "location": "/CompilerTools.Loops/#compilertoolsloops", 
            "text": "", 
            "title": "CompilerTools.Loops"
        }, 
        {
            "location": "/CompilerTools.Loops/#exported", 
            "text": "CompilerTools.Loops.DomLoops  \u00b6  A type that holds information about which basic blocks dominate which other blocks.\nIt also contains an array \"loops\" of all the loops discovered within the function.\nThe same basic block may occur as a member in multiple loop entries if those loops are nested.\nThis module doesn't currently help identify these nesting levels but by looking at loop members it is easy enough to figure out.  source:  CompilerTools/src/loops.jl:59    CompilerTools.Loops.Loop  \u00b6  A type to hold information about a loop.\nA loop has a \"head\" that dominates all the other blocks in the loop.\nA loop has a back_edge which is a block that has \"head\" as one of its successors.\nIt also contains \"members\" which is a set of basic block labels of all the basic blocks that are a part of this loop.  source:  CompilerTools/src/loops.jl:43", 
            "title": "Exported"
        }, 
        {
            "location": "/CompilerTools.Loops/#internal", 
            "text": "compute_dom_loops(bl::CompilerTools.CFGs.CFG)  \u00b6  Find the loops in a CFGs.CFG in \"bl\".  source:  CompilerTools/src/loops.jl:211    findLoopInvariants(l::CompilerTools.Loops.Loop,  udinfo::Dict{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.UDChains.UDInfo},  bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  Finds those computations within a loop that are iteration invariant.\nTakes as input:\n   l - the Loop to find invariants in\n   udinfo - UDChains (use-definition chains) for the basic blocks of the function.\n   bl - LivenessAnalysis.BlockLiveness with liveness information for variables within the function.  source:  CompilerTools/src/loops.jl:86    findLoopMembers(head,  back_edge,  bbs)  \u00b6  Find all the members of the loop as specified by the \"head\" basic block and the \"back_edge\" basic block.\nAlso takes the dictionary of labels to basic blocks.\nStart with just the head of the loop as a member and then starts recursing with the back_edge using flm_internal.  source:  CompilerTools/src/loops.jl:205    flm_internal(cur_bb,  members,  bbs)  \u00b6  Add to the \"members\" of the loop being accumulated given \"cur_bb\" which is known to be a member of the loop.  source:  CompilerTools/src/loops.jl:183    isInLoop(dl::CompilerTools.Loops.DomLoops,  bb::Int64)  \u00b6  Takes a DomLoops object containing loop information about the function.\nReturns true if the given basic block label \"bb\" is in some loop in the function.  source:  CompilerTools/src/loops.jl:66", 
            "title": "Internal"
        }, 
        {
            "location": "/CompilerTools.OptFramework/", 
            "text": "CompilerTools.OptFramework\n\n\nExported\n\n\n\n\n\n\naddOptPass(func,  level) \n\u00b6\n\n\nSame as the other addOptPass but with a pass call back function and pass level as input.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:103\n\n\n\n\n\n\naddOptPass(pass::CompilerTools.OptFramework.OptPass) \n\u00b6\n\n\nAdd an optimization pass. If this is going to be called multiple times then you need some external way of corrdinating the code/modules that are calling this function so that optimization passes are added in some sane order.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:88\n\n\n\n\n\n\n@acc(ast1, ast2...) \n\u00b6\n\n\nThe @acc macro comes in two forms:\n1) @acc expression\n3) @acc function ... end\nIn the first form, the set of optimization passes to apply come from the default set of optimization passes as specified with the funciton setOptPasses.  The @acc macro replaces each call in the expression with a call to a trampolines that determines the types of the call and if that combination of function and signature has not previously been optimized then it calls the set of optimization passes to optimize it.  Then, the trampoline calls the optimized function.\nThe second form is similar, and instead annotating callsite, the @acc macro can be used in front of a function's declaration. Used this way, it will replace the body of the function with the trampoline itself. The programmer can use @acc either at function callsite, or at function delcaration, but not both.\nThis macro may optionally take an OptPass array, right after @acc and followed by an expression or function.  In this case, the specified set of optPasses are used just for optimizing the following expression. When used with the second form (in front of a function), the value of this OptPass array will be statically evaluated at the macro expansion stage.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:580\n\n\n\n\n\n\n@noacc(ast) \n\u00b6\n\n\nThe macro @noacc can be used at call site to specifically run the non-accelerated copy of an accelerated function. It has no effect and gives a warning when the given function is not found to have been accelerated. We do not support nested @acc or @noacc. \n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:651\n\n\nInternal\n\n\n\n\n\n\nTypedExpr(typ,  rest...) \n\u00b6\n\n\nCreates a typed Expr AST node.\nConvenence function that takes a type as first argument and the varargs thereafter.\nThe varargs are used to form an Expr AST node and the type parameter is used to fill in the \"typ\" field of the Expr.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:42\n\n\n\n\n\n\ncleanupASTLabels(ast) \n\u00b6\n\n\nClean up the labels in AST by renaming them, and removing duplicates.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:265\n\n\n\n\n\n\nconvertCodeToLevel(ast::ANY,  sig::ANY,  old_level,  new_level,  func) \n\u00b6\n\n\nconvert AST from \"old_level\" to \"new_level\". The input \"ast\" can be either Expr or Function type. In the latter case, the result AST will be obtained from this function using an matching signature \"sig\". The last \"func\" is a skeleton function that is used internally to facility such conversion.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:133\n\n\n\n\n\n\nconvert_expr(per_site_opt_set,  ast) \n\u00b6\n\n\nWhen @acc is used at a function's callsite, we use AstWalk to search for callsites via the opt_calls_insert_trampoline callback and to then insert trampolines.  That updated expression containing trampoline calls is then returned as the generated code from the @acc macro.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:471\n\n\n\n\n\n\nconvert_function(per_site_opt_set,  opt_set,  macros,  ast) \n\u00b6\n\n\nWhen @acc is used at a function definition, it creates a trampoline function, when called with a specific set of signature types, will try to optimize the original function, and call it with the real arguments.  The input \"ast\" should be an AST of the original function at macro level, which will be   replaced by the trampoline. \n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:486\n\n\n\n\n\n\ncreate_label_map(x,  state::CompilerTools.OptFramework.lmstate,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAn AstWalk callback that collects information about labels in an AST.\nThe labels in AST are generally not sequential but to feed back into a Function Expr\ncorrectly they need to be.  So, we keep a map from the old label in the AST to a new label\nthat we monotonically increases.\nIf we have code in the AST like the following:\n   1:\n   2:\n... then one of these labels is redundant.  We set \"last_was_label\" if the last AST node\nwe saw was a label.  If we see another LabelNode right after that then we duplicate the rhs\nof the label map.  For example, if you had the code:\n   5:\n   4:\n... and the label 5 was the third label in the code then in the label map you would then have:\n   5 -\n 3, 4 -\n 3.\nThis indicates that uses of both label 5 and label 4 in the code will become label 3 in the modified AST.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:238\n\n\n\n\n\n\ndumpLevel(level) \n\u00b6\n\n\npretty print pass level number as string.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:54\n\n\n\n\n\n\nevalPerSiteOptSet(per_site_opt_set) \n\u00b6\n\n\nStatically evaluate per-site optimization passes setting, and return the result.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:558\n\n\n\n\n\n\nfindOriginalFunc(mod::Module,  name::Symbol) \n\u00b6\n\n\nFind the original (before @acc macro) function for a wrapper function in the given module. \nReturn the input function if not found. Always return as a GlobalRef.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:616\n\n\n\n\n\n\nfindTargetFunc(mod::Module,  name::Symbol) \n\u00b6\n\n\nFind the optimizing target function (after @acc macro) for a wrapper function in the given module. \nReturn the input function if not found. Always return as a GlobalRef.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:607\n\n\n\n\n\n\ngetCodeAtLevel(func,  sig,  level) \n\u00b6\n\n\nRetrieve the AST of the given function \"func\" and signature \"sig\" for at the given pass \"level\".\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:110\n\n\n\n\n\n\nidentical{T}(t::Type{T},  x::T) \n\u00b6\n\n\nA hack to get around Julia's type inference. This is essentially an identity conversion,\nbut forces inferred return type to be the given type.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:370\n\n\n\n\n\n\nmakeWrapperFunc(new_fname::Symbol,  real_fname::Symbol,  call_sig_args::Array{Any, 1},  per_site_opt_set) \n\u00b6\n\n\nDefine a wrapper function with the name given by \"new_func\" that when called will try to optimize the \"real_func\" function, and run it with given parameters in \"call_sig_args\". The input \"per_site_opt_set\" can be either nothing, or a quoted Expr that refers to an array of OptPass.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:374\n\n\n\n\n\n\nopt_calls_insert_trampoline(x,  per_site_opt_set,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAn AstWalk callback function.\nFinds call sites in the AST and replaces them with calls to newly generated trampoline functions.\nThese trampolines functions allow us to capture runtime types which in turn enables optimization passes to run on fully typed AST.\nIf a function/signature combination has not previously been optimized then call processFuncCall to optimize it.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:440\n\n\n\n\n\n\nprocessFuncCall(func::ANY,  call_sig_arg_tuple::ANY,  per_site_opt_set::ANY) \n\u00b6\n\n\nTakes a function, a signature, and a set of optimizations and applies that set of optimizations to the function,\nreturns a new optimized function without modifying the input.  Argument explanation follows:\n1) func - the function being optimized\n2) call_sig_arg_tuple - the signature of the function, i.e., the types of each of its arguments\n3) per_site_opt_set - the set of optimization passes to apply to this function.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:309\n\n\n\n\n\n\nremoveDupLabels(stmts) \n\u00b6\n\n\nSometimes update_labels creates two label nodes that are the same.\nThis function removes such duplicate labels.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:245\n\n\n\n\n\n\nsetOptPasses(passes::Array{CompilerTools.OptFramework.OptPass, 1}) \n\u00b6\n\n\nSet the default set of optimization passes to apply with the @acc macro. \n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:79\n\n\n\n\n\n\ntfuncPresent(func,  tt) \n\u00b6\n\n\nMakes sure that a newly created function is correctly present in the internal Julia method table.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:282\n\n\n\n\n\n\nupdate_labels(x,  state::CompilerTools.OptFramework.lmstate,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAn AstWalk callback that applies the label map created during create_label_map AstWalk.\nFor each label in the code, replace that label with the rhs of the label map.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:190\n\n\n\n\n\n\nCompilerTools.OptFramework.OptPass \n\u00b6\n\n\nA data structure that holds information about one high-level optimization pass to run.\n\"func\" is the callback function that does the optimization pass and should have the signature (GlobalRef, Expr, Tuple) where the GlobalRef provides the locate of the function to be optimized, Expr is the AST input to this pass, and Tuple is a tuple of all parameter types of the functions. It must return either an optimized Expr, or a Function.\n\"level\" indicates at which level this pass is to be run. \n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:70\n\n\n\n\n\n\nCompilerTools.OptFramework.lmstate \n\u00b6\n\n\nThe callback state variable used by create_label_map and update_labels.\nlabel_map is a dictionary mapping old label ID's in the old AST with new label ID's in the new AST.\nnext_block_num is a monotonically increasing integer starting from 0 so label occur sequentially in the new AST.\nlast_was_label keeps track of whether we see two consecutive LabelNodes in the AST.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:178\n\n\n\n\n\n\ngOptFrameworkDict \n\u00b6\n\n\nA global memo-table that maps both: the triple (function, signature, optPasses) to the trampoline function, and the trampoline function to the real function.\n\n\nsource:\n\n\nCompilerTools/src/OptFramework.jl:167", 
            "title": "CompilerTools.OptFramework"
        }, 
        {
            "location": "/CompilerTools.OptFramework/#compilertoolsoptframework", 
            "text": "", 
            "title": "CompilerTools.OptFramework"
        }, 
        {
            "location": "/CompilerTools.OptFramework/#exported", 
            "text": "addOptPass(func,  level)  \u00b6  Same as the other addOptPass but with a pass call back function and pass level as input.  source:  CompilerTools/src/OptFramework.jl:103    addOptPass(pass::CompilerTools.OptFramework.OptPass)  \u00b6  Add an optimization pass. If this is going to be called multiple times then you need some external way of corrdinating the code/modules that are calling this function so that optimization passes are added in some sane order.  source:  CompilerTools/src/OptFramework.jl:88    @acc(ast1, ast2...)  \u00b6  The @acc macro comes in two forms:\n1) @acc expression\n3) @acc function ... end\nIn the first form, the set of optimization passes to apply come from the default set of optimization passes as specified with the funciton setOptPasses.  The @acc macro replaces each call in the expression with a call to a trampolines that determines the types of the call and if that combination of function and signature has not previously been optimized then it calls the set of optimization passes to optimize it.  Then, the trampoline calls the optimized function.\nThe second form is similar, and instead annotating callsite, the @acc macro can be used in front of a function's declaration. Used this way, it will replace the body of the function with the trampoline itself. The programmer can use @acc either at function callsite, or at function delcaration, but not both.\nThis macro may optionally take an OptPass array, right after @acc and followed by an expression or function.  In this case, the specified set of optPasses are used just for optimizing the following expression. When used with the second form (in front of a function), the value of this OptPass array will be statically evaluated at the macro expansion stage.  source:  CompilerTools/src/OptFramework.jl:580    @noacc(ast)  \u00b6  The macro @noacc can be used at call site to specifically run the non-accelerated copy of an accelerated function. It has no effect and gives a warning when the given function is not found to have been accelerated. We do not support nested @acc or @noacc.   source:  CompilerTools/src/OptFramework.jl:651", 
            "title": "Exported"
        }, 
        {
            "location": "/CompilerTools.OptFramework/#internal", 
            "text": "TypedExpr(typ,  rest...)  \u00b6  Creates a typed Expr AST node.\nConvenence function that takes a type as first argument and the varargs thereafter.\nThe varargs are used to form an Expr AST node and the type parameter is used to fill in the \"typ\" field of the Expr.  source:  CompilerTools/src/OptFramework.jl:42    cleanupASTLabels(ast)  \u00b6  Clean up the labels in AST by renaming them, and removing duplicates.  source:  CompilerTools/src/OptFramework.jl:265    convertCodeToLevel(ast::ANY,  sig::ANY,  old_level,  new_level,  func)  \u00b6  convert AST from \"old_level\" to \"new_level\". The input \"ast\" can be either Expr or Function type. In the latter case, the result AST will be obtained from this function using an matching signature \"sig\". The last \"func\" is a skeleton function that is used internally to facility such conversion.  source:  CompilerTools/src/OptFramework.jl:133    convert_expr(per_site_opt_set,  ast)  \u00b6  When @acc is used at a function's callsite, we use AstWalk to search for callsites via the opt_calls_insert_trampoline callback and to then insert trampolines.  That updated expression containing trampoline calls is then returned as the generated code from the @acc macro.  source:  CompilerTools/src/OptFramework.jl:471    convert_function(per_site_opt_set,  opt_set,  macros,  ast)  \u00b6  When @acc is used at a function definition, it creates a trampoline function, when called with a specific set of signature types, will try to optimize the original function, and call it with the real arguments.  The input \"ast\" should be an AST of the original function at macro level, which will be   replaced by the trampoline.   source:  CompilerTools/src/OptFramework.jl:486    create_label_map(x,  state::CompilerTools.OptFramework.lmstate,  top_level_number,  is_top_level,  read)  \u00b6  An AstWalk callback that collects information about labels in an AST.\nThe labels in AST are generally not sequential but to feed back into a Function Expr\ncorrectly they need to be.  So, we keep a map from the old label in the AST to a new label\nthat we monotonically increases.\nIf we have code in the AST like the following:\n   1:\n   2:\n... then one of these labels is redundant.  We set \"last_was_label\" if the last AST node\nwe saw was a label.  If we see another LabelNode right after that then we duplicate the rhs\nof the label map.  For example, if you had the code:\n   5:\n   4:\n... and the label 5 was the third label in the code then in the label map you would then have:\n   5 -  3, 4 -  3.\nThis indicates that uses of both label 5 and label 4 in the code will become label 3 in the modified AST.  source:  CompilerTools/src/OptFramework.jl:238    dumpLevel(level)  \u00b6  pretty print pass level number as string.  source:  CompilerTools/src/OptFramework.jl:54    evalPerSiteOptSet(per_site_opt_set)  \u00b6  Statically evaluate per-site optimization passes setting, and return the result.  source:  CompilerTools/src/OptFramework.jl:558    findOriginalFunc(mod::Module,  name::Symbol)  \u00b6  Find the original (before @acc macro) function for a wrapper function in the given module. \nReturn the input function if not found. Always return as a GlobalRef.  source:  CompilerTools/src/OptFramework.jl:616    findTargetFunc(mod::Module,  name::Symbol)  \u00b6  Find the optimizing target function (after @acc macro) for a wrapper function in the given module. \nReturn the input function if not found. Always return as a GlobalRef.  source:  CompilerTools/src/OptFramework.jl:607    getCodeAtLevel(func,  sig,  level)  \u00b6  Retrieve the AST of the given function \"func\" and signature \"sig\" for at the given pass \"level\".  source:  CompilerTools/src/OptFramework.jl:110    identical{T}(t::Type{T},  x::T)  \u00b6  A hack to get around Julia's type inference. This is essentially an identity conversion,\nbut forces inferred return type to be the given type.  source:  CompilerTools/src/OptFramework.jl:370    makeWrapperFunc(new_fname::Symbol,  real_fname::Symbol,  call_sig_args::Array{Any, 1},  per_site_opt_set)  \u00b6  Define a wrapper function with the name given by \"new_func\" that when called will try to optimize the \"real_func\" function, and run it with given parameters in \"call_sig_args\". The input \"per_site_opt_set\" can be either nothing, or a quoted Expr that refers to an array of OptPass.  source:  CompilerTools/src/OptFramework.jl:374    opt_calls_insert_trampoline(x,  per_site_opt_set,  top_level_number,  is_top_level,  read)  \u00b6  An AstWalk callback function.\nFinds call sites in the AST and replaces them with calls to newly generated trampoline functions.\nThese trampolines functions allow us to capture runtime types which in turn enables optimization passes to run on fully typed AST.\nIf a function/signature combination has not previously been optimized then call processFuncCall to optimize it.  source:  CompilerTools/src/OptFramework.jl:440    processFuncCall(func::ANY,  call_sig_arg_tuple::ANY,  per_site_opt_set::ANY)  \u00b6  Takes a function, a signature, and a set of optimizations and applies that set of optimizations to the function,\nreturns a new optimized function without modifying the input.  Argument explanation follows:\n1) func - the function being optimized\n2) call_sig_arg_tuple - the signature of the function, i.e., the types of each of its arguments\n3) per_site_opt_set - the set of optimization passes to apply to this function.  source:  CompilerTools/src/OptFramework.jl:309    removeDupLabels(stmts)  \u00b6  Sometimes update_labels creates two label nodes that are the same.\nThis function removes such duplicate labels.  source:  CompilerTools/src/OptFramework.jl:245    setOptPasses(passes::Array{CompilerTools.OptFramework.OptPass, 1})  \u00b6  Set the default set of optimization passes to apply with the @acc macro.   source:  CompilerTools/src/OptFramework.jl:79    tfuncPresent(func,  tt)  \u00b6  Makes sure that a newly created function is correctly present in the internal Julia method table.  source:  CompilerTools/src/OptFramework.jl:282    update_labels(x,  state::CompilerTools.OptFramework.lmstate,  top_level_number,  is_top_level,  read)  \u00b6  An AstWalk callback that applies the label map created during create_label_map AstWalk.\nFor each label in the code, replace that label with the rhs of the label map.  source:  CompilerTools/src/OptFramework.jl:190    CompilerTools.OptFramework.OptPass  \u00b6  A data structure that holds information about one high-level optimization pass to run.\n\"func\" is the callback function that does the optimization pass and should have the signature (GlobalRef, Expr, Tuple) where the GlobalRef provides the locate of the function to be optimized, Expr is the AST input to this pass, and Tuple is a tuple of all parameter types of the functions. It must return either an optimized Expr, or a Function.\n\"level\" indicates at which level this pass is to be run.   source:  CompilerTools/src/OptFramework.jl:70    CompilerTools.OptFramework.lmstate  \u00b6  The callback state variable used by create_label_map and update_labels.\nlabel_map is a dictionary mapping old label ID's in the old AST with new label ID's in the new AST.\nnext_block_num is a monotonically increasing integer starting from 0 so label occur sequentially in the new AST.\nlast_was_label keeps track of whether we see two consecutive LabelNodes in the AST.  source:  CompilerTools/src/OptFramework.jl:178    gOptFrameworkDict  \u00b6  A global memo-table that maps both: the triple (function, signature, optPasses) to the trampoline function, and the trampoline function to the real function.  source:  CompilerTools/src/OptFramework.jl:167", 
            "title": "Internal"
        }, 
        {
            "location": "/CompilerTools.ReadWriteSet/", 
            "text": "CompilerTools.ReadWriteSet\n\n\nExported\n\n\n\n\n\n\nfrom_exprs(ast::Array{T, N}) \n\u00b6\n\n\nWalk through an array of expressions.\nJust recursively call from_expr for each expression in the array.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:129\n\n\n\n\n\n\nfrom_exprs(ast::Array{T, N},  callback::Union{Function, Void},  cbdata::ANY) \n\u00b6\n\n\nWalk through an array of expressions.\nJust recursively call from_expr for each expression in the array.\nTakes a callback and an opaque object so that non-standard Julia AST nodes can be processed via the callback.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:139\n\n\n\n\n\n\nfrom_exprs(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY) \n\u00b6\n\n\nWalk through an array of expressions.\nJust recursively call from_expr for each expression in the array.\nTakes a callback and an opaque object so that non-standard Julia AST nodes can be processed via the callback.\nTakes a ReadWriteSetType in \"rws\" into which information will be stored.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:167\n\n\n\n\n\n\nisRead(sym::Union{GenSym, Symbol},  rws::CompilerTools.ReadWriteSet.ReadWriteSetType) \n\u00b6\n\n\nReturn true if some symbol in \"sym\" is read either as a scalar or array within the computed ReadWriteSetType.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:82\n\n\n\n\n\n\nisWritten(sym::Union{GenSym, Symbol},  rws::CompilerTools.ReadWriteSet.ReadWriteSetType) \n\u00b6\n\n\nReturn true if some symbol in \"sym\" is written either as a scalar or array within the computed ReadWriteSetType.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:95\n\n\n\n\n\n\nCompilerTools.ReadWriteSet.AccessSet \n\u00b6\n\n\nHolds which scalars and which array are accessed and for array which index expressions are used.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:40\n\n\n\n\n\n\nCompilerTools.ReadWriteSet.ReadWriteSetType \n\u00b6\n\n\nStores which scalars and arrays are read or written in some code region.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:49\n\n\nInternal\n\n\n\n\n\n\naddIndexExpr!(this_dict,  array_name,  index_expr) \n\u00b6\n\n\nTakes a dictionary of symbol to an array of index expression.\nTakes an array in \"array_name\" being accessed with expression \"index_expr\".\nMakes sure there is an entry in the dictionary for this array and adds the index expression to this array.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:229\n\n\n\n\n\n\nfrom_assignment(ast::Array{Any, 1},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY) \n\u00b6\n\n\nProcess an assignment AST node.\nThe left-hand side of the assignment is added to the writeSet.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:214\n\n\n\n\n\n\nfrom_call(ast::Array{Any, 1},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY) \n\u00b6\n\n\nProcess :call Expr nodes to find arrayref and arrayset calls and adding the corresponding index expressions to the read and write sets respectively.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:239\n\n\n\n\n\n\nfrom_coloncolon(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY) \n\u00b6\n\n\nProcess a :(::) AST node.\nJust process the symbol part of the :(::) node in ast[1] (which is args of the node passed in).\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:189\n\n\n\n\n\n\nfrom_expr(ast::ANY) \n\u00b6\n\n\nWalk through one AST node.\nCalls the main internal walking function after initializing an empty ReadWriteSetType.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:146\n\n\n\n\n\n\nfrom_expr(ast::ANY,  callback::Union{Function, Void},  cbdata::ANY) \n\u00b6\n\n\nWalk through one AST node.\nCalls the main internal walking function after initializing an empty ReadWriteSetType.\nTakes a callback and an opaque object so that non-standard Julia AST nodes can be processed via the callback.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:156\n\n\n\n\n\n\nfrom_expr(ast::LambdaStaticData,  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY) \n\u00b6\n\n\nThe main routine that switches on all the various AST node types.\nThe internal nodes of the AST are of type Expr with various different Expr.head field values such as :lambda, :body, :block, etc.\nThe leaf nodes of the AST all have different types.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:302\n\n\n\n\n\n\nfrom_lambda(ast::Expr,  depth,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY) \n\u00b6\n\n\nWalk through a lambda expression.\nWe just need to recurse through the lambda body and can ignore the rest.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:118\n\n\n\n\n\n\nfrom_tuple(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY) \n\u00b6\n\n\nWalk through a tuple.\nJust recursively call from_exprs on the internal tuple array to process each part of the tuple.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:181\n\n\n\n\n\n\ntoSymGen(x::Union{GenSym, Symbol}) \n\u00b6\n\n\nIn various places we need a SymGen type which is the union of Symbol and GenSym.\nThis function takes a Symbol, SymbolNode, or GenSym and return either a Symbol or GenSym.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:198\n\n\n\n\n\n\ntryCallback(ast::ANY,  callback::Union{Function, Void},  cbdata::ANY,  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType) \n\u00b6\n\n\nIf an AST node is not recognized then we try the passing the node to the callback to see if \nit was able to process it.  If so, then we process the regular Julia statement returned by\nthe callback.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:284\n\n\n\n\n\n\nuncompressed_ast(l::LambdaStaticData) \n\u00b6\n\n\nConvert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nsource:\n\n\nCompilerTools/src/read-write-set.jl:108", 
            "title": "CompilerTools.ReadWriteSet"
        }, 
        {
            "location": "/CompilerTools.ReadWriteSet/#compilertoolsreadwriteset", 
            "text": "", 
            "title": "CompilerTools.ReadWriteSet"
        }, 
        {
            "location": "/CompilerTools.ReadWriteSet/#exported", 
            "text": "from_exprs(ast::Array{T, N})  \u00b6  Walk through an array of expressions.\nJust recursively call from_expr for each expression in the array.  source:  CompilerTools/src/read-write-set.jl:129    from_exprs(ast::Array{T, N},  callback::Union{Function, Void},  cbdata::ANY)  \u00b6  Walk through an array of expressions.\nJust recursively call from_expr for each expression in the array.\nTakes a callback and an opaque object so that non-standard Julia AST nodes can be processed via the callback.  source:  CompilerTools/src/read-write-set.jl:139    from_exprs(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)  \u00b6  Walk through an array of expressions.\nJust recursively call from_expr for each expression in the array.\nTakes a callback and an opaque object so that non-standard Julia AST nodes can be processed via the callback.\nTakes a ReadWriteSetType in \"rws\" into which information will be stored.  source:  CompilerTools/src/read-write-set.jl:167    isRead(sym::Union{GenSym, Symbol},  rws::CompilerTools.ReadWriteSet.ReadWriteSetType)  \u00b6  Return true if some symbol in \"sym\" is read either as a scalar or array within the computed ReadWriteSetType.  source:  CompilerTools/src/read-write-set.jl:82    isWritten(sym::Union{GenSym, Symbol},  rws::CompilerTools.ReadWriteSet.ReadWriteSetType)  \u00b6  Return true if some symbol in \"sym\" is written either as a scalar or array within the computed ReadWriteSetType.  source:  CompilerTools/src/read-write-set.jl:95    CompilerTools.ReadWriteSet.AccessSet  \u00b6  Holds which scalars and which array are accessed and for array which index expressions are used.  source:  CompilerTools/src/read-write-set.jl:40    CompilerTools.ReadWriteSet.ReadWriteSetType  \u00b6  Stores which scalars and arrays are read or written in some code region.  source:  CompilerTools/src/read-write-set.jl:49", 
            "title": "Exported"
        }, 
        {
            "location": "/CompilerTools.ReadWriteSet/#internal", 
            "text": "addIndexExpr!(this_dict,  array_name,  index_expr)  \u00b6  Takes a dictionary of symbol to an array of index expression.\nTakes an array in \"array_name\" being accessed with expression \"index_expr\".\nMakes sure there is an entry in the dictionary for this array and adds the index expression to this array.  source:  CompilerTools/src/read-write-set.jl:229    from_assignment(ast::Array{Any, 1},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)  \u00b6  Process an assignment AST node.\nThe left-hand side of the assignment is added to the writeSet.  source:  CompilerTools/src/read-write-set.jl:214    from_call(ast::Array{Any, 1},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)  \u00b6  Process :call Expr nodes to find arrayref and arrayset calls and adding the corresponding index expressions to the read and write sets respectively.  source:  CompilerTools/src/read-write-set.jl:239    from_coloncolon(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)  \u00b6  Process a :(::) AST node.\nJust process the symbol part of the :(::) node in ast[1] (which is args of the node passed in).  source:  CompilerTools/src/read-write-set.jl:189    from_expr(ast::ANY)  \u00b6  Walk through one AST node.\nCalls the main internal walking function after initializing an empty ReadWriteSetType.  source:  CompilerTools/src/read-write-set.jl:146    from_expr(ast::ANY,  callback::Union{Function, Void},  cbdata::ANY)  \u00b6  Walk through one AST node.\nCalls the main internal walking function after initializing an empty ReadWriteSetType.\nTakes a callback and an opaque object so that non-standard Julia AST nodes can be processed via the callback.  source:  CompilerTools/src/read-write-set.jl:156    from_expr(ast::LambdaStaticData,  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)  \u00b6  The main routine that switches on all the various AST node types.\nThe internal nodes of the AST are of type Expr with various different Expr.head field values such as :lambda, :body, :block, etc.\nThe leaf nodes of the AST all have different types.  source:  CompilerTools/src/read-write-set.jl:302    from_lambda(ast::Expr,  depth,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)  \u00b6  Walk through a lambda expression.\nWe just need to recurse through the lambda body and can ignore the rest.  source:  CompilerTools/src/read-write-set.jl:118    from_tuple(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)  \u00b6  Walk through a tuple.\nJust recursively call from_exprs on the internal tuple array to process each part of the tuple.  source:  CompilerTools/src/read-write-set.jl:181    toSymGen(x::Union{GenSym, Symbol})  \u00b6  In various places we need a SymGen type which is the union of Symbol and GenSym.\nThis function takes a Symbol, SymbolNode, or GenSym and return either a Symbol or GenSym.  source:  CompilerTools/src/read-write-set.jl:198    tryCallback(ast::ANY,  callback::Union{Function, Void},  cbdata::ANY,  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType)  \u00b6  If an AST node is not recognized then we try the passing the node to the callback to see if \nit was able to process it.  If so, then we process the regular Julia statement returned by\nthe callback.  source:  CompilerTools/src/read-write-set.jl:284    uncompressed_ast(l::LambdaStaticData)  \u00b6  Convert a compressed LambdaStaticData format into the uncompressed AST format.  source:  CompilerTools/src/read-write-set.jl:108", 
            "title": "Internal"
        }, 
        {
            "location": "/CompilerTools.UDChains/", 
            "text": "CompilerTools.UDChains\n\n\nInternal\n\n\n\n\n\n\ngetOrCreate(live::Dict{Symbol, Set{T}},  s::Symbol) \n\u00b6\n\n\nGet the set of definition blocks reaching this block for a given symbol \"s\".\n\n\nsource:\n\n\nCompilerTools/src/udchains.jl:49\n\n\n\n\n\n\ngetOrCreate(udchains::Dict{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.UDChains.UDInfo},  bb::CompilerTools.LivenessAnalysis.BasicBlock) \n\u00b6\n\n\nGet the UDInfo for a specified basic block \"bb\" or create one if it doesn't already exist.\n\n\nsource:\n\n\nCompilerTools/src/udchains.jl:59\n\n\n\n\n\n\ngetUDChains(bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nGet the Use-Definition chains at a basic block level given LivenessAnalysis.BlockLiveness as input in \"bl\".\n\n\nsource:\n\n\nCompilerTools/src/udchains.jl:105\n\n\n\n\n\n\nprintLabels(level,  dict) \n\u00b6\n\n\nPrint a live in or live out dictionary in a nice way if the debug level is set high enough.\n\n\nsource:\n\n\nCompilerTools/src/udchains.jl:82\n\n\n\n\n\n\nprintSet(level,  s) \n\u00b6\n\n\nPrint the set part of a live in or live out dictiononary in a nice way if the debug level is set high enough.\n\n\nsource:\n\n\nCompilerTools/src/udchains.jl:69\n\n\n\n\n\n\nprintUDInfo(level,  ud) \n\u00b6\n\n\nPrint UDChains in a nice way if the debug level is set high enough.\n\n\nsource:\n\n\nCompilerTools/src/udchains.jl:93\n\n\n\n\n\n\nCompilerTools.UDChains.UDInfo \n\u00b6\n\n\nContains the UDchains for one basic block.\n\n\nsource:\n\n\nCompilerTools/src/udchains.jl:37", 
            "title": "CompilerTools.UDChains"
        }, 
        {
            "location": "/CompilerTools.UDChains/#compilertoolsudchains", 
            "text": "", 
            "title": "CompilerTools.UDChains"
        }, 
        {
            "location": "/CompilerTools.UDChains/#internal", 
            "text": "getOrCreate(live::Dict{Symbol, Set{T}},  s::Symbol)  \u00b6  Get the set of definition blocks reaching this block for a given symbol \"s\".  source:  CompilerTools/src/udchains.jl:49    getOrCreate(udchains::Dict{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.UDChains.UDInfo},  bb::CompilerTools.LivenessAnalysis.BasicBlock)  \u00b6  Get the UDInfo for a specified basic block \"bb\" or create one if it doesn't already exist.  source:  CompilerTools/src/udchains.jl:59    getUDChains(bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  Get the Use-Definition chains at a basic block level given LivenessAnalysis.BlockLiveness as input in \"bl\".  source:  CompilerTools/src/udchains.jl:105    printLabels(level,  dict)  \u00b6  Print a live in or live out dictionary in a nice way if the debug level is set high enough.  source:  CompilerTools/src/udchains.jl:82    printSet(level,  s)  \u00b6  Print the set part of a live in or live out dictiononary in a nice way if the debug level is set high enough.  source:  CompilerTools/src/udchains.jl:69    printUDInfo(level,  ud)  \u00b6  Print UDChains in a nice way if the debug level is set high enough.  source:  CompilerTools/src/udchains.jl:93    CompilerTools.UDChains.UDInfo  \u00b6  Contains the UDchains for one basic block.  source:  CompilerTools/src/udchains.jl:37", 
            "title": "Internal"
        }, 
        {
            "location": "/CompilerTools/", 
            "text": "CompilerTools", 
            "title": "CompilerTools"
        }, 
        {
            "location": "/CompilerTools/#compilertools", 
            "text": "", 
            "title": "CompilerTools"
        }, 
        {
            "location": "/DomainIR/", 
            "text": "ParallelAccelerator.DomainIR\n\n\nInternal\n\n\n\n\n\n\nlookupConstDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode}) \n\u00b6\n\n\nLook up a definition of a variable only when it is const or assigned once.\nReturn nothing If none is found.\n\n\nsource:\n\n\nParallelAccelerator/src/domain-ir.jl:259\n\n\n\n\n\n\nlookupConstDefForArg(state::ParallelAccelerator.DomainIR.IRState,  s) \n\u00b6\n\n\nLook up a definition of a variable recursively until the RHS is no-longer just a variable.\nReturn the last rhs If found, or the input variable itself otherwise.\n\n\nsource:\n\n\nParallelAccelerator/src/domain-ir.jl:273\n\n\n\n\n\n\nlookupDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode}) \n\u00b6\n\n\nLook up a definition of a variable.\nReturn nothing If none is found.\n\n\nsource:\n\n\nParallelAccelerator/src/domain-ir.jl:250\n\n\n\n\n\n\nlookupDefInAllScopes(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode}) \n\u00b6\n\n\nLook up a definition of a variable throughout nested states until a definition is found.\nReturn nothing If none is found.\n\n\nsource:\n\n\nParallelAccelerator/src/domain-ir.jl:286\n\n\n\n\n\n\nupdateDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode},  rhs) \n\u00b6\n\n\nUpdate the definition of a variable.\n\n\nsource:\n\n\nParallelAccelerator/src/domain-ir.jl:235", 
            "title": "DomainIR"
        }, 
        {
            "location": "/DomainIR/#parallelacceleratordomainir", 
            "text": "", 
            "title": "ParallelAccelerator.DomainIR"
        }, 
        {
            "location": "/DomainIR/#internal", 
            "text": "lookupConstDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})  \u00b6  Look up a definition of a variable only when it is const or assigned once.\nReturn nothing If none is found.  source:  ParallelAccelerator/src/domain-ir.jl:259    lookupConstDefForArg(state::ParallelAccelerator.DomainIR.IRState,  s)  \u00b6  Look up a definition of a variable recursively until the RHS is no-longer just a variable.\nReturn the last rhs If found, or the input variable itself otherwise.  source:  ParallelAccelerator/src/domain-ir.jl:273    lookupDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})  \u00b6  Look up a definition of a variable.\nReturn nothing If none is found.  source:  ParallelAccelerator/src/domain-ir.jl:250    lookupDefInAllScopes(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})  \u00b6  Look up a definition of a variable throughout nested states until a definition is found.\nReturn nothing If none is found.  source:  ParallelAccelerator/src/domain-ir.jl:286    updateDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode},  rhs)  \u00b6  Update the definition of a variable.  source:  ParallelAccelerator/src/domain-ir.jl:235", 
            "title": "Internal"
        }, 
        {
            "location": "/ParallelAccelerator.API.Capture/", 
            "text": "ParallelAccelerator.API.Capture\n\n\nInternal\n\n\n\n\n\n\nprocess_node(node::Expr,  state,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAt macro level, we translate function calls and operators that matches operator names\nin our API module to direct call to those in the API module. \n\n\nsource:\n\n\nParallelAccelerator/src/api-capture.jl:25", 
            "title": "ParallelAccelerator.API.Capture"
        }, 
        {
            "location": "/ParallelAccelerator.API.Capture/#parallelacceleratorapicapture", 
            "text": "", 
            "title": "ParallelAccelerator.API.Capture"
        }, 
        {
            "location": "/ParallelAccelerator.API.Capture/#internal", 
            "text": "process_node(node::Expr,  state,  top_level_number,  is_top_level,  read)  \u00b6  At macro level, we translate function calls and operators that matches operator names\nin our API module to direct call to those in the API module.   source:  ParallelAccelerator/src/api-capture.jl:25", 
            "title": "Internal"
        }, 
        {
            "location": "/ParallelAccelerator.API.Stencil/", 
            "text": "ParallelAccelerator.API.Stencil\n\n\nExported\n\n\n\n\n\n\nrunStencil(inputs...) \n\u00b6\n\n\n\"runStencil\" takes arguments in the form of \"(kernel_function, A, B, C, ...,\niteration, border_style)\" where \"kernel_function\" is a lambda that represent\nstencil kernel, and \"A\", \"B\", \"C\", ... are arrays (of same dimension and size)\nthat will be traversed by the stencil, and they must match the number of\narguments of the stencil kernel. \"iteration\" and \"border_style\" are optional,\nand if present, \"iteration\" is the number of steps to repeat the stencil\ncomputation, and \"border_style\" is a symbol of the following:\n\n\n:oob_src_zero, returns zero from a read when it is out-of-bound.\n\n:oob_dst_zero, writes zero to destination array in an assigment should any read in its right-hand-side become out-of-bound.\n\n:oob_wraparound, wraps around the index (with respect to source array dimension and sizes) of a read operation when it is out-of-bound.\n\n:oob_skip, skips write to destination array in an assignment should any read in its right-hand-side become out-of-bound.\n\n\n\nThe \"kernel_function\" should take a set of arrays as input, and in the function\nbody only index them with relative indices as if there is a cursor (at index 0)\ntraversing them. It may contain more than one assignment to any input arrays,\nbut such writes must always be indexed at 0 to guarantee write operation never\ngoes out-of-bound. Also care must be taken when the same array is both read\nfrom and written into in the kernel function, as they'll result in\nnon-deterministic behavior when the stencil is parallelized by ParallelAccelerator. \n\n\nThe \"kernel_function\" may optionally access scalar variables from outerscope,\nbut no write is permitted.  It may optinally contain a return statement, which\nacts as a specification for buffer swapping when it is an interative stencil\nloop (ISL). The number of arrays returned must match the input arrays.  If it\nis not an ISL, it should always return nothing.\n\n\nThis function is a reference implementation of stencil in native Julia for two\npurposes: to verify expected return result, and to make sure user code type\nchecks. It runs very very slow, so any real usage should go through ParallelAccelerator\noptimizations.\n\n\n\"runStencil\" always returns nothing.\n\n\nsource:\n\n\nParallelAccelerator/src/api-stencil.jl:142\n\n\nInternal\n\n\n\n\n\n\nprocess_node(node,  state,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nThis function is a AstWalker callback.\n\n\nsource:\n\n\nParallelAccelerator/src/api-stencil.jl:377\n\n\n\n\n\n\n@comprehend(ast) \n\u00b6\n\n\nTranslate all comprehension in an AST into equivalent code that uses cartesianarray call.\n\n\nsource:\n\n\nParallelAccelerator/src/api-stencil.jl:392", 
            "title": "ParallelAccelerator.API.Stencil"
        }, 
        {
            "location": "/ParallelAccelerator.API.Stencil/#parallelacceleratorapistencil", 
            "text": "", 
            "title": "ParallelAccelerator.API.Stencil"
        }, 
        {
            "location": "/ParallelAccelerator.API.Stencil/#exported", 
            "text": "runStencil(inputs...)  \u00b6  \"runStencil\" takes arguments in the form of \"(kernel_function, A, B, C, ...,\niteration, border_style)\" where \"kernel_function\" is a lambda that represent\nstencil kernel, and \"A\", \"B\", \"C\", ... are arrays (of same dimension and size)\nthat will be traversed by the stencil, and they must match the number of\narguments of the stencil kernel. \"iteration\" and \"border_style\" are optional,\nand if present, \"iteration\" is the number of steps to repeat the stencil\ncomputation, and \"border_style\" is a symbol of the following:  :oob_src_zero, returns zero from a read when it is out-of-bound.\n\n:oob_dst_zero, writes zero to destination array in an assigment should any read in its right-hand-side become out-of-bound.\n\n:oob_wraparound, wraps around the index (with respect to source array dimension and sizes) of a read operation when it is out-of-bound.\n\n:oob_skip, skips write to destination array in an assignment should any read in its right-hand-side become out-of-bound.  The \"kernel_function\" should take a set of arrays as input, and in the function\nbody only index them with relative indices as if there is a cursor (at index 0)\ntraversing them. It may contain more than one assignment to any input arrays,\nbut such writes must always be indexed at 0 to guarantee write operation never\ngoes out-of-bound. Also care must be taken when the same array is both read\nfrom and written into in the kernel function, as they'll result in\nnon-deterministic behavior when the stencil is parallelized by ParallelAccelerator.   The \"kernel_function\" may optionally access scalar variables from outerscope,\nbut no write is permitted.  It may optinally contain a return statement, which\nacts as a specification for buffer swapping when it is an interative stencil\nloop (ISL). The number of arrays returned must match the input arrays.  If it\nis not an ISL, it should always return nothing.  This function is a reference implementation of stencil in native Julia for two\npurposes: to verify expected return result, and to make sure user code type\nchecks. It runs very very slow, so any real usage should go through ParallelAccelerator\noptimizations.  \"runStencil\" always returns nothing.  source:  ParallelAccelerator/src/api-stencil.jl:142", 
            "title": "Exported"
        }, 
        {
            "location": "/ParallelAccelerator.API.Stencil/#internal", 
            "text": "process_node(node,  state,  top_level_number,  is_top_level,  read)  \u00b6  This function is a AstWalker callback.  source:  ParallelAccelerator/src/api-stencil.jl:377    @comprehend(ast)  \u00b6  Translate all comprehension in an AST into equivalent code that uses cartesianarray call.  source:  ParallelAccelerator/src/api-stencil.jl:392", 
            "title": "Internal"
        }, 
        {
            "location": "/ParallelAccelerator.API/", 
            "text": "ParallelAccelerator.API", 
            "title": "ParallelAccelerator.API"
        }, 
        {
            "location": "/ParallelAccelerator.API/#parallelacceleratorapi", 
            "text": "", 
            "title": "ParallelAccelerator.API"
        }, 
        {
            "location": "/ParallelAccelerator.CGen/", 
            "text": "ParallelAccelerator.CGen", 
            "title": "ParallelAccelerator.CGen"
        }, 
        {
            "location": "/ParallelAccelerator.CGen/#parallelacceleratorcgen", 
            "text": "", 
            "title": "ParallelAccelerator.CGen"
        }, 
        {
            "location": "/ParallelAccelerator.CallGraph/", 
            "text": "ParallelAccelerator.CallGraph", 
            "title": "ParallelAccelerator.CallGraph"
        }, 
        {
            "location": "/ParallelAccelerator.CallGraph/#parallelacceleratorcallgraph", 
            "text": "", 
            "title": "ParallelAccelerator.CallGraph"
        }, 
        {
            "location": "/ParallelAccelerator.Comprehension/", 
            "text": "ParallelAccelerator.Comprehension\n\n\nExported\n\n\n\n\n\n\n@comprehend(ast) \n\u00b6\n\n\nTranslate all comprehension in an AST into equivalent code that uses cartesianarray call.\n\n\nsource:\n\n\nParallelAccelerator/src/comprehension.jl:82\n\n\nInternal\n\n\n\n\n\n\ncomprehension_to_cartesianarray(ast) \n\u00b6\n\n\nTranslate an ast whose head is :comprehension into equivalent code that uses cartesianarray call.\n\n\nsource:\n\n\nParallelAccelerator/src/comprehension.jl:35\n\n\n\n\n\n\nprocess_node(node,  state,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nThis function is a AstWalker callback.\n\n\nsource:\n\n\nParallelAccelerator/src/comprehension.jl:64", 
            "title": "ParallelAccelerator.Comprehension"
        }, 
        {
            "location": "/ParallelAccelerator.Comprehension/#parallelacceleratorcomprehension", 
            "text": "", 
            "title": "ParallelAccelerator.Comprehension"
        }, 
        {
            "location": "/ParallelAccelerator.Comprehension/#exported", 
            "text": "@comprehend(ast)  \u00b6  Translate all comprehension in an AST into equivalent code that uses cartesianarray call.  source:  ParallelAccelerator/src/comprehension.jl:82", 
            "title": "Exported"
        }, 
        {
            "location": "/ParallelAccelerator.Comprehension/#internal", 
            "text": "comprehension_to_cartesianarray(ast)  \u00b6  Translate an ast whose head is :comprehension into equivalent code that uses cartesianarray call.  source:  ParallelAccelerator/src/comprehension.jl:35    process_node(node,  state,  top_level_number,  is_top_level,  read)  \u00b6  This function is a AstWalker callback.  source:  ParallelAccelerator/src/comprehension.jl:64", 
            "title": "Internal"
        }, 
        {
            "location": "/ParallelAccelerator.DistributedIR/", 
            "text": "ParallelAccelerator.DistributedIR\n\n\nInternal\n\n\n\n\n\n\ncheckParforsForDistribution(state::ParallelAccelerator.DistributedIR.DistIrState) \n\u00b6\n\n\nAll arrays of a parfor should distributable for it to be distributable.\nIf an array is used in any sequential parfor, it is not distributable.\n\n\nsource:\n\n\nParallelAccelerator/src/distributed-ir.jl:233\n\n\n\n\n\n\nget_arr_dist_info(node::Expr,  state,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nmark sequential arrays\n\n\nsource:\n\n\nParallelAccelerator/src/distributed-ir.jl:161", 
            "title": "ParallelAccelerator.DistributedIR"
        }, 
        {
            "location": "/ParallelAccelerator.DistributedIR/#parallelacceleratordistributedir", 
            "text": "", 
            "title": "ParallelAccelerator.DistributedIR"
        }, 
        {
            "location": "/ParallelAccelerator.DistributedIR/#internal", 
            "text": "checkParforsForDistribution(state::ParallelAccelerator.DistributedIR.DistIrState)  \u00b6  All arrays of a parfor should distributable for it to be distributable.\nIf an array is used in any sequential parfor, it is not distributable.  source:  ParallelAccelerator/src/distributed-ir.jl:233    get_arr_dist_info(node::Expr,  state,  top_level_number,  is_top_level,  read)  \u00b6  mark sequential arrays  source:  ParallelAccelerator/src/distributed-ir.jl:161", 
            "title": "Internal"
        }, 
        {
            "location": "/ParallelAccelerator.DomainIR/", 
            "text": "ParallelAccelerator.DomainIR\n\n\nInternal\n\n\n\n\n\n\nlookupConstDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode}) \n\u00b6\n\n\nLook up a definition of a variable only when it is const or assigned once.\nReturn nothing If none is found.\n\n\nsource:\n\n\nParallelAccelerator/src/domain-ir.jl:259\n\n\n\n\n\n\nlookupConstDefForArg(state::ParallelAccelerator.DomainIR.IRState,  s) \n\u00b6\n\n\nLook up a definition of a variable recursively until the RHS is no-longer just a variable.\nReturn the last rhs If found, or the input variable itself otherwise.\n\n\nsource:\n\n\nParallelAccelerator/src/domain-ir.jl:273\n\n\n\n\n\n\nlookupDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode}) \n\u00b6\n\n\nLook up a definition of a variable.\nReturn nothing If none is found.\n\n\nsource:\n\n\nParallelAccelerator/src/domain-ir.jl:250\n\n\n\n\n\n\nlookupDefInAllScopes(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode}) \n\u00b6\n\n\nLook up a definition of a variable throughout nested states until a definition is found.\nReturn nothing If none is found.\n\n\nsource:\n\n\nParallelAccelerator/src/domain-ir.jl:286\n\n\n\n\n\n\nupdateDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode},  rhs) \n\u00b6\n\n\nUpdate the definition of a variable.\n\n\nsource:\n\n\nParallelAccelerator/src/domain-ir.jl:235", 
            "title": "ParallelAccelerator.DomainIR"
        }, 
        {
            "location": "/ParallelAccelerator.DomainIR/#parallelacceleratordomainir", 
            "text": "", 
            "title": "ParallelAccelerator.DomainIR"
        }, 
        {
            "location": "/ParallelAccelerator.DomainIR/#internal", 
            "text": "lookupConstDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})  \u00b6  Look up a definition of a variable only when it is const or assigned once.\nReturn nothing If none is found.  source:  ParallelAccelerator/src/domain-ir.jl:259    lookupConstDefForArg(state::ParallelAccelerator.DomainIR.IRState,  s)  \u00b6  Look up a definition of a variable recursively until the RHS is no-longer just a variable.\nReturn the last rhs If found, or the input variable itself otherwise.  source:  ParallelAccelerator/src/domain-ir.jl:273    lookupDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})  \u00b6  Look up a definition of a variable.\nReturn nothing If none is found.  source:  ParallelAccelerator/src/domain-ir.jl:250    lookupDefInAllScopes(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})  \u00b6  Look up a definition of a variable throughout nested states until a definition is found.\nReturn nothing If none is found.  source:  ParallelAccelerator/src/domain-ir.jl:286    updateDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode},  rhs)  \u00b6  Update the definition of a variable.  source:  ParallelAccelerator/src/domain-ir.jl:235", 
            "title": "Internal"
        }, 
        {
            "location": "/ParallelAccelerator.Driver/", 
            "text": "ParallelAccelerator.Driver\n\n\nExported\n\n\n\n\n\n\ncaptureOperators(func,  ast,  sig) \n\u00b6\n\n\nA pass that translates supported operators and function calls to\nthose defined in ParallelAccelerator.API.\n\n\nsource:\n\n\nParallelAccelerator/src/driver.jl:98\n\n\n\n\n\n\nrunStencilMacro(func,  ast,  sig) \n\u00b6\n\n\nPass that translates runStencil call in the same way as a macro would do.\nThis is only used when PROSPECT_MODE is off.\n\n\nsource:\n\n\nParallelAccelerator/src/driver.jl:107\n\n\n\n\n\n\ntoCartesianArray(func,  ast,  sig) \n\u00b6\n\n\nPass for comprehension to cartesianarray translation.\n\n\nsource:\n\n\nParallelAccelerator/src/driver.jl:114", 
            "title": "ParallelAccelerator.Driver"
        }, 
        {
            "location": "/ParallelAccelerator.Driver/#parallelacceleratordriver", 
            "text": "", 
            "title": "ParallelAccelerator.Driver"
        }, 
        {
            "location": "/ParallelAccelerator.Driver/#exported", 
            "text": "captureOperators(func,  ast,  sig)  \u00b6  A pass that translates supported operators and function calls to\nthose defined in ParallelAccelerator.API.  source:  ParallelAccelerator/src/driver.jl:98    runStencilMacro(func,  ast,  sig)  \u00b6  Pass that translates runStencil call in the same way as a macro would do.\nThis is only used when PROSPECT_MODE is off.  source:  ParallelAccelerator/src/driver.jl:107    toCartesianArray(func,  ast,  sig)  \u00b6  Pass for comprehension to cartesianarray translation.  source:  ParallelAccelerator/src/driver.jl:114", 
            "title": "Exported"
        }, 
        {
            "location": "/ParallelAccelerator.J2CArray/", 
            "text": "ParallelAccelerator.J2CArray", 
            "title": "ParallelAccelerator.J2CArray"
        }, 
        {
            "location": "/ParallelAccelerator.J2CArray/#parallelacceleratorj2carray", 
            "text": "", 
            "title": "ParallelAccelerator.J2CArray"
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/", 
            "text": "ParallelAccelerator.ParallelIR\n\n\nExported\n\n\n\n\n\n\nAstWalk(ast,  callback,  cbdata) \n\u00b6\n\n\nParallelIR version of AstWalk.\nInvokes the DomainIR version of AstWalk and provides the parallel IR AstWalk callback AstWalkCallback.\n\n\nParallel IR AstWalk calls Domain IR AstWalk which in turn calls CompilerTools.AstWalker.AstWalk.\nFor each AST node, CompilerTools.AstWalker.AstWalk calls Domain IR callback to give it a chance to handle the node if it is a Domain IR node.\nLikewise, Domain IR callback first calls Parallel IR callback to give it a chance to handle Parallel IR nodes.\nThe Parallel IR callback similarly first calls the user-level callback to give it a chance to process the node.\nIf a callback returns \"nothing\" it means it didn't modify that node and that the previous code should process it.\nThe Parallel IR callback will return \"nothing\" if the node isn't a Parallel IR node.\nThe Domain IR callback will return \"nothing\" if the node isn't a Domain IR node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4876\n\n\n\n\n\n\nPIRInplace(x) \n\u00b6\n\n\nIf set to non-zero, perform the phase where non-inplace maps are converted to inplace maps to reduce allocations.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3816\n\n\n\n\n\n\nPIRNumSimplify(x) \n\u00b6\n\n\nSpecify the number of passes over the AST that do things like hoisting and other rearranging to maximize fusion.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1672\n\n\n\n\n\n\nPIRRunAsTasks(x) \n\u00b6\n\n\nDebugging feature to specify the number of tasks to create and to stop thereafter.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1853\n\n\n\n\n\n\nPIRSetFuseLimit(x) \n\u00b6\n\n\nControl how many parfor can be fused for testing purposes.\n    -1 means fuse all possible parfors.\n    0  means don't fuse any parfors.\n    1+ means fuse the specified number of parfors but then stop fusing beyond that.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1667\n\n\n\n\n\n\nPIRShortcutArrayAssignment(x) \n\u00b6\n\n\nEnables an experimental mode where if there is a statement a = b and they are arrays and b is not live-out then \nuse a special assignment node like a move assignment in C++.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3842\n\n\n\n\n\n\nPIRTaskGraphMode(x) \n\u00b6\n\n\nControl how blocks of code are made into tasks.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:589\n\n\n\n\n\n\nfrom_exprs(ast::Array{Any, 1},  depth,  state) \n\u00b6\n\n\nProcess an array of expressions.\nDifferentiate between top-level arrays of statements and arrays of expression that may occur elsewhere than the :body Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2274\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.PIRLoopNest \n\u00b6\n\n\nHolds the information about a loop in a parfor node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:76\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.PIRParForAst \n\u00b6\n\n\nThe parfor AST node type.\nWhile we are lowering domain IR to parfors and fusing we use this representation because it\nmakes it easier to associate related statements before and after the loop to the loop itself.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:174\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.PIRReduction \n\u00b6\n\n\nHolds the information about a reduction in a parfor node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:86\n\n\nInternal\n\n\n\n\n\n\nAstWalkCallback(x::Expr,  dw::ParallelAccelerator.ParallelIR.DirWalk,  top_level_number::Int64,  is_top_level::Bool,  read::Bool) \n\u00b6\n\n\nAstWalk callback that handles ParallelIR AST node types.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4724\n\n\n\n\n\n\nEquivalenceClassesAdd(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  sym::Symbol) \n\u00b6\n\n\nAdd a symbol as part of a new equivalence class if the symbol wasn't already in an equivalence class.\nReturn the equivalence class for the symbol.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:139\n\n\n\n\n\n\nEquivalenceClassesClear(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses) \n\u00b6\n\n\nClear an equivalence class.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:153\n\n\n\n\n\n\nEquivalenceClassesMerge(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  merge_to::Symbol,  merge_from::Symbol) \n\u00b6\n\n\nAt some point we realize that two arrays must have the same dimensions but up until that point\nwe might not have known that.  In which case they will start in different equivalence classes,\nmerge_to and merge_from, but need to be combined into one equivalence class.\nGo through the equivalence class dictionary and for any symbol belonging to the merge_from\nequivalence class, change it to now belong to the merge_to equivalence class.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:123\n\n\n\n\n\n\nPIRBbReorder(x) \n\u00b6\n\n\nIf set to non-zero, perform the bubble-sort like reordering phase to coalesce more parfor nodes together for fusion.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3832\n\n\n\n\n\n\nPIRHoistAllocation(x) \n\u00b6\n\n\nIf set to non-zero, perform the rearrangement phase that tries to moves alllocations outside of loops.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3824\n\n\n\n\n\n\nTypedExpr(typ,  rest...) \n\u00b6\n\n\nThis should pretty always be used instead of Expr(...) to form an expression as it forces the typ to be provided.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:67\n\n\n\n\n\n\naddUnknownArray(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nGiven an array whose name is in \"x\", allocate a new equivalence class for this array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:746\n\n\n\n\n\n\naddUnknownRange(x::Array{Any, 1},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nGiven an array of RangeExprs describing loop nest ranges, allocate a new equivalence class for this range.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:755\n\n\n\n\n\n\nadd_merge_correlations(old_sym::Union{GenSym, Symbol},  new_sym::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nIf we somehow determine that two arrays must be the same length then \nget the equivalence classes for the two arrays and merge those equivalence classes together.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:792\n\n\n\n\n\n\nasArray(x) \n\u00b6\n\n\nReturn one element array with element x.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4715\n\n\n\n\n\n\naugment_sn(dim::Int64,  index_vars,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1}) \n\u00b6\n\n\nMake sure the index parameters to arrayref or arrayset are Int64 or SymbolNode.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:29\n\n\n\n\n\n\ncall_instruction_count(args,  state::ParallelAccelerator.ParallelIR.eic_state,  debug_level) \n\u00b6\n\n\nGenerate an instruction count estimate for a call instruction.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:352\n\n\n\n\n\n\ncheckAndAddSymbolCorrelation(lhs::Union{GenSym, Symbol},  state,  dim_array) \n\u00b6\n\n\nMake sure all the dimensions are SymbolNodes.\nMake sure each dimension variable is assigned to only once in the function.\nExtract just the dimension variables names into dim_names and then register the correlation from lhs to those dimension names.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3277\n\n\n\n\n\n\nconvertUnsafe(stmt) \n\u00b6\n\n\nRemove unsafe array access Symbols from the incoming \"stmt\".\nReturns the updated statement if something was modifed, else returns \"nothing\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:951\n\n\n\n\n\n\nconvertUnsafeOrElse(stmt) \n\u00b6\n\n\nTry to remove unsafe array access Symbols from the incoming \"stmt\".  If successful, then return the updated\nstatement, else return the unmodified statement.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:970\n\n\n\n\n\n\nconvertUnsafeWalk(x::Expr,  state,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nThe AstWalk callback to find unsafe arrayset and arrayref variants and\nreplace them with the regular Julia versions.  Sets the \"found\" flag\nin the state when such a replacement is performed.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:919\n\n\n\n\n\n\ncopy_propagate(node::ANY,  data::ParallelAccelerator.ParallelIR.CopyPropagateState,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nIn each basic block, if there is a \"copy\" (i.e., something of the form \"a = b\") then put\nthat in copies as copies[a] = b.  Then, later in the basic block if you see the symbol\n\"a\" then replace it with \"b\".  Note that this is not SSA so \"a\" may be written again\nand if it is then it must be removed from copies.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2849\n\n\n\n\n\n\ncount_assignments(x,  symbol_assigns::Dict{Symbol, Int64},  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAstWalk callback to count the number of static times that a symbol is assigne within a method.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:920\n\n\n\n\n\n\ncreate1D_array_access_desc(array::SymbolNode) \n\u00b6\n\n\nCreate an array access descriptor for \"array\".\nPresumes that for point \"i\" in the iteration space that only index \"i\" is accessed.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:124\n\n\n\n\n\n\ncreate2D_array_access_desc(array::SymbolNode) \n\u00b6\n\n\nCreate an array access descriptor for \"array\".\nPresumes that for points \"(i,j)\" in the iteration space that only indices \"(i,j)\" is accessed.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:134\n\n\n\n\n\n\ncreateInstructionCountEstimate(the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nTakes a parfor and walks the body of the parfor and estimates the number of instruction needed for one instance of that body.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:557\n\n\n\n\n\n\ncreateLoweredAliasMap(dict1) \n\u00b6\n\n\nTake a single-step alias map, e.g., a=\nb, b=\nc, and create a lowered dictionary, a=\nc, b=\nc, that\nmaps each array to the transitively lowered array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1840\n\n\n\n\n\n\ncreateMapLhsToParfor(parfor_assignment,  the_parfor,  is_multi::Bool,  sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nCreates a mapping between variables on the left-hand side of an assignment where the right-hand side is a parfor\nand the arrays or scalars in that parfor that get assigned to the corresponding parts of the left-hand side.\nReturns a tuple where the first element is a map for arrays between left-hand side and parfor and the second\nelement is a map for reduction scalars between left-hand side and parfor.\nis_multi is true if the assignment is a fusion assignment.\nparfor_assignment is the AST of the whole expression.\nthe_parfor is the PIRParForAst type part of the incoming assignment.\nsym_to_type is an out parameter that maps symbols in the output mapping to their types.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1774\n\n\n\n\n\n\ncreateStateVar(state,  name,  typ,  access) \n\u00b6\n\n\nAdd a local variable to the current function's lambdaInfo.\nReturns a symbol node of the new variable.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:639\n\n\n\n\n\n\ncreateTempForArray(array_sn::Union{GenSym, Symbol, SymbolNode},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nCreate a temporary variable that is parfor private to hold the value of an element of an array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:647\n\n\n\n\n\n\ncreateTempForRangeOffset(num_used,  ranges::Array{ParallelAccelerator.ParallelIR.RangeData, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nCreate a variable to hold the offset of a range offset from the start of the array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:322\n\n\n\n\n\n\ncreateTempForRangedArray(array_sn::Union{GenSym, Symbol, SymbolNode},  range::Array{Union{GenSym, SymbolNode}, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nCreate a temporary variable that is parfor private to hold the value of an element of an array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:338\n\n\n\n\n\n\ncreate_array_access_desc(array::SymbolNode) \n\u00b6\n\n\nCreate an array access descriptor for \"array\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:144\n\n\n\n\n\n\ncreate_equivalence_classes(node::Expr,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level_number::Int64,  is_top_level::Bool,  read::Bool) \n\u00b6\n\n\nAstWalk callback to determine the array equivalence classes.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3405\n\n\n\n\n\n\ndfsVisit(swd::ParallelAccelerator.ParallelIR.StatementWithDeps,  vtime::Int64,  topo_sort::Array{ParallelAccelerator.ParallelIR.StatementWithDeps, N}) \n\u00b6\n\n\nConstruct a topological sort of the dependence graph.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3863\n\n\n\n\n\n\nestimateInstrCount(ast::Expr,  state::ParallelAccelerator.ParallelIR.eic_state,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAstWalk callback for estimating the instruction count.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:474\n\n\n\n\n\n\nextractArrayEquivalencies(node::Expr,  state) \n\u00b6\n\n\n\"node\" is a domainIR node.  Take the arrays used in this node, create an array equivalence for them if they \ndon't already have one and make sure they all share one equivalence class.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3215\n\n\n\n\n\n\nfindSelectedDimensions(inputInfo::Array{ParallelAccelerator.ParallelIR.InputInfo, 1},  state) \n\u00b6\n\n\nGiven all the InputInfo for a Domain IR operation being lowered to Parallel IR,\ndetermine the number of output dimensions for those arrays taking into account\nthat singly selected trailing dimensinos are eliminated.  Make sure that all such\narrays have the same output dimensions because this will match the loop nest size.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:745\n\n\n\n\n\n\nflattenParfor(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst) \n\u00b6\n\n\nTakes a new array of body statements in the process of construction in \"new_body\" and takes a parfor to add to that\nbody.  This parfor is in the nested (parfor code is in the parfor node itself) temporary form we use for fusion although \npre-statements and post-statements are already elevated by this point.  We replace this nested form with a non-nested\nform where we have a parfor_start and parfor_end to delineate the parfor code.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-flatten.jl:94\n\n\n\n\n\n\nfrom_assertEqShape(node::Expr,  state) \n\u00b6\n\n\nCreate array equivalences from an assertEqShape AST node.\nThere are two arrays in the args to assertEqShape.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2604\n\n\n\n\n\n\nfrom_assignment(lhs,  rhs,  depth,  state) \n\u00b6\n\n\nProcess an assignment expression.\nStarts by recurisvely processing the right-hand side of the assignment.\nEliminates the assignment of a=b if a is dead afterwards and b has no side effects.\n    Does some array equivalence class work which may be redundant given that we now run a separate equivalence class pass so consider removing that part of this code.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2685\n\n\n\n\n\n\nfrom_call(ast::Array{Any, 1},  depth,  state) \n\u00b6\n\n\nProcess a call AST node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2807\n\n\n\n\n\n\nfrom_expr(ast::Expr,  depth,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level) \n\u00b6\n\n\nThe main ParallelIR function for processing some node in the AST.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4546\n\n\n\n\n\n\nfrom_lambda(lambda::Expr,  depth,  state) \n\u00b6\n\n\nProcess a :lambda Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:946\n\n\n\n\n\n\nfrom_root(function_name,  ast::Expr) \n\u00b6\n\n\nThe main ENTRY point into ParallelIR.\n1) Do liveness analysis.\n2) Convert mmap to mmap! where possible.\n3) Do some code rearrangement (e.g., hoisting) to maximize later fusion.\n4) Create array equivalence classes within the function.\n5) Rearrange statements within a basic block to push domain operations to the bottom so more fusion.\n6) Call the main from_expr to process the AST for the function.  This will\na) Lower domain IR to parallel IR AST nodes.\nb) Fuse parallel IR nodes where possible.\nc) Convert to task IR nodes if task mode enabled.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4208\n\n\n\n\n\n\nfullyLowerAlias(dict::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  input::Union{GenSym, Symbol}) \n\u00b6\n\n\nGiven an \"input\" Symbol, use that Symbol as key to a dictionary.  While such a Symbol is present\nin the dictionary replace it with the corresponding value from the dict.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1829\n\n\n\n\n\n\nfuse(body,  body_index,  cur,  state) \n\u00b6\n\n\nTest whether we can fuse the two most recent parfor statements and if so to perform that fusion.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1871\n\n\n\n\n\n\ngenerate_instr_count(function_name,  signature) \n\u00b6\n\n\nTry to figure out the instruction count for a given call.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:398\n\n\n\n\n\n\ngetArrayElemType(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturns the element type of an Array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:611\n\n\n\n\n\n\ngetArrayElemType(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturns the element type of an Array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:604\n\n\n\n\n\n\ngetArrayElemType(atyp::DataType) \n\u00b6\n\n\nReturns the element type of an Array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:591\n\n\n\n\n\n\ngetArrayNumDims(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturn the number of dimensions of an Array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:628\n\n\n\n\n\n\ngetArrayNumDims(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturn the number of dimensions of an Array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:619\n\n\n\n\n\n\ngetConstDims(num_dim_inputs,  inputInfo::ParallelAccelerator.ParallelIR.InputInfo) \n\u00b6\n\n\nIn the case where a domain IR operation on an array creates a lower dimensional output,\nthe indexing expression needs the expression that selects those constant trailing dimensions\nthat are being dropped.  This function returns an array of those constant expressions for\nthe trailing dimensions.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:766\n\n\n\n\n\n\ngetCorrelation(sng::Union{GenSym, Symbol, SymbolNode},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nGet the equivalence class of a domain IR input in inputInfo.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1747\n\n\n\n\n\n\ngetFirstArrayLens(prestatements,  num_dims) \n\u00b6\n\n\nGet the variable which holds the length of the first input array to a parfor.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1438\n\n\n\n\n\n\ngetIO(stmt_ids,  bb_statements) \n\u00b6\n\n\nGiven a set of statement IDs and liveness information for the statements of the function, determine\nwhich symbols are needed at input and which symbols are purely local to the functio.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:840\n\n\n\n\n\n\ngetInputSet(node::ParallelAccelerator.ParallelIR.PIRParForAst) \n\u00b6\n\n\nReturns a Set with all the arrays read by this parfor.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1106\n\n\n\n\n\n\ngetLhsFromAssignment(assignment) \n\u00b6\n\n\nGet the left-hand side of an assignment expression.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1077\n\n\n\n\n\n\ngetLhsOutputSet(lhs,  assignment) \n\u00b6\n\n\nGet the real outputs of an assignment statement.\nIf the assignment expression is normal then the output is just the left-hand side.\nIf the assignment expression is augmented with a FusionSentinel then the real outputs\nare the 4+ arguments to the expression.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1121\n\n\n\n\n\n\ngetMaxLabel(max_label,  stmts::Array{Any, 1}) \n\u00b6\n\n\nScan the body of a function in \"stmts\" and return the max label in a LabelNode AST seen in the body.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4026\n\n\n\n\n\n\ngetNonBlock(head_preds,  back_edge) \n\u00b6\n\n\nFind the basic block before the entry to a loop.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:5\n\n\n\n\n\n\ngetOrAddArrayCorrelation(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturn a correlation set for an array.  If the array was not previously added then add it and return it.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:802\n\n\n\n\n\n\ngetOrAddRangeCorrelation(ranges::Array{ParallelAccelerator.ParallelIR.RangeExprs, 1},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nGets (or adds if absent) the range correlation for the given array of RangeExprs.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:813\n\n\n\n\n\n\ngetOrAddSymbolCorrelation(array::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state,  dims::Array{Union{GenSym, Symbol}, 1}) \n\u00b6\n\n\nA new array is being created with an explicit size specification in dims.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:832\n\n\n\n\n\n\ngetParforCorrelation(parfor,  state) \n\u00b6\n\n\nGet the equivalence class of the first array who length is extracted in the pre-statements of the specified \"parfor\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1740\n\n\n\n\n\n\ngetParforNode(node) \n\u00b6\n\n\nGet the parfor object from either a bare parfor or one part of an assignment.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1059\n\n\n\n\n\n\ngetPrivateSet(body::Array{Any, 1}) \n\u00b6\n\n\nGo through the body of a parfor and collect those Symbols, GenSyms, etc. that are assigned to within the parfor except reduction variables.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:898\n\n\n\n\n\n\ngetPrivateSetInner(x::Expr,  state::Set{Union{GenSym, Symbol, SymbolNode}},  top_level_number::Int64,  is_top_level::Bool,  read::Bool) \n\u00b6\n\n\nThe AstWalk callback function for getPrivateSet.\nFor each AST in a parfor body, if the node is an assignment or loop head node then add the written entity to the state.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:868\n\n\n\n\n\n\ngetRhsFromAssignment(assignment) \n\u00b6\n\n\nGet the right-hand side of an assignment expression.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1070\n\n\n\n\n\n\ngetSName(ssn::Symbol) \n\u00b6\n\n\nGet the name of a symbol whether the input is a Symbol or SymbolNode or :(::) Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2237\n\n\n\n\n\n\nget_one(ast::Array{T, N}) \n\u00b6\n\n\nTake something returned from AstWalk and assert it should be an array but in this\ncontext that the array should also be of length 1 and then return that single element.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4700\n\n\n\n\n\n\nget_unique_num() \n\u00b6\n\n\nIf we need to generate a name and make sure it is unique then include an monotonically increasing number.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:853\n\n\n\n\n\n\nhasNoSideEffects(node::Union{GenSym, LambdaStaticData, Number, Symbol, SymbolNode}) \n\u00b6\n\n\nSometimes statements we exist in the AST of the form a=Expr where a is a Symbol that isn't live past the assignment\nand we'd like to eliminate the whole assignment statement but we have to know that the right-hand side has no\nside effects before we can do that.  This function says whether the right-hand side passed into it has side effects\nor not.  Several common function calls that otherwise we wouldn't know are safe are explicitly checked for.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2547\n\n\n\n\n\n\nhasSymbol(ssn::Symbol) \n\u00b6\n\n\nReturns true if the incoming AST node can be interpreted as a Symbol.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2218\n\n\n\n\n\n\nhoistAllocation(ast::Array{Any, 1},  lives,  domLoop::CompilerTools.Loops.DomLoops,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nTry to hoist allocations outside the loop if possible.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3698\n\n\n\n\n\n\ninsert_no_deps_beginning(node,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nWorks with remove_no_deps below to move statements with no dependencies to the beginning of the AST.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3055\n\n\n\n\n\n\nintermediate_from_exprs(ast::Array{Any, 1},  depth,  state) \n\u00b6\n\n\nProcess an array of expressions that aren't from a :body Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2288\n\n\n\n\n\n\nisArrayType(typ) \n\u00b6\n\n\nReturns true if the incoming type in \"typ\" is an array type.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:584\n\n\n\n\n\n\nisArrayType(x::SymbolNode) \n\u00b6\n\n\nReturns true if a given SymbolNode \"x\" is an Array type.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2316\n\n\n\n\n\n\nisArrayref(x) \n\u00b6\n\n\nIs a node an arrayref node?\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1356\n\n\n\n\n\n\nisArrayrefCall(x::Expr) \n\u00b6\n\n\nIs a node a call to arrayref.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1377\n\n\n\n\n\n\nisArrayset(x) \n\u00b6\n\n\nIs a node an arrayset node?\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1346\n\n\n\n\n\n\nisArraysetCall(x::Expr) \n\u00b6\n\n\nIs a node a call to arrayset.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1366\n\n\n\n\n\n\nisAssignmentNode(node::Expr) \n\u00b6\n\n\nIs a node an assignment expression node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:987\n\n\n\n\n\n\nisBareParfor(node::Expr) \n\u00b6\n\n\nIs this a parfor node not part of an assignment statement.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1009\n\n\n\n\n\n\nisDomainNode(ast::Expr) \n\u00b6\n\n\nReturns true if the given \"ast\" node is a DomainIR operation.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3882\n\n\n\n\n\n\nisFusionAssignment(x::Expr) \n\u00b6\n\n\nCheck if an assignement is a fusion assignment.\n    In regular assignments, there are only two args, the left and right hand sides.\n    In fusion assignments, we introduce a third arg that is marked by an object of FusionSentinel type.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1700\n\n\n\n\n\n\nisLoopheadNode(node::Expr) \n\u00b6\n\n\nIs a node a loophead expression node (a form of assignment).\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:998\n\n\n\n\n\n\nisParforAssignmentNode(node::Expr) \n\u00b6\n\n\nIs a node an assignment expression with a parfor node as the right-hand side.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1033\n\n\n\n\n\n\nisSymbolsUsed(vars,  top_level_numbers::Array{Int64, 1},  state) \n\u00b6\n\n\nReturns true if any variable in the collection \"vars\" is used in any statement whose top level number is in \"top_level_numbers\".\n    We use expr_state \"state\" to get the block liveness information from which we use \"def\" and \"use\" to determine if a variable\n        usage is present.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1716\n\n\n\n\n\n\nis_eliminated_arraylen(x::Expr) \n\u00b6\n\n\nReturns true if the input node is an assignment node where the right-hand side is a call to arraysize.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1589\n\n\n\n\n\n\nisbitstuple(a::Tuple) \n\u00b6\n\n\nReturns true if input \"a\" is a tuple and each element of the tuple of isbits type.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4493\n\n\n\n\n\n\niterations_equals_inputs(node::ParallelAccelerator.ParallelIR.PIRParForAst) \n\u00b6\n\n\nReturns true if the domain operation mapped to this parfor has the property that the iteration space\nis identical to the dimenions of the inputs.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1086\n\n\n\n\n\n\nlambdaFromDomainLambda(domain_lambda,  dl_inputs) \n\u00b6\n\n\nForm a Julia :lambda Expr from a DomainLambda.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4038\n\n\n\n\n\n\nmakePrivateParfor(var_name::Symbol,  state) \n\u00b6\n\n\nTakes an existing variable whose name is in \"var_name\" and adds the descriptor flag ISPRIVATEPARFORLOOP to declare the\nvariable to be parfor loop private and eventually go in an OMP private clause.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:659\n\n\n\n\n\n\nmakeTasks(start_index,  stop_index,  body,  bb_live_info,  state,  task_graph_mode) \n\u00b6\n\n\nFor a given start and stop index in some body and liveness information, form a set of tasks.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:759\n\n\n\n\n\n\nmaxFusion(bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nFor every basic block, try to push domain IR statements down and non-domain IR statements up so that domain nodes\nare next to each other and can be fused.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3926\n\n\n\n\n\n\nmergeLambdaIntoOuterState(state,  inner_lambda::Expr) \n\u00b6\n\n\nPull the information from the inner lambda into the outer lambda.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1218\n\n\n\n\n\n\nmerge_correlations(state,  unchanging,  eliminate) \n\u00b6\n\n\nIf we somehow determine that two sets of correlations are actually the same length then merge one into the other.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:764\n\n\n\n\n\n\nmk_alloc_array_1d_expr(elem_type,  atype,  length) \n\u00b6\n\n\nReturn an expression that allocates and initializes a 1D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and a \"length\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:496\n\n\n\n\n\n\nmk_alloc_array_2d_expr(elem_type,  atype,  length1,  length2) \n\u00b6\n\n\nReturn an expression that allocates and initializes a 2D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and two dimensions of length in \"length1\" and \"length2\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:534\n\n\n\n\n\n\nmk_alloc_array_3d_expr(elem_type,  atype,  length1,  length2,  length3) \n\u00b6\n\n\nReturn an expression that allocates and initializes a 3D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and two dimensions of length in \"length1\" and \"length2\" and \"length3\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:560\n\n\n\n\n\n\nmk_arraylen_expr(x::ParallelAccelerator.ParallelIR.InputInfo,  dim::Int64) \n\u00b6\n\n\nCreate an expression whose value is the length of the input array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:447\n\n\n\n\n\n\nmk_arraylen_expr(x::Union{GenSym, Symbol, SymbolNode},  dim::Int64) \n\u00b6\n\n\nCreate an expression whose value is the length of the input array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:440\n\n\n\n\n\n\nmk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturn an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:54\n\n\n\n\n\n\nmk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1}) \n\u00b6\n\n\nReturn an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:54\n\n\n\n\n\n\nmk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1}) \n\u00b6\n\n\nReturn an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:54\n\n\n\n\n\n\nmk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturn a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:85\n\n\n\n\n\n\nmk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1}) \n\u00b6\n\n\nReturn a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:85\n\n\n\n\n\n\nmk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1}) \n\u00b6\n\n\nReturn a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:85\n\n\n\n\n\n\nmk_assignment_expr(lhs::Union{GenSym, Symbol, SymbolNode},  rhs,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nCreate an assignment expression AST node given a left and right-hand side.\nThe left-hand side has to be a symbol node from which we extract the type so as to type the new Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:353\n\n\n\n\n\n\nmk_colon_expr(start_expr,  skip_expr,  end_expr) \n\u00b6\n\n\nReturns an expression to construct a :colon object that contains the start of a range, the end and the skip expression.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:878\n\n\n\n\n\n\nmk_convert(new_type,  ex) \n\u00b6\n\n\nReturns an expression that convert \"ex\" into a another type \"new_type\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:473\n\n\n\n\n\n\nmk_gotoifnot_expr(cond,  goto_label) \n\u00b6\n\n\nReturns a :gotoifnot Expr given a condition \"cond\" and a label \"goto_label\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:900\n\n\n\n\n\n\nmk_next_expr(colon_sym,  start_sym) \n\u00b6\n\n\nReturns a :next call Expr that gets the next element of an iteration range from a :colon object.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:892\n\n\n\n\n\n\nmk_parallelir_ref(sym) \n\u00b6\n\n\nCreate an expression that references something inside ParallelIR.\nIn other words, returns an expression the equivalent of ParallelAccelerator.ParallelIR.sym where sym is an input argument to this function.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:465\n\n\n\n\n\n\nmk_parallelir_ref(sym,  ref_type) \n\u00b6\n\n\nCreate an expression that references something inside ParallelIR.\nIn other words, returns an expression the equivalent of ParallelAccelerator.ParallelIR.sym where sym is an input argument to this function.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:465\n\n\n\n\n\n\nmk_parfor_args_from_mmap!(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  with_indices,  domain_oprs,  state) \n\u00b6\n\n\nThe main routine that converts a mmap! AST node to a parfor AST node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:498\n\n\n\n\n\n\nmk_parfor_args_from_mmap(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  domain_oprs,  state) \n\u00b6\n\n\nThe main routine that converts a mmap AST node to a parfor AST node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:789\n\n\n\n\n\n\nmk_parfor_args_from_reduce(input_args::Array{Any, 1},  state) \n\u00b6\n\n\nThe main routine that converts a reduce AST node to a parfor AST node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:119\n\n\n\n\n\n\nmk_return_expr(outs) \n\u00b6\n\n\nGiven an array of outputs in \"outs\", form a return expression.\nIf there is only one out then the args of :return is just that expression.\nIf there are multiple outs then form a tuple of them and that tuple goes in :return args.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:338\n\n\n\n\n\n\nmk_start_expr(colon_sym) \n\u00b6\n\n\nReturns an expression to get the start of an iteration range from a :colon object.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:885\n\n\n\n\n\n\nmk_svec_expr(parts...) \n\u00b6\n\n\nMake a svec expression.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:487\n\n\n\n\n\n\nmk_tuple_expr(tuple_fields,  typ) \n\u00b6\n\n\nReturn an expression which creates a tuple.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1151\n\n\n\n\n\n\nmk_tupleref_expr(tuple_var,  index,  typ) \n\u00b6\n\n\nCreate an expression which returns the index'th element of the tuple whose name is contained in tuple_var.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:480\n\n\n\n\n\n\nmk_untyped_assignment(lhs,  rhs) \n\u00b6\n\n\nOnly used to create fake expression to force lhs to be seen as written rather than read.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:370\n\n\n\n\n\n\nmmapInline(ast::Expr,  lives,  uniqSet) \n\u00b6\n\n\nIf a definition of a mmap is only used once and not aliased, it can be inlined into its\n\n\nuse side as long as its dependencies have not been changed.\n\n\nFIXME: is the implementation still correct when branches are present?\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3621\n\n\n\n\n\n\nmmapToMmap!(ast,  lives,  uniqSet) \n\u00b6\n\n\nPerforms the mmap to mmap! phase.\nIf the arguments of a mmap dies aftewards, and is not aliased, then\nwe can safely change the mmap to mmap!.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3764\n\n\n\n\n\n\nmustRemainLastStatementInBlock(node::GotoNode) \n\u00b6\n\n\nReturns true if the given AST \"node\" must remain the last statement in a basic block.\nThis is true if the node is a GotoNode or a :gotoifnot Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3910\n\n\n\n\n\n\nnameToSymbolNode(name::Symbol,  sym_to_type) \n\u00b6\n\n\nForms a SymbolNode given a symbol in \"name\" and get the type of that symbol from the incoming dictionary \"sym_to_type\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1159\n\n\n\n\n\n\nnested_function_exprs(max_label,  domain_lambda,  dl_inputs) \n\u00b6\n\n\nA routine similar to the main parallel IR entry put but designed to process the lambda part of\ndomain IR AST nodes.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4067\n\n\n\n\n\n\nnext_label(state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturns the next usable label for the current function.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:738\n\n\n\n\n\n\noneIfOnly(x) \n\u00b6\n\n\nReturns a single element of an array if there is only one or the array otherwise.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1860\n\n\n\n\n\n\nparforToTask(parfor_index,  bb_statements,  body,  state) \n\u00b6\n\n\nGiven a parfor statement index in \"parfor_index\" in the \"body\"'s statements, create a TaskInfo node for this parfor.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:1190\n\n\n\n\n\n\npirPrintDl(dbg_level,  dl) \n\u00b6\n\n\nDebug print the parts of a DomainLambda.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4017\n\n\n\n\n\n\npir_alias_cb(ast::Expr,  state,  cbdata) \n\u00b6\n\n\nAn AliasAnalysis callback (similar to LivenessAnalysis callback) that handles ParallelIR introduced AST node types.\nFor each ParallelIR specific node type, form an array of expressions that AliasAnalysis\n    can analyze to reflect the aliases of the given AST node.\n    If we read a symbol it is sufficient to just return that symbol as one of the expressions.\n    If we write a symbol, then form a fake mk_assignment_expr just to get liveness to realize the symbol is written.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4884\n\n\n\n\n\n\npir_live_cb(ast::Expr,  cbdata::ANY) \n\u00b6\n\n\nA LivenessAnalysis callback that handles ParallelIR introduced AST node types.\nFor each ParallelIR specific node type, form an array of expressions that liveness\ncan analysis to reflect the read/write set of the given AST node.\nIf we read a symbol it is sufficient to just return that symbol as one of the expressions.\nIf we write a symbol, then form a fake mk_assignment_expr just to get liveness to realize the symbol is written.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2412\n\n\n\n\n\n\npir_live_cb_def(x) \n\u00b6\n\n\nJust call the AST walker for symbol for parallel IR nodes with no state.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:939\n\n\n\n\n\n\nprintBody(dlvl,  body::Array{Any, 1}) \n\u00b6\n\n\nPretty print the args part of the \"body\" of a :lambda Expr at a given debug level in \"dlvl\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2327\n\n\n\n\n\n\nprintLambda(dlvl,  node::Expr) \n\u00b6\n\n\nPretty print a :lambda Expr in \"node\" at a given debug level in \"dlvl\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2340\n\n\n\n\n\n\nprocessAndUpdateBody(lambda::Expr,  f::Function,  state) \n\u00b6\n\n\nApply a function \"f\" that takes the :body from the :lambda and returns a new :body that is stored back into the :lambda.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3295\n\n\n\n\n\n\nrangeSize(start,  skip,  last) \n\u00b6\n\n\nCompute size of a range.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:432\n\n\n\n\n\n\nrangeToRangeData(range::Expr,  pre_offsets::Array{Expr, 1},  arr,  range_num::Int64,  state) \n\u00b6\n\n\nConvert a :range Expr introduced by Domain IR into a Parallel IR data structure RangeData.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:354\n\n\n\n\n\n\nrecreateLoops(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state,  newLambdaInfo) \n\u00b6\n\n\nIn threads mode, we can't have parfor_start and parfor_end in the code since Julia has to compile the code itself and so\nwe have to reconstruct a loop infrastructure based on the parfor's loop nest information.  This function takes a parfor\nand outputs that parfor to the new function body as regular Julia loops.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:1156\n\n\n\n\n\n\nrecreateLoopsInternal(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  loop_nest_level,  next_available_label,  state,  newLambdaInfo) \n\u00b6\n\n\nThis is a recursive routine to reconstruct a regular Julia loop nest from the loop nests described in PIRParForAst.\nOne call of this routine handles one level of the loop nest.\nIf the incoming loop nest level is more than the number of loops nests in the parfor then that is the spot to\ninsert the body of the parfor into the new function body in \"new_body\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:1020\n\n\n\n\n\n\nrememberTypeForSym(sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  sym::Union{GenSym, Symbol},  typ::DataType) \n\u00b6\n\n\nAdd to the map of symbol names to types.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1679\n\n\n\n\n\n\nremoveAssertEqShape(args::Array{Any, 1},  state) \n\u00b6\n\n\nImplements one of the main ParallelIR passes to remove assertEqShape AST nodes from the body if they are statically known to be in the same equivalence class.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2588\n\n\n\n\n\n\nremoveNothingStmts(args::Array{Any, 1},  state) \n\u00b6\n\n\nEmpty statements can be added to the AST by some passes in ParallelIR.\nThis pass over the statements of the :body excludes such \"nothing\" statements from the new :body.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3306\n\n\n\n\n\n\nremove_dead(node,  data::ParallelAccelerator.ParallelIR.RemoveDeadState,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAn AstWalk callback that uses liveness information in \"data\" to remove dead stores.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2988\n\n\n\n\n\n\nremove_extra_allocs(ast) \n\u00b6\n\n\nremoves extra allocations\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4363\n\n\n\n\n\n\nremove_no_deps(node::ANY,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nThis routine gathers up nodes that do not use\n\n\nany variable and removes them from the AST into top_level_no_deps.  This works in conjunction with\n\n\ninsert_no_deps_beginning above to move these statements with no dependencies to the beginning of the AST\n\n\nwhere they can't prevent fusion.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3071\n\n\n\n\n\n\nreplaceParforWithDict(parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  gensym_map) \n\u00b6\n\n\nNot currently used but might need it at some point.\nSearch a whole PIRParForAst object and replace one SymAllGen with another.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:216\n\n\n\n\n\n\nrun_as_task() \n\u00b6\n\n\nReturn true if run_as_task_decrement would return true but don't update the run_as_tasks count.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:229\n\n\n\n\n\n\nrun_as_task_decrement() \n\u00b6\n\n\nIf run_as_tasks is positive then convert this parfor to a task and decrement the count so that only the\noriginal number run_as_tasks if the number of tasks created.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:215\n\n\n\n\n\n\nselectToRangeData(select::Expr,  pre_offsets::Array{Expr, 1},  state) \n\u00b6\n\n\nConvert the range(s) part of a :select Expr introduced by Domain IR into an array of Parallel IR data structures RangeData.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:371\n\n\n\n\n\n\nseqTask(body_indices,  bb_statements,  body,  state) \n\u00b6\n\n\nForm a task out of a range of sequential statements.\nThis is not currently implemented.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:1538\n\n\n\n\n\n\nshow(io::IO,  pnode::ParallelAccelerator.ParallelIR.PIRParForAst) \n\u00b6\n\n\nOverload of Base.show to pretty print for parfor AST nodes.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:273\n\n\n\n\n\n\nsimpleIndex(dict) \n\u00b6\n\n\nReturns true if all array references use singular index variables and nothing more complicated involving,\nfor example, addition or subtraction by a constant.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:668\n\n\n\n\n\n\nsub_arraylen_walk(x::Expr,  replacement,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAstWalk callback that does the work of substitute_arraylen on a node-by-node basis.\nreplacement is an array containing the length of the dimensions of the arrays a part of this parfor.\nIf we see a call to create an array, replace the length params with those in the common set in \"replacement\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1620\n\n\n\n\n\n\nsub_arrayset_walk(x::Expr,  cbd,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAstWalk callback that does the work of substitute_arrayset on a node-by-node basis.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1388\n\n\n\n\n\n\nsub_cur_body_walk(x::Expr,  cbd::ParallelAccelerator.ParallelIR.cur_body_data,  top_level_number::Int64,  is_top_level::Bool,  read::Bool) \n\u00b6\n\n\nAstWalk callback that does the work of substitute_cur_body on a node-by-node basis.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1471\n\n\n\n\n\n\nsubstitute_arraylen(x,  replacement) \n\u00b6\n\n\nreplacement is an array containing the length of the dimensions of the arrays a part of this parfor.\nIf we see a call to create an array, replace the length params with those in the common set in \"replacement\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1652\n\n\n\n\n\n\nsubstitute_arrayset(x,  arrays_set_in_cur_body,  output_items_with_aliases) \n\u00b6\n\n\nModify the body of a parfor.\ntemp_map holds a map of array names whose arraysets should be turned into a mapped variable instead of the arrayset. a[i] = b. a=\nc. becomes c = b\nmap_for_non_eliminated holds arrays for which we need to add a variable to save the value but we can't eiminate the arrayset. a[i] = b. a=\nc. becomes c = a[i] = b\n    map_drop_arrayset drops the arrayset without replacing with a variable.  This is because a variable was previously added here with a map_for_non_eliminated case.\n    a[i] = b. becomes b\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1433\n\n\n\n\n\n\nsubstitute_cur_body(x,  temp_map::Dict{Union{GenSym, Symbol}, Union{GenSym, SymbolNode}},  index_map::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  arrays_set_in_cur_body::Set{Union{GenSym, Symbol}},  replace_array_name_in_arrayset::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nMake changes to the second parfor body in the process of parfor fusion.\ntemp_map holds array names for which arrayrefs should be converted to a variable.  a[i].  a=\nb. becomes b\n    index_map holds maps between index variables.  The second parfor is modified to use the index variable of the first parfor.\n    arrays_set_in_cur_body           # Used as output.  Collects the arrays set in the current body.\n    replace_array_name_in_arrayset   # Map from one array to another.  Replace first array with second when used in arrayset context.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1575\n\n\n\n\n\n\ntaskableParfor(node) \n\u00b6\n\n\nReturns true if the \"node\" is a parfor and the task limit hasn't been exceeded.\nAlso controls whether stencils or reduction can become tasks.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:278\n\n\n\n\n\n\ntoSNGen(x::Symbol,  typ) \n\u00b6\n\n\nIf we have the type, convert a Symbol to SymbolNode.\nIf we have a GenSym then we have to keep it.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2788\n\n\n\n\n\n\ntoSymGen(x::Symbol) \n\u00b6\n\n\nIn various places we need a SymGen type which is the union of Symbol and GenSym.\nThis function takes a Symbol, SymbolNode, or GenSym and return either a Symbol or GenSym.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:699\n\n\n\n\n\n\ntoSymNodeGen(x::Symbol,  typ) \n\u00b6\n\n\nForm a SymbolNode with the given typ if possible or a GenSym if that is what is passed in.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:718\n\n\n\n\n\n\nuncompressed_ast(l::LambdaStaticData) \n\u00b6\n\n\nConvert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:914\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.CopyPropagateState \n\u00b6\n\n\nState to aide in the copy propagation phase.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2831\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.DirWalk \n\u00b6\n\n\nWraps the callback and opaque data passed from the user of ParallelIR's AstWalk.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4707\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.DomainOperation \n\u00b6\n\n\nHolds information about domain operations part of a parfor node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:95\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.EquivalenceClasses \n\u00b6\n\n\nHolds a dictionary from an array symbol to an integer corresponding to an equivalence class.\nAll array symbol in the same equivalence class are known to have the same shape.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:105\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.FusionSentinel \n\u00b6\n\n\nJust used to hold a spot in an array to indicate the this is a special assignment expression with embedded real array output names from a fusion.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1690\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.InProgress \n\u00b6\n\n\nA sentinel in the instruction count estimation process.\nBefore recursively processing a call, we add a sentinel for that function so that if we see that\nsentinel later we know we've tried to recursively process it and so can bail out by setting\nfully_analyzed to false.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:346\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.InputInfo \n\u00b6\n\n\nType used by mk_parfor_args... functions to hold information about input arrays.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:391\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.InsertTaskNode \n\u00b6\n\n\nA data type containing the information that CGen uses to generate a call to pert_insert_divisible_task.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:197\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.PIRParForStartEnd \n\u00b6\n\n\nAfter lowering, it is necessary to make the parfor body top-level statements so that basic blocks\ncan be correctly identified and labels correctly found.  There is a phase in parallel IR where we \ntake a PIRParForAst node and split it into a parfor_start node followed by the body as top-level\nstatements followed by parfor_end (also a top-level statement).\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:238\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.RangeData \n\u00b6\n\n\nHolds the information from one Domain IR :range Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:377\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.RemoveDeadState \n\u00b6\n\n\nHolds liveness information for the remove_dead AstWalk phase.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2981\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.RemoveNoDepsState \n\u00b6\n\n\nState for the remove_no_deps and insert_no_deps_beginning phases.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3041\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.ReplacedRegion \n\u00b6\n\n\nStore information about a section of a body that will be translated into a task.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:21\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.RhsDead \n\u00b6\n\n\nMarks an assignment statement where the left-hand side can take over the storage from the right-hand side.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:577\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.StatementWithDeps \n\u00b6\n\n\nType for dependence graph creation and topological sorting.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3848\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.TaskInfo \n\u00b6\n\n\nStructure for storing information about task formation.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:36\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.cur_body_data \n\u00b6\n\n\nHolds the data for substitute_cur_body AST walk.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1460\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.cuw_state \n\u00b6\n\n\nJust to hold the \"found\" Bool that says whether a unsafe variant was replaced with a regular version.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:907\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.expr_state \n\u00b6\n\n\nState passed around while converting an AST from domain to parallel IR.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:245\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.pir_arg_metadata \n\u00b6\n\n\nA Julia representation of the argument metadata that will be passed to the runtime.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:157\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.pir_array_access_desc \n\u00b6\n\n\nDescribes an array.\nrow_major is true if the array is stored in row major format.\ndim_info describes which portion of the array is accessed for a given point in the iteration space.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:111\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.pir_grain_size \n\u00b6\n\n\nA Julia representation of the grain size that will be passed to the runtime.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:178\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.pir_range \n\u00b6\n\n\nTranslated to pert_range_Nd_t in the task runtime.\nThis represents an iteration space.\ndim is the number of dimensions in the iteration space.\nlower_bounds contains the lower bound of the iteration space in each dimension.\nupper_bounds contains the upper bound of the iteration space in each dimension.\nlower_bounds and upper_bounds can be expressions.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:56\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.pir_range_actual \n\u00b6\n\n\nSimilar to pir_range but used in circumstances where the expressions must have already been evaluated.\nTherefore the arrays are typed as Int64.\nUp to 3 dimensional iteration space constructors are supported to make it easier to do code generation later.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:70\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.sub_arrayset_data \n\u00b6\n\n\nHolds data for modifying arrayset calls.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1338", 
            "title": "ParallelAccelerator.ParallelIR"
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/#parallelacceleratorparallelir", 
            "text": "", 
            "title": "ParallelAccelerator.ParallelIR"
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/#exported", 
            "text": "AstWalk(ast,  callback,  cbdata)  \u00b6  ParallelIR version of AstWalk.\nInvokes the DomainIR version of AstWalk and provides the parallel IR AstWalk callback AstWalkCallback.  Parallel IR AstWalk calls Domain IR AstWalk which in turn calls CompilerTools.AstWalker.AstWalk.\nFor each AST node, CompilerTools.AstWalker.AstWalk calls Domain IR callback to give it a chance to handle the node if it is a Domain IR node.\nLikewise, Domain IR callback first calls Parallel IR callback to give it a chance to handle Parallel IR nodes.\nThe Parallel IR callback similarly first calls the user-level callback to give it a chance to process the node.\nIf a callback returns \"nothing\" it means it didn't modify that node and that the previous code should process it.\nThe Parallel IR callback will return \"nothing\" if the node isn't a Parallel IR node.\nThe Domain IR callback will return \"nothing\" if the node isn't a Domain IR node.  source:  ParallelAccelerator/src/parallel-ir.jl:4876    PIRInplace(x)  \u00b6  If set to non-zero, perform the phase where non-inplace maps are converted to inplace maps to reduce allocations.  source:  ParallelAccelerator/src/parallel-ir.jl:3816    PIRNumSimplify(x)  \u00b6  Specify the number of passes over the AST that do things like hoisting and other rearranging to maximize fusion.  source:  ParallelAccelerator/src/parallel-ir.jl:1672    PIRRunAsTasks(x)  \u00b6  Debugging feature to specify the number of tasks to create and to stop thereafter.  source:  ParallelAccelerator/src/parallel-ir.jl:1853    PIRSetFuseLimit(x)  \u00b6  Control how many parfor can be fused for testing purposes.\n    -1 means fuse all possible parfors.\n    0  means don't fuse any parfors.\n    1+ means fuse the specified number of parfors but then stop fusing beyond that.  source:  ParallelAccelerator/src/parallel-ir.jl:1667    PIRShortcutArrayAssignment(x)  \u00b6  Enables an experimental mode where if there is a statement a = b and they are arrays and b is not live-out then \nuse a special assignment node like a move assignment in C++.  source:  ParallelAccelerator/src/parallel-ir.jl:3842    PIRTaskGraphMode(x)  \u00b6  Control how blocks of code are made into tasks.  source:  ParallelAccelerator/src/parallel-ir-task.jl:589    from_exprs(ast::Array{Any, 1},  depth,  state)  \u00b6  Process an array of expressions.\nDifferentiate between top-level arrays of statements and arrays of expression that may occur elsewhere than the :body Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:2274    ParallelAccelerator.ParallelIR.PIRLoopNest  \u00b6  Holds the information about a loop in a parfor node.  source:  ParallelAccelerator/src/parallel-ir.jl:76    ParallelAccelerator.ParallelIR.PIRParForAst  \u00b6  The parfor AST node type.\nWhile we are lowering domain IR to parfors and fusing we use this representation because it\nmakes it easier to associate related statements before and after the loop to the loop itself.  source:  ParallelAccelerator/src/parallel-ir.jl:174    ParallelAccelerator.ParallelIR.PIRReduction  \u00b6  Holds the information about a reduction in a parfor node.  source:  ParallelAccelerator/src/parallel-ir.jl:86", 
            "title": "Exported"
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/#internal", 
            "text": "AstWalkCallback(x::Expr,  dw::ParallelAccelerator.ParallelIR.DirWalk,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)  \u00b6  AstWalk callback that handles ParallelIR AST node types.  source:  ParallelAccelerator/src/parallel-ir.jl:4724    EquivalenceClassesAdd(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  sym::Symbol)  \u00b6  Add a symbol as part of a new equivalence class if the symbol wasn't already in an equivalence class.\nReturn the equivalence class for the symbol.  source:  ParallelAccelerator/src/parallel-ir.jl:139    EquivalenceClassesClear(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses)  \u00b6  Clear an equivalence class.  source:  ParallelAccelerator/src/parallel-ir.jl:153    EquivalenceClassesMerge(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  merge_to::Symbol,  merge_from::Symbol)  \u00b6  At some point we realize that two arrays must have the same dimensions but up until that point\nwe might not have known that.  In which case they will start in different equivalence classes,\nmerge_to and merge_from, but need to be combined into one equivalence class.\nGo through the equivalence class dictionary and for any symbol belonging to the merge_from\nequivalence class, change it to now belong to the merge_to equivalence class.  source:  ParallelAccelerator/src/parallel-ir.jl:123    PIRBbReorder(x)  \u00b6  If set to non-zero, perform the bubble-sort like reordering phase to coalesce more parfor nodes together for fusion.  source:  ParallelAccelerator/src/parallel-ir.jl:3832    PIRHoistAllocation(x)  \u00b6  If set to non-zero, perform the rearrangement phase that tries to moves alllocations outside of loops.  source:  ParallelAccelerator/src/parallel-ir.jl:3824    TypedExpr(typ,  rest...)  \u00b6  This should pretty always be used instead of Expr(...) to form an expression as it forces the typ to be provided.  source:  ParallelAccelerator/src/parallel-ir.jl:67    addUnknownArray(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Given an array whose name is in \"x\", allocate a new equivalence class for this array.  source:  ParallelAccelerator/src/parallel-ir.jl:746    addUnknownRange(x::Array{Any, 1},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Given an array of RangeExprs describing loop nest ranges, allocate a new equivalence class for this range.  source:  ParallelAccelerator/src/parallel-ir.jl:755    add_merge_correlations(old_sym::Union{GenSym, Symbol},  new_sym::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  If we somehow determine that two arrays must be the same length then \nget the equivalence classes for the two arrays and merge those equivalence classes together.  source:  ParallelAccelerator/src/parallel-ir.jl:792    asArray(x)  \u00b6  Return one element array with element x.  source:  ParallelAccelerator/src/parallel-ir.jl:4715    augment_sn(dim::Int64,  index_vars,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})  \u00b6  Make sure the index parameters to arrayref or arrayset are Int64 or SymbolNode.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:29    call_instruction_count(args,  state::ParallelAccelerator.ParallelIR.eic_state,  debug_level)  \u00b6  Generate an instruction count estimate for a call instruction.  source:  ParallelAccelerator/src/parallel-ir-task.jl:352    checkAndAddSymbolCorrelation(lhs::Union{GenSym, Symbol},  state,  dim_array)  \u00b6  Make sure all the dimensions are SymbolNodes.\nMake sure each dimension variable is assigned to only once in the function.\nExtract just the dimension variables names into dim_names and then register the correlation from lhs to those dimension names.  source:  ParallelAccelerator/src/parallel-ir.jl:3277    convertUnsafe(stmt)  \u00b6  Remove unsafe array access Symbols from the incoming \"stmt\".\nReturns the updated statement if something was modifed, else returns \"nothing\".  source:  ParallelAccelerator/src/parallel-ir-task.jl:951    convertUnsafeOrElse(stmt)  \u00b6  Try to remove unsafe array access Symbols from the incoming \"stmt\".  If successful, then return the updated\nstatement, else return the unmodified statement.  source:  ParallelAccelerator/src/parallel-ir-task.jl:970    convertUnsafeWalk(x::Expr,  state,  top_level_number,  is_top_level,  read)  \u00b6  The AstWalk callback to find unsafe arrayset and arrayref variants and\nreplace them with the regular Julia versions.  Sets the \"found\" flag\nin the state when such a replacement is performed.  source:  ParallelAccelerator/src/parallel-ir-task.jl:919    copy_propagate(node::ANY,  data::ParallelAccelerator.ParallelIR.CopyPropagateState,  top_level_number,  is_top_level,  read)  \u00b6  In each basic block, if there is a \"copy\" (i.e., something of the form \"a = b\") then put\nthat in copies as copies[a] = b.  Then, later in the basic block if you see the symbol\n\"a\" then replace it with \"b\".  Note that this is not SSA so \"a\" may be written again\nand if it is then it must be removed from copies.  source:  ParallelAccelerator/src/parallel-ir.jl:2849    count_assignments(x,  symbol_assigns::Dict{Symbol, Int64},  top_level_number,  is_top_level,  read)  \u00b6  AstWalk callback to count the number of static times that a symbol is assigne within a method.  source:  ParallelAccelerator/src/parallel-ir.jl:920    create1D_array_access_desc(array::SymbolNode)  \u00b6  Create an array access descriptor for \"array\".\nPresumes that for point \"i\" in the iteration space that only index \"i\" is accessed.  source:  ParallelAccelerator/src/parallel-ir-task.jl:124    create2D_array_access_desc(array::SymbolNode)  \u00b6  Create an array access descriptor for \"array\".\nPresumes that for points \"(i,j)\" in the iteration space that only indices \"(i,j)\" is accessed.  source:  ParallelAccelerator/src/parallel-ir-task.jl:134    createInstructionCountEstimate(the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Takes a parfor and walks the body of the parfor and estimates the number of instruction needed for one instance of that body.  source:  ParallelAccelerator/src/parallel-ir-task.jl:557    createLoweredAliasMap(dict1)  \u00b6  Take a single-step alias map, e.g., a= b, b= c, and create a lowered dictionary, a= c, b= c, that\nmaps each array to the transitively lowered array.  source:  ParallelAccelerator/src/parallel-ir.jl:1840    createMapLhsToParfor(parfor_assignment,  the_parfor,  is_multi::Bool,  sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Creates a mapping between variables on the left-hand side of an assignment where the right-hand side is a parfor\nand the arrays or scalars in that parfor that get assigned to the corresponding parts of the left-hand side.\nReturns a tuple where the first element is a map for arrays between left-hand side and parfor and the second\nelement is a map for reduction scalars between left-hand side and parfor.\nis_multi is true if the assignment is a fusion assignment.\nparfor_assignment is the AST of the whole expression.\nthe_parfor is the PIRParForAst type part of the incoming assignment.\nsym_to_type is an out parameter that maps symbols in the output mapping to their types.  source:  ParallelAccelerator/src/parallel-ir.jl:1774    createStateVar(state,  name,  typ,  access)  \u00b6  Add a local variable to the current function's lambdaInfo.\nReturns a symbol node of the new variable.  source:  ParallelAccelerator/src/parallel-ir.jl:639    createTempForArray(array_sn::Union{GenSym, Symbol, SymbolNode},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Create a temporary variable that is parfor private to hold the value of an element of an array.  source:  ParallelAccelerator/src/parallel-ir.jl:647    createTempForRangeOffset(num_used,  ranges::Array{ParallelAccelerator.ParallelIR.RangeData, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Create a variable to hold the offset of a range offset from the start of the array.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:322    createTempForRangedArray(array_sn::Union{GenSym, Symbol, SymbolNode},  range::Array{Union{GenSym, SymbolNode}, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Create a temporary variable that is parfor private to hold the value of an element of an array.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:338    create_array_access_desc(array::SymbolNode)  \u00b6  Create an array access descriptor for \"array\".  source:  ParallelAccelerator/src/parallel-ir-task.jl:144    create_equivalence_classes(node::Expr,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)  \u00b6  AstWalk callback to determine the array equivalence classes.  source:  ParallelAccelerator/src/parallel-ir.jl:3405    dfsVisit(swd::ParallelAccelerator.ParallelIR.StatementWithDeps,  vtime::Int64,  topo_sort::Array{ParallelAccelerator.ParallelIR.StatementWithDeps, N})  \u00b6  Construct a topological sort of the dependence graph.  source:  ParallelAccelerator/src/parallel-ir.jl:3863    estimateInstrCount(ast::Expr,  state::ParallelAccelerator.ParallelIR.eic_state,  top_level_number,  is_top_level,  read)  \u00b6  AstWalk callback for estimating the instruction count.  source:  ParallelAccelerator/src/parallel-ir-task.jl:474    extractArrayEquivalencies(node::Expr,  state)  \u00b6  \"node\" is a domainIR node.  Take the arrays used in this node, create an array equivalence for them if they \ndon't already have one and make sure they all share one equivalence class.  source:  ParallelAccelerator/src/parallel-ir.jl:3215    findSelectedDimensions(inputInfo::Array{ParallelAccelerator.ParallelIR.InputInfo, 1},  state)  \u00b6  Given all the InputInfo for a Domain IR operation being lowered to Parallel IR,\ndetermine the number of output dimensions for those arrays taking into account\nthat singly selected trailing dimensinos are eliminated.  Make sure that all such\narrays have the same output dimensions because this will match the loop nest size.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:745    flattenParfor(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst)  \u00b6  Takes a new array of body statements in the process of construction in \"new_body\" and takes a parfor to add to that\nbody.  This parfor is in the nested (parfor code is in the parfor node itself) temporary form we use for fusion although \npre-statements and post-statements are already elevated by this point.  We replace this nested form with a non-nested\nform where we have a parfor_start and parfor_end to delineate the parfor code.  source:  ParallelAccelerator/src/parallel-ir-flatten.jl:94    from_assertEqShape(node::Expr,  state)  \u00b6  Create array equivalences from an assertEqShape AST node.\nThere are two arrays in the args to assertEqShape.  source:  ParallelAccelerator/src/parallel-ir.jl:2604    from_assignment(lhs,  rhs,  depth,  state)  \u00b6  Process an assignment expression.\nStarts by recurisvely processing the right-hand side of the assignment.\nEliminates the assignment of a=b if a is dead afterwards and b has no side effects.\n    Does some array equivalence class work which may be redundant given that we now run a separate equivalence class pass so consider removing that part of this code.  source:  ParallelAccelerator/src/parallel-ir.jl:2685    from_call(ast::Array{Any, 1},  depth,  state)  \u00b6  Process a call AST node.  source:  ParallelAccelerator/src/parallel-ir.jl:2807    from_expr(ast::Expr,  depth,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level)  \u00b6  The main ParallelIR function for processing some node in the AST.  source:  ParallelAccelerator/src/parallel-ir.jl:4546    from_lambda(lambda::Expr,  depth,  state)  \u00b6  Process a :lambda Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:946    from_root(function_name,  ast::Expr)  \u00b6  The main ENTRY point into ParallelIR.\n1) Do liveness analysis.\n2) Convert mmap to mmap! where possible.\n3) Do some code rearrangement (e.g., hoisting) to maximize later fusion.\n4) Create array equivalence classes within the function.\n5) Rearrange statements within a basic block to push domain operations to the bottom so more fusion.\n6) Call the main from_expr to process the AST for the function.  This will\na) Lower domain IR to parallel IR AST nodes.\nb) Fuse parallel IR nodes where possible.\nc) Convert to task IR nodes if task mode enabled.  source:  ParallelAccelerator/src/parallel-ir.jl:4208    fullyLowerAlias(dict::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  input::Union{GenSym, Symbol})  \u00b6  Given an \"input\" Symbol, use that Symbol as key to a dictionary.  While such a Symbol is present\nin the dictionary replace it with the corresponding value from the dict.  source:  ParallelAccelerator/src/parallel-ir.jl:1829    fuse(body,  body_index,  cur,  state)  \u00b6  Test whether we can fuse the two most recent parfor statements and if so to perform that fusion.  source:  ParallelAccelerator/src/parallel-ir.jl:1871    generate_instr_count(function_name,  signature)  \u00b6  Try to figure out the instruction count for a given call.  source:  ParallelAccelerator/src/parallel-ir-task.jl:398    getArrayElemType(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Returns the element type of an Array.  source:  ParallelAccelerator/src/parallel-ir.jl:611    getArrayElemType(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Returns the element type of an Array.  source:  ParallelAccelerator/src/parallel-ir.jl:604    getArrayElemType(atyp::DataType)  \u00b6  Returns the element type of an Array.  source:  ParallelAccelerator/src/parallel-ir.jl:591    getArrayNumDims(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Return the number of dimensions of an Array.  source:  ParallelAccelerator/src/parallel-ir.jl:628    getArrayNumDims(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Return the number of dimensions of an Array.  source:  ParallelAccelerator/src/parallel-ir.jl:619    getConstDims(num_dim_inputs,  inputInfo::ParallelAccelerator.ParallelIR.InputInfo)  \u00b6  In the case where a domain IR operation on an array creates a lower dimensional output,\nthe indexing expression needs the expression that selects those constant trailing dimensions\nthat are being dropped.  This function returns an array of those constant expressions for\nthe trailing dimensions.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:766    getCorrelation(sng::Union{GenSym, Symbol, SymbolNode},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Get the equivalence class of a domain IR input in inputInfo.  source:  ParallelAccelerator/src/parallel-ir.jl:1747    getFirstArrayLens(prestatements,  num_dims)  \u00b6  Get the variable which holds the length of the first input array to a parfor.  source:  ParallelAccelerator/src/parallel-ir.jl:1438    getIO(stmt_ids,  bb_statements)  \u00b6  Given a set of statement IDs and liveness information for the statements of the function, determine\nwhich symbols are needed at input and which symbols are purely local to the functio.  source:  ParallelAccelerator/src/parallel-ir-task.jl:840    getInputSet(node::ParallelAccelerator.ParallelIR.PIRParForAst)  \u00b6  Returns a Set with all the arrays read by this parfor.  source:  ParallelAccelerator/src/parallel-ir.jl:1106    getLhsFromAssignment(assignment)  \u00b6  Get the left-hand side of an assignment expression.  source:  ParallelAccelerator/src/parallel-ir.jl:1077    getLhsOutputSet(lhs,  assignment)  \u00b6  Get the real outputs of an assignment statement.\nIf the assignment expression is normal then the output is just the left-hand side.\nIf the assignment expression is augmented with a FusionSentinel then the real outputs\nare the 4+ arguments to the expression.  source:  ParallelAccelerator/src/parallel-ir.jl:1121    getMaxLabel(max_label,  stmts::Array{Any, 1})  \u00b6  Scan the body of a function in \"stmts\" and return the max label in a LabelNode AST seen in the body.  source:  ParallelAccelerator/src/parallel-ir.jl:4026    getNonBlock(head_preds,  back_edge)  \u00b6  Find the basic block before the entry to a loop.  source:  ParallelAccelerator/src/parallel-ir-task.jl:5    getOrAddArrayCorrelation(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Return a correlation set for an array.  If the array was not previously added then add it and return it.  source:  ParallelAccelerator/src/parallel-ir.jl:802    getOrAddRangeCorrelation(ranges::Array{ParallelAccelerator.ParallelIR.RangeExprs, 1},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Gets (or adds if absent) the range correlation for the given array of RangeExprs.  source:  ParallelAccelerator/src/parallel-ir.jl:813    getOrAddSymbolCorrelation(array::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state,  dims::Array{Union{GenSym, Symbol}, 1})  \u00b6  A new array is being created with an explicit size specification in dims.  source:  ParallelAccelerator/src/parallel-ir.jl:832    getParforCorrelation(parfor,  state)  \u00b6  Get the equivalence class of the first array who length is extracted in the pre-statements of the specified \"parfor\".  source:  ParallelAccelerator/src/parallel-ir.jl:1740    getParforNode(node)  \u00b6  Get the parfor object from either a bare parfor or one part of an assignment.  source:  ParallelAccelerator/src/parallel-ir.jl:1059    getPrivateSet(body::Array{Any, 1})  \u00b6  Go through the body of a parfor and collect those Symbols, GenSyms, etc. that are assigned to within the parfor except reduction variables.  source:  ParallelAccelerator/src/parallel-ir.jl:898    getPrivateSetInner(x::Expr,  state::Set{Union{GenSym, Symbol, SymbolNode}},  top_level_number::Int64,  is_top_level::Bool,  read::Bool)  \u00b6  The AstWalk callback function for getPrivateSet.\nFor each AST in a parfor body, if the node is an assignment or loop head node then add the written entity to the state.  source:  ParallelAccelerator/src/parallel-ir.jl:868    getRhsFromAssignment(assignment)  \u00b6  Get the right-hand side of an assignment expression.  source:  ParallelAccelerator/src/parallel-ir.jl:1070    getSName(ssn::Symbol)  \u00b6  Get the name of a symbol whether the input is a Symbol or SymbolNode or :(::) Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:2237    get_one(ast::Array{T, N})  \u00b6  Take something returned from AstWalk and assert it should be an array but in this\ncontext that the array should also be of length 1 and then return that single element.  source:  ParallelAccelerator/src/parallel-ir.jl:4700    get_unique_num()  \u00b6  If we need to generate a name and make sure it is unique then include an monotonically increasing number.  source:  ParallelAccelerator/src/parallel-ir.jl:853    hasNoSideEffects(node::Union{GenSym, LambdaStaticData, Number, Symbol, SymbolNode})  \u00b6  Sometimes statements we exist in the AST of the form a=Expr where a is a Symbol that isn't live past the assignment\nand we'd like to eliminate the whole assignment statement but we have to know that the right-hand side has no\nside effects before we can do that.  This function says whether the right-hand side passed into it has side effects\nor not.  Several common function calls that otherwise we wouldn't know are safe are explicitly checked for.  source:  ParallelAccelerator/src/parallel-ir.jl:2547    hasSymbol(ssn::Symbol)  \u00b6  Returns true if the incoming AST node can be interpreted as a Symbol.  source:  ParallelAccelerator/src/parallel-ir.jl:2218    hoistAllocation(ast::Array{Any, 1},  lives,  domLoop::CompilerTools.Loops.DomLoops,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Try to hoist allocations outside the loop if possible.  source:  ParallelAccelerator/src/parallel-ir.jl:3698    insert_no_deps_beginning(node,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read)  \u00b6  Works with remove_no_deps below to move statements with no dependencies to the beginning of the AST.  source:  ParallelAccelerator/src/parallel-ir.jl:3055    intermediate_from_exprs(ast::Array{Any, 1},  depth,  state)  \u00b6  Process an array of expressions that aren't from a :body Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:2288    isArrayType(typ)  \u00b6  Returns true if the incoming type in \"typ\" is an array type.  source:  ParallelAccelerator/src/parallel-ir.jl:584    isArrayType(x::SymbolNode)  \u00b6  Returns true if a given SymbolNode \"x\" is an Array type.  source:  ParallelAccelerator/src/parallel-ir.jl:2316    isArrayref(x)  \u00b6  Is a node an arrayref node?  source:  ParallelAccelerator/src/parallel-ir.jl:1356    isArrayrefCall(x::Expr)  \u00b6  Is a node a call to arrayref.  source:  ParallelAccelerator/src/parallel-ir.jl:1377    isArrayset(x)  \u00b6  Is a node an arrayset node?  source:  ParallelAccelerator/src/parallel-ir.jl:1346    isArraysetCall(x::Expr)  \u00b6  Is a node a call to arrayset.  source:  ParallelAccelerator/src/parallel-ir.jl:1366    isAssignmentNode(node::Expr)  \u00b6  Is a node an assignment expression node.  source:  ParallelAccelerator/src/parallel-ir.jl:987    isBareParfor(node::Expr)  \u00b6  Is this a parfor node not part of an assignment statement.  source:  ParallelAccelerator/src/parallel-ir.jl:1009    isDomainNode(ast::Expr)  \u00b6  Returns true if the given \"ast\" node is a DomainIR operation.  source:  ParallelAccelerator/src/parallel-ir.jl:3882    isFusionAssignment(x::Expr)  \u00b6  Check if an assignement is a fusion assignment.\n    In regular assignments, there are only two args, the left and right hand sides.\n    In fusion assignments, we introduce a third arg that is marked by an object of FusionSentinel type.  source:  ParallelAccelerator/src/parallel-ir.jl:1700    isLoopheadNode(node::Expr)  \u00b6  Is a node a loophead expression node (a form of assignment).  source:  ParallelAccelerator/src/parallel-ir.jl:998    isParforAssignmentNode(node::Expr)  \u00b6  Is a node an assignment expression with a parfor node as the right-hand side.  source:  ParallelAccelerator/src/parallel-ir.jl:1033    isSymbolsUsed(vars,  top_level_numbers::Array{Int64, 1},  state)  \u00b6  Returns true if any variable in the collection \"vars\" is used in any statement whose top level number is in \"top_level_numbers\".\n    We use expr_state \"state\" to get the block liveness information from which we use \"def\" and \"use\" to determine if a variable\n        usage is present.  source:  ParallelAccelerator/src/parallel-ir.jl:1716    is_eliminated_arraylen(x::Expr)  \u00b6  Returns true if the input node is an assignment node where the right-hand side is a call to arraysize.  source:  ParallelAccelerator/src/parallel-ir.jl:1589    isbitstuple(a::Tuple)  \u00b6  Returns true if input \"a\" is a tuple and each element of the tuple of isbits type.  source:  ParallelAccelerator/src/parallel-ir.jl:4493    iterations_equals_inputs(node::ParallelAccelerator.ParallelIR.PIRParForAst)  \u00b6  Returns true if the domain operation mapped to this parfor has the property that the iteration space\nis identical to the dimenions of the inputs.  source:  ParallelAccelerator/src/parallel-ir.jl:1086    lambdaFromDomainLambda(domain_lambda,  dl_inputs)  \u00b6  Form a Julia :lambda Expr from a DomainLambda.  source:  ParallelAccelerator/src/parallel-ir.jl:4038    makePrivateParfor(var_name::Symbol,  state)  \u00b6  Takes an existing variable whose name is in \"var_name\" and adds the descriptor flag ISPRIVATEPARFORLOOP to declare the\nvariable to be parfor loop private and eventually go in an OMP private clause.  source:  ParallelAccelerator/src/parallel-ir.jl:659    makeTasks(start_index,  stop_index,  body,  bb_live_info,  state,  task_graph_mode)  \u00b6  For a given start and stop index in some body and liveness information, form a set of tasks.  source:  ParallelAccelerator/src/parallel-ir-task.jl:759    maxFusion(bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  For every basic block, try to push domain IR statements down and non-domain IR statements up so that domain nodes\nare next to each other and can be fused.  source:  ParallelAccelerator/src/parallel-ir.jl:3926    mergeLambdaIntoOuterState(state,  inner_lambda::Expr)  \u00b6  Pull the information from the inner lambda into the outer lambda.  source:  ParallelAccelerator/src/parallel-ir.jl:1218    merge_correlations(state,  unchanging,  eliminate)  \u00b6  If we somehow determine that two sets of correlations are actually the same length then merge one into the other.  source:  ParallelAccelerator/src/parallel-ir.jl:764    mk_alloc_array_1d_expr(elem_type,  atype,  length)  \u00b6  Return an expression that allocates and initializes a 1D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and a \"length\".  source:  ParallelAccelerator/src/parallel-ir.jl:496    mk_alloc_array_2d_expr(elem_type,  atype,  length1,  length2)  \u00b6  Return an expression that allocates and initializes a 2D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and two dimensions of length in \"length1\" and \"length2\".  source:  ParallelAccelerator/src/parallel-ir.jl:534    mk_alloc_array_3d_expr(elem_type,  atype,  length1,  length2,  length3)  \u00b6  Return an expression that allocates and initializes a 3D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and two dimensions of length in \"length1\" and \"length2\" and \"length3\".  source:  ParallelAccelerator/src/parallel-ir.jl:560    mk_arraylen_expr(x::ParallelAccelerator.ParallelIR.InputInfo,  dim::Int64)  \u00b6  Create an expression whose value is the length of the input array.  source:  ParallelAccelerator/src/parallel-ir.jl:447    mk_arraylen_expr(x::Union{GenSym, Symbol, SymbolNode},  dim::Int64)  \u00b6  Create an expression whose value is the length of the input array.  source:  ParallelAccelerator/src/parallel-ir.jl:440    mk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Return an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:54    mk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1})  \u00b6  Return an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:54    mk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})  \u00b6  Return an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:54    mk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:85    mk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1})  \u00b6  Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:85    mk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})  \u00b6  Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:85    mk_assignment_expr(lhs::Union{GenSym, Symbol, SymbolNode},  rhs,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Create an assignment expression AST node given a left and right-hand side.\nThe left-hand side has to be a symbol node from which we extract the type so as to type the new Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:353    mk_colon_expr(start_expr,  skip_expr,  end_expr)  \u00b6  Returns an expression to construct a :colon object that contains the start of a range, the end and the skip expression.  source:  ParallelAccelerator/src/parallel-ir-task.jl:878    mk_convert(new_type,  ex)  \u00b6  Returns an expression that convert \"ex\" into a another type \"new_type\".  source:  ParallelAccelerator/src/parallel-ir.jl:473    mk_gotoifnot_expr(cond,  goto_label)  \u00b6  Returns a :gotoifnot Expr given a condition \"cond\" and a label \"goto_label\".  source:  ParallelAccelerator/src/parallel-ir-task.jl:900    mk_next_expr(colon_sym,  start_sym)  \u00b6  Returns a :next call Expr that gets the next element of an iteration range from a :colon object.  source:  ParallelAccelerator/src/parallel-ir-task.jl:892    mk_parallelir_ref(sym)  \u00b6  Create an expression that references something inside ParallelIR.\nIn other words, returns an expression the equivalent of ParallelAccelerator.ParallelIR.sym where sym is an input argument to this function.  source:  ParallelAccelerator/src/parallel-ir.jl:465    mk_parallelir_ref(sym,  ref_type)  \u00b6  Create an expression that references something inside ParallelIR.\nIn other words, returns an expression the equivalent of ParallelAccelerator.ParallelIR.sym where sym is an input argument to this function.  source:  ParallelAccelerator/src/parallel-ir.jl:465    mk_parfor_args_from_mmap!(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  with_indices,  domain_oprs,  state)  \u00b6  The main routine that converts a mmap! AST node to a parfor AST node.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:498    mk_parfor_args_from_mmap(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  domain_oprs,  state)  \u00b6  The main routine that converts a mmap AST node to a parfor AST node.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:789    mk_parfor_args_from_reduce(input_args::Array{Any, 1},  state)  \u00b6  The main routine that converts a reduce AST node to a parfor AST node.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:119    mk_return_expr(outs)  \u00b6  Given an array of outputs in \"outs\", form a return expression.\nIf there is only one out then the args of :return is just that expression.\nIf there are multiple outs then form a tuple of them and that tuple goes in :return args.  source:  ParallelAccelerator/src/parallel-ir.jl:338    mk_start_expr(colon_sym)  \u00b6  Returns an expression to get the start of an iteration range from a :colon object.  source:  ParallelAccelerator/src/parallel-ir-task.jl:885    mk_svec_expr(parts...)  \u00b6  Make a svec expression.  source:  ParallelAccelerator/src/parallel-ir.jl:487    mk_tuple_expr(tuple_fields,  typ)  \u00b6  Return an expression which creates a tuple.  source:  ParallelAccelerator/src/parallel-ir.jl:1151    mk_tupleref_expr(tuple_var,  index,  typ)  \u00b6  Create an expression which returns the index'th element of the tuple whose name is contained in tuple_var.  source:  ParallelAccelerator/src/parallel-ir.jl:480    mk_untyped_assignment(lhs,  rhs)  \u00b6  Only used to create fake expression to force lhs to be seen as written rather than read.  source:  ParallelAccelerator/src/parallel-ir.jl:370    mmapInline(ast::Expr,  lives,  uniqSet)  \u00b6", 
            "title": "Internal"
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/#if-a-definition-of-a-mmap-is-only-used-once-and-not-aliased-it-can-be-inlined-into-its", 
            "text": "", 
            "title": "If a definition of a mmap is only used once and not aliased, it can be inlined into its"
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/#use-side-as-long-as-its-dependencies-have-not-been-changed", 
            "text": "", 
            "title": "use side as long as its dependencies have not been changed."
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/#fixme-is-the-implementation-still-correct-when-branches-are-present", 
            "text": "source:  ParallelAccelerator/src/parallel-ir.jl:3621    mmapToMmap!(ast,  lives,  uniqSet)  \u00b6  Performs the mmap to mmap! phase.\nIf the arguments of a mmap dies aftewards, and is not aliased, then\nwe can safely change the mmap to mmap!.  source:  ParallelAccelerator/src/parallel-ir.jl:3764    mustRemainLastStatementInBlock(node::GotoNode)  \u00b6  Returns true if the given AST \"node\" must remain the last statement in a basic block.\nThis is true if the node is a GotoNode or a :gotoifnot Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:3910    nameToSymbolNode(name::Symbol,  sym_to_type)  \u00b6  Forms a SymbolNode given a symbol in \"name\" and get the type of that symbol from the incoming dictionary \"sym_to_type\".  source:  ParallelAccelerator/src/parallel-ir.jl:1159    nested_function_exprs(max_label,  domain_lambda,  dl_inputs)  \u00b6  A routine similar to the main parallel IR entry put but designed to process the lambda part of\ndomain IR AST nodes.  source:  ParallelAccelerator/src/parallel-ir.jl:4067    next_label(state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Returns the next usable label for the current function.  source:  ParallelAccelerator/src/parallel-ir.jl:738    oneIfOnly(x)  \u00b6  Returns a single element of an array if there is only one or the array otherwise.  source:  ParallelAccelerator/src/parallel-ir.jl:1860    parforToTask(parfor_index,  bb_statements,  body,  state)  \u00b6  Given a parfor statement index in \"parfor_index\" in the \"body\"'s statements, create a TaskInfo node for this parfor.  source:  ParallelAccelerator/src/parallel-ir-task.jl:1190    pirPrintDl(dbg_level,  dl)  \u00b6  Debug print the parts of a DomainLambda.  source:  ParallelAccelerator/src/parallel-ir.jl:4017    pir_alias_cb(ast::Expr,  state,  cbdata)  \u00b6  An AliasAnalysis callback (similar to LivenessAnalysis callback) that handles ParallelIR introduced AST node types.\nFor each ParallelIR specific node type, form an array of expressions that AliasAnalysis\n    can analyze to reflect the aliases of the given AST node.\n    If we read a symbol it is sufficient to just return that symbol as one of the expressions.\n    If we write a symbol, then form a fake mk_assignment_expr just to get liveness to realize the symbol is written.  source:  ParallelAccelerator/src/parallel-ir.jl:4884    pir_live_cb(ast::Expr,  cbdata::ANY)  \u00b6  A LivenessAnalysis callback that handles ParallelIR introduced AST node types.\nFor each ParallelIR specific node type, form an array of expressions that liveness\ncan analysis to reflect the read/write set of the given AST node.\nIf we read a symbol it is sufficient to just return that symbol as one of the expressions.\nIf we write a symbol, then form a fake mk_assignment_expr just to get liveness to realize the symbol is written.  source:  ParallelAccelerator/src/parallel-ir.jl:2412    pir_live_cb_def(x)  \u00b6  Just call the AST walker for symbol for parallel IR nodes with no state.  source:  ParallelAccelerator/src/parallel-ir.jl:939    printBody(dlvl,  body::Array{Any, 1})  \u00b6  Pretty print the args part of the \"body\" of a :lambda Expr at a given debug level in \"dlvl\".  source:  ParallelAccelerator/src/parallel-ir.jl:2327    printLambda(dlvl,  node::Expr)  \u00b6  Pretty print a :lambda Expr in \"node\" at a given debug level in \"dlvl\".  source:  ParallelAccelerator/src/parallel-ir.jl:2340    processAndUpdateBody(lambda::Expr,  f::Function,  state)  \u00b6  Apply a function \"f\" that takes the :body from the :lambda and returns a new :body that is stored back into the :lambda.  source:  ParallelAccelerator/src/parallel-ir.jl:3295    rangeSize(start,  skip,  last)  \u00b6  Compute size of a range.  source:  ParallelAccelerator/src/parallel-ir.jl:432    rangeToRangeData(range::Expr,  pre_offsets::Array{Expr, 1},  arr,  range_num::Int64,  state)  \u00b6  Convert a :range Expr introduced by Domain IR into a Parallel IR data structure RangeData.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:354    recreateLoops(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state,  newLambdaInfo)  \u00b6  In threads mode, we can't have parfor_start and parfor_end in the code since Julia has to compile the code itself and so\nwe have to reconstruct a loop infrastructure based on the parfor's loop nest information.  This function takes a parfor\nand outputs that parfor to the new function body as regular Julia loops.  source:  ParallelAccelerator/src/parallel-ir-task.jl:1156    recreateLoopsInternal(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  loop_nest_level,  next_available_label,  state,  newLambdaInfo)  \u00b6  This is a recursive routine to reconstruct a regular Julia loop nest from the loop nests described in PIRParForAst.\nOne call of this routine handles one level of the loop nest.\nIf the incoming loop nest level is more than the number of loops nests in the parfor then that is the spot to\ninsert the body of the parfor into the new function body in \"new_body\".  source:  ParallelAccelerator/src/parallel-ir-task.jl:1020    rememberTypeForSym(sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  sym::Union{GenSym, Symbol},  typ::DataType)  \u00b6  Add to the map of symbol names to types.  source:  ParallelAccelerator/src/parallel-ir.jl:1679    removeAssertEqShape(args::Array{Any, 1},  state)  \u00b6  Implements one of the main ParallelIR passes to remove assertEqShape AST nodes from the body if they are statically known to be in the same equivalence class.  source:  ParallelAccelerator/src/parallel-ir.jl:2588    removeNothingStmts(args::Array{Any, 1},  state)  \u00b6  Empty statements can be added to the AST by some passes in ParallelIR.\nThis pass over the statements of the :body excludes such \"nothing\" statements from the new :body.  source:  ParallelAccelerator/src/parallel-ir.jl:3306    remove_dead(node,  data::ParallelAccelerator.ParallelIR.RemoveDeadState,  top_level_number,  is_top_level,  read)  \u00b6  An AstWalk callback that uses liveness information in \"data\" to remove dead stores.  source:  ParallelAccelerator/src/parallel-ir.jl:2988    remove_extra_allocs(ast)  \u00b6  removes extra allocations  source:  ParallelAccelerator/src/parallel-ir.jl:4363    remove_no_deps(node::ANY,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read)  \u00b6", 
            "title": "FIXME: is the implementation still correct when branches are present?"
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/#this-routine-gathers-up-nodes-that-do-not-use", 
            "text": "", 
            "title": "This routine gathers up nodes that do not use"
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/#any-variable-and-removes-them-from-the-ast-into-top_level_no_deps-this-works-in-conjunction-with", 
            "text": "", 
            "title": "any variable and removes them from the AST into top_level_no_deps.  This works in conjunction with"
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/#insert_no_deps_beginning-above-to-move-these-statements-with-no-dependencies-to-the-beginning-of-the-ast", 
            "text": "", 
            "title": "insert_no_deps_beginning above to move these statements with no dependencies to the beginning of the AST"
        }, 
        {
            "location": "/ParallelAccelerator.ParallelIR/#where-they-cant-prevent-fusion", 
            "text": "source:  ParallelAccelerator/src/parallel-ir.jl:3071    replaceParforWithDict(parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  gensym_map)  \u00b6  Not currently used but might need it at some point.\nSearch a whole PIRParForAst object and replace one SymAllGen with another.  source:  ParallelAccelerator/src/parallel-ir.jl:216    run_as_task()  \u00b6  Return true if run_as_task_decrement would return true but don't update the run_as_tasks count.  source:  ParallelAccelerator/src/parallel-ir-task.jl:229    run_as_task_decrement()  \u00b6  If run_as_tasks is positive then convert this parfor to a task and decrement the count so that only the\noriginal number run_as_tasks if the number of tasks created.  source:  ParallelAccelerator/src/parallel-ir-task.jl:215    selectToRangeData(select::Expr,  pre_offsets::Array{Expr, 1},  state)  \u00b6  Convert the range(s) part of a :select Expr introduced by Domain IR into an array of Parallel IR data structures RangeData.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:371    seqTask(body_indices,  bb_statements,  body,  state)  \u00b6  Form a task out of a range of sequential statements.\nThis is not currently implemented.  source:  ParallelAccelerator/src/parallel-ir-task.jl:1538    show(io::IO,  pnode::ParallelAccelerator.ParallelIR.PIRParForAst)  \u00b6  Overload of Base.show to pretty print for parfor AST nodes.  source:  ParallelAccelerator/src/parallel-ir.jl:273    simpleIndex(dict)  \u00b6  Returns true if all array references use singular index variables and nothing more complicated involving,\nfor example, addition or subtraction by a constant.  source:  ParallelAccelerator/src/parallel-ir.jl:668    sub_arraylen_walk(x::Expr,  replacement,  top_level_number,  is_top_level,  read)  \u00b6  AstWalk callback that does the work of substitute_arraylen on a node-by-node basis.\nreplacement is an array containing the length of the dimensions of the arrays a part of this parfor.\nIf we see a call to create an array, replace the length params with those in the common set in \"replacement\".  source:  ParallelAccelerator/src/parallel-ir.jl:1620    sub_arrayset_walk(x::Expr,  cbd,  top_level_number,  is_top_level,  read)  \u00b6  AstWalk callback that does the work of substitute_arrayset on a node-by-node basis.  source:  ParallelAccelerator/src/parallel-ir.jl:1388    sub_cur_body_walk(x::Expr,  cbd::ParallelAccelerator.ParallelIR.cur_body_data,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)  \u00b6  AstWalk callback that does the work of substitute_cur_body on a node-by-node basis.  source:  ParallelAccelerator/src/parallel-ir.jl:1471    substitute_arraylen(x,  replacement)  \u00b6  replacement is an array containing the length of the dimensions of the arrays a part of this parfor.\nIf we see a call to create an array, replace the length params with those in the common set in \"replacement\".  source:  ParallelAccelerator/src/parallel-ir.jl:1652    substitute_arrayset(x,  arrays_set_in_cur_body,  output_items_with_aliases)  \u00b6  Modify the body of a parfor.\ntemp_map holds a map of array names whose arraysets should be turned into a mapped variable instead of the arrayset. a[i] = b. a= c. becomes c = b\nmap_for_non_eliminated holds arrays for which we need to add a variable to save the value but we can't eiminate the arrayset. a[i] = b. a= c. becomes c = a[i] = b\n    map_drop_arrayset drops the arrayset without replacing with a variable.  This is because a variable was previously added here with a map_for_non_eliminated case.\n    a[i] = b. becomes b  source:  ParallelAccelerator/src/parallel-ir.jl:1433    substitute_cur_body(x,  temp_map::Dict{Union{GenSym, Symbol}, Union{GenSym, SymbolNode}},  index_map::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  arrays_set_in_cur_body::Set{Union{GenSym, Symbol}},  replace_array_name_in_arrayset::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Make changes to the second parfor body in the process of parfor fusion.\ntemp_map holds array names for which arrayrefs should be converted to a variable.  a[i].  a= b. becomes b\n    index_map holds maps between index variables.  The second parfor is modified to use the index variable of the first parfor.\n    arrays_set_in_cur_body           # Used as output.  Collects the arrays set in the current body.\n    replace_array_name_in_arrayset   # Map from one array to another.  Replace first array with second when used in arrayset context.  source:  ParallelAccelerator/src/parallel-ir.jl:1575    taskableParfor(node)  \u00b6  Returns true if the \"node\" is a parfor and the task limit hasn't been exceeded.\nAlso controls whether stencils or reduction can become tasks.  source:  ParallelAccelerator/src/parallel-ir-task.jl:278    toSNGen(x::Symbol,  typ)  \u00b6  If we have the type, convert a Symbol to SymbolNode.\nIf we have a GenSym then we have to keep it.  source:  ParallelAccelerator/src/parallel-ir.jl:2788    toSymGen(x::Symbol)  \u00b6  In various places we need a SymGen type which is the union of Symbol and GenSym.\nThis function takes a Symbol, SymbolNode, or GenSym and return either a Symbol or GenSym.  source:  ParallelAccelerator/src/parallel-ir.jl:699    toSymNodeGen(x::Symbol,  typ)  \u00b6  Form a SymbolNode with the given typ if possible or a GenSym if that is what is passed in.  source:  ParallelAccelerator/src/parallel-ir.jl:718    uncompressed_ast(l::LambdaStaticData)  \u00b6  Convert a compressed LambdaStaticData format into the uncompressed AST format.  source:  ParallelAccelerator/src/parallel-ir.jl:914    ParallelAccelerator.ParallelIR.CopyPropagateState  \u00b6  State to aide in the copy propagation phase.  source:  ParallelAccelerator/src/parallel-ir.jl:2831    ParallelAccelerator.ParallelIR.DirWalk  \u00b6  Wraps the callback and opaque data passed from the user of ParallelIR's AstWalk.  source:  ParallelAccelerator/src/parallel-ir.jl:4707    ParallelAccelerator.ParallelIR.DomainOperation  \u00b6  Holds information about domain operations part of a parfor node.  source:  ParallelAccelerator/src/parallel-ir.jl:95    ParallelAccelerator.ParallelIR.EquivalenceClasses  \u00b6  Holds a dictionary from an array symbol to an integer corresponding to an equivalence class.\nAll array symbol in the same equivalence class are known to have the same shape.  source:  ParallelAccelerator/src/parallel-ir.jl:105    ParallelAccelerator.ParallelIR.FusionSentinel  \u00b6  Just used to hold a spot in an array to indicate the this is a special assignment expression with embedded real array output names from a fusion.  source:  ParallelAccelerator/src/parallel-ir.jl:1690    ParallelAccelerator.ParallelIR.InProgress  \u00b6  A sentinel in the instruction count estimation process.\nBefore recursively processing a call, we add a sentinel for that function so that if we see that\nsentinel later we know we've tried to recursively process it and so can bail out by setting\nfully_analyzed to false.  source:  ParallelAccelerator/src/parallel-ir-task.jl:346    ParallelAccelerator.ParallelIR.InputInfo  \u00b6  Type used by mk_parfor_args... functions to hold information about input arrays.  source:  ParallelAccelerator/src/parallel-ir.jl:391    ParallelAccelerator.ParallelIR.InsertTaskNode  \u00b6  A data type containing the information that CGen uses to generate a call to pert_insert_divisible_task.  source:  ParallelAccelerator/src/parallel-ir-task.jl:197    ParallelAccelerator.ParallelIR.PIRParForStartEnd  \u00b6  After lowering, it is necessary to make the parfor body top-level statements so that basic blocks\ncan be correctly identified and labels correctly found.  There is a phase in parallel IR where we \ntake a PIRParForAst node and split it into a parfor_start node followed by the body as top-level\nstatements followed by parfor_end (also a top-level statement).  source:  ParallelAccelerator/src/parallel-ir.jl:238    ParallelAccelerator.ParallelIR.RangeData  \u00b6  Holds the information from one Domain IR :range Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:377    ParallelAccelerator.ParallelIR.RemoveDeadState  \u00b6  Holds liveness information for the remove_dead AstWalk phase.  source:  ParallelAccelerator/src/parallel-ir.jl:2981    ParallelAccelerator.ParallelIR.RemoveNoDepsState  \u00b6  State for the remove_no_deps and insert_no_deps_beginning phases.  source:  ParallelAccelerator/src/parallel-ir.jl:3041    ParallelAccelerator.ParallelIR.ReplacedRegion  \u00b6  Store information about a section of a body that will be translated into a task.  source:  ParallelAccelerator/src/parallel-ir-task.jl:21    ParallelAccelerator.ParallelIR.RhsDead  \u00b6  Marks an assignment statement where the left-hand side can take over the storage from the right-hand side.  source:  ParallelAccelerator/src/parallel-ir-task.jl:577    ParallelAccelerator.ParallelIR.StatementWithDeps  \u00b6  Type for dependence graph creation and topological sorting.  source:  ParallelAccelerator/src/parallel-ir.jl:3848    ParallelAccelerator.ParallelIR.TaskInfo  \u00b6  Structure for storing information about task formation.  source:  ParallelAccelerator/src/parallel-ir-task.jl:36    ParallelAccelerator.ParallelIR.cur_body_data  \u00b6  Holds the data for substitute_cur_body AST walk.  source:  ParallelAccelerator/src/parallel-ir.jl:1460    ParallelAccelerator.ParallelIR.cuw_state  \u00b6  Just to hold the \"found\" Bool that says whether a unsafe variant was replaced with a regular version.  source:  ParallelAccelerator/src/parallel-ir-task.jl:907    ParallelAccelerator.ParallelIR.expr_state  \u00b6  State passed around while converting an AST from domain to parallel IR.  source:  ParallelAccelerator/src/parallel-ir.jl:245    ParallelAccelerator.ParallelIR.pir_arg_metadata  \u00b6  A Julia representation of the argument metadata that will be passed to the runtime.  source:  ParallelAccelerator/src/parallel-ir-task.jl:157    ParallelAccelerator.ParallelIR.pir_array_access_desc  \u00b6  Describes an array.\nrow_major is true if the array is stored in row major format.\ndim_info describes which portion of the array is accessed for a given point in the iteration space.  source:  ParallelAccelerator/src/parallel-ir-task.jl:111    ParallelAccelerator.ParallelIR.pir_grain_size  \u00b6  A Julia representation of the grain size that will be passed to the runtime.  source:  ParallelAccelerator/src/parallel-ir-task.jl:178    ParallelAccelerator.ParallelIR.pir_range  \u00b6  Translated to pert_range_Nd_t in the task runtime.\nThis represents an iteration space.\ndim is the number of dimensions in the iteration space.\nlower_bounds contains the lower bound of the iteration space in each dimension.\nupper_bounds contains the upper bound of the iteration space in each dimension.\nlower_bounds and upper_bounds can be expressions.  source:  ParallelAccelerator/src/parallel-ir-task.jl:56    ParallelAccelerator.ParallelIR.pir_range_actual  \u00b6  Similar to pir_range but used in circumstances where the expressions must have already been evaluated.\nTherefore the arrays are typed as Int64.\nUp to 3 dimensional iteration space constructors are supported to make it easier to do code generation later.  source:  ParallelAccelerator/src/parallel-ir-task.jl:70    ParallelAccelerator.ParallelIR.sub_arrayset_data  \u00b6  Holds data for modifying arrayset calls.  source:  ParallelAccelerator/src/parallel-ir.jl:1338", 
            "title": "where they can't prevent fusion."
        }, 
        {
            "location": "/ParallelAccelerator/", 
            "text": "ParallelAccelerator\n\n\nInternal\n\n\n\n\n\n\ninit\n() \n\u00b6\n\n\nCalled when the package is loaded to do initialization.\n\n\nsource:\n\n\nParallelAccelerator/src/ParallelAccelerator.jl:206\n\n\n\n\n\n\nembed() \n\u00b6\n\n\nThis version of embed tries to use JULIA_HOME to find the root of the source distribution.\nIt then calls the version above specifying the path.\n\n\nsource:\n\n\nParallelAccelerator/src/ParallelAccelerator.jl:185\n\n\n\n\n\n\nembed(julia_root) \n\u00b6\n\n\nCall this function if you want to embed binary-code of ParallelAccelerator into your Julia build to speed-up @acc compilation time.\nIt will attempt to add a userimg.jl file to your Julia distribution and then re-build Julia.\n\n\nsource:\n\n\nParallelAccelerator/src/ParallelAccelerator.jl:138\n\n\n\n\n\n\ngetPackageRoot() \n\u00b6\n\n\nGenerate a file path to the directory above the one containing this source file.\nThis should be the root of the package.\n\n\nsource:\n\n\nParallelAccelerator/src/ParallelAccelerator.jl:126\n\n\n\n\n\n\ngetPseMode() \n\u00b6\n\n\nReturn internal mode number by looking up environment variable \"PROSPECT_MODE\".\n\n\nsource:\n\n\nParallelAccelerator/src/ParallelAccelerator.jl:57\n\n\n\n\n\n\ngetTaskMode() \n\u00b6\n\n\nReturn internal mode number by looking up environment variable \"PROSPECT_TASK_MODE\".\nIf not specified, it defaults to NO_TASK_MODE, or DYNAMIC_TASK_MODE when \ngetPseMode() is TASK_MODE.\n\n\nsource:\n\n\nParallelAccelerator/src/ParallelAccelerator.jl:100", 
            "title": "ParallelAccelerator"
        }, 
        {
            "location": "/ParallelAccelerator/#parallelaccelerator", 
            "text": "", 
            "title": "ParallelAccelerator"
        }, 
        {
            "location": "/ParallelAccelerator/#internal", 
            "text": "init ()  \u00b6  Called when the package is loaded to do initialization.  source:  ParallelAccelerator/src/ParallelAccelerator.jl:206    embed()  \u00b6  This version of embed tries to use JULIA_HOME to find the root of the source distribution.\nIt then calls the version above specifying the path.  source:  ParallelAccelerator/src/ParallelAccelerator.jl:185    embed(julia_root)  \u00b6  Call this function if you want to embed binary-code of ParallelAccelerator into your Julia build to speed-up @acc compilation time.\nIt will attempt to add a userimg.jl file to your Julia distribution and then re-build Julia.  source:  ParallelAccelerator/src/ParallelAccelerator.jl:138    getPackageRoot()  \u00b6  Generate a file path to the directory above the one containing this source file.\nThis should be the root of the package.  source:  ParallelAccelerator/src/ParallelAccelerator.jl:126    getPseMode()  \u00b6  Return internal mode number by looking up environment variable \"PROSPECT_MODE\".  source:  ParallelAccelerator/src/ParallelAccelerator.jl:57    getTaskMode()  \u00b6  Return internal mode number by looking up environment variable \"PROSPECT_TASK_MODE\".\nIf not specified, it defaults to NO_TASK_MODE, or DYNAMIC_TASK_MODE when \ngetPseMode() is TASK_MODE.  source:  ParallelAccelerator/src/ParallelAccelerator.jl:100", 
            "title": "Internal"
        }, 
        {
            "location": "/ParallelIR/", 
            "text": "ParallelAccelerator.ParallelIR\n\n\nExported\n\n\n\n\n\n\nAstWalk(ast,  callback,  cbdata) \n\u00b6\n\n\nParallelIR version of AstWalk.\nInvokes the DomainIR version of AstWalk and provides the parallel IR AstWalk callback AstWalkCallback.\n\n\nParallel IR AstWalk calls Domain IR AstWalk which in turn calls CompilerTools.AstWalker.AstWalk.\nFor each AST node, CompilerTools.AstWalker.AstWalk calls Domain IR callback to give it a chance to handle the node if it is a Domain IR node.\nLikewise, Domain IR callback first calls Parallel IR callback to give it a chance to handle Parallel IR nodes.\nThe Parallel IR callback similarly first calls the user-level callback to give it a chance to process the node.\nIf a callback returns \"nothing\" it means it didn't modify that node and that the previous code should process it.\nThe Parallel IR callback will return \"nothing\" if the node isn't a Parallel IR node.\nThe Domain IR callback will return \"nothing\" if the node isn't a Domain IR node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4876\n\n\n\n\n\n\nPIRInplace(x) \n\u00b6\n\n\nIf set to non-zero, perform the phase where non-inplace maps are converted to inplace maps to reduce allocations.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3816\n\n\n\n\n\n\nPIRNumSimplify(x) \n\u00b6\n\n\nSpecify the number of passes over the AST that do things like hoisting and other rearranging to maximize fusion.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1672\n\n\n\n\n\n\nPIRRunAsTasks(x) \n\u00b6\n\n\nDebugging feature to specify the number of tasks to create and to stop thereafter.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1853\n\n\n\n\n\n\nPIRSetFuseLimit(x) \n\u00b6\n\n\nControl how many parfor can be fused for testing purposes.\n    -1 means fuse all possible parfors.\n    0  means don't fuse any parfors.\n    1+ means fuse the specified number of parfors but then stop fusing beyond that.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1667\n\n\n\n\n\n\nPIRShortcutArrayAssignment(x) \n\u00b6\n\n\nEnables an experimental mode where if there is a statement a = b and they are arrays and b is not live-out then \nuse a special assignment node like a move assignment in C++.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3842\n\n\n\n\n\n\nPIRTaskGraphMode(x) \n\u00b6\n\n\nControl how blocks of code are made into tasks.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:589\n\n\n\n\n\n\nfrom_exprs(ast::Array{Any, 1},  depth,  state) \n\u00b6\n\n\nProcess an array of expressions.\nDifferentiate between top-level arrays of statements and arrays of expression that may occur elsewhere than the :body Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2274\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.PIRLoopNest \n\u00b6\n\n\nHolds the information about a loop in a parfor node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:76\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.PIRParForAst \n\u00b6\n\n\nThe parfor AST node type.\nWhile we are lowering domain IR to parfors and fusing we use this representation because it\nmakes it easier to associate related statements before and after the loop to the loop itself.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:174\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.PIRReduction \n\u00b6\n\n\nHolds the information about a reduction in a parfor node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:86\n\n\nInternal\n\n\n\n\n\n\nAstWalkCallback(x::Expr,  dw::ParallelAccelerator.ParallelIR.DirWalk,  top_level_number::Int64,  is_top_level::Bool,  read::Bool) \n\u00b6\n\n\nAstWalk callback that handles ParallelIR AST node types.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4724\n\n\n\n\n\n\nEquivalenceClassesAdd(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  sym::Symbol) \n\u00b6\n\n\nAdd a symbol as part of a new equivalence class if the symbol wasn't already in an equivalence class.\nReturn the equivalence class for the symbol.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:139\n\n\n\n\n\n\nEquivalenceClassesClear(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses) \n\u00b6\n\n\nClear an equivalence class.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:153\n\n\n\n\n\n\nEquivalenceClassesMerge(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  merge_to::Symbol,  merge_from::Symbol) \n\u00b6\n\n\nAt some point we realize that two arrays must have the same dimensions but up until that point\nwe might not have known that.  In which case they will start in different equivalence classes,\nmerge_to and merge_from, but need to be combined into one equivalence class.\nGo through the equivalence class dictionary and for any symbol belonging to the merge_from\nequivalence class, change it to now belong to the merge_to equivalence class.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:123\n\n\n\n\n\n\nPIRBbReorder(x) \n\u00b6\n\n\nIf set to non-zero, perform the bubble-sort like reordering phase to coalesce more parfor nodes together for fusion.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3832\n\n\n\n\n\n\nPIRHoistAllocation(x) \n\u00b6\n\n\nIf set to non-zero, perform the rearrangement phase that tries to moves alllocations outside of loops.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3824\n\n\n\n\n\n\nTypedExpr(typ,  rest...) \n\u00b6\n\n\nThis should pretty always be used instead of Expr(...) to form an expression as it forces the typ to be provided.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:67\n\n\n\n\n\n\naddUnknownArray(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nGiven an array whose name is in \"x\", allocate a new equivalence class for this array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:746\n\n\n\n\n\n\naddUnknownRange(x::Array{Any, 1},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nGiven an array of RangeExprs describing loop nest ranges, allocate a new equivalence class for this range.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:755\n\n\n\n\n\n\nadd_merge_correlations(old_sym::Union{GenSym, Symbol},  new_sym::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nIf we somehow determine that two arrays must be the same length then \nget the equivalence classes for the two arrays and merge those equivalence classes together.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:792\n\n\n\n\n\n\nasArray(x) \n\u00b6\n\n\nReturn one element array with element x.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4715\n\n\n\n\n\n\naugment_sn(dim::Int64,  index_vars,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1}) \n\u00b6\n\n\nMake sure the index parameters to arrayref or arrayset are Int64 or SymbolNode.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:29\n\n\n\n\n\n\ncall_instruction_count(args,  state::ParallelAccelerator.ParallelIR.eic_state,  debug_level) \n\u00b6\n\n\nGenerate an instruction count estimate for a call instruction.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:352\n\n\n\n\n\n\ncheckAndAddSymbolCorrelation(lhs::Union{GenSym, Symbol},  state,  dim_array) \n\u00b6\n\n\nMake sure all the dimensions are SymbolNodes.\nMake sure each dimension variable is assigned to only once in the function.\nExtract just the dimension variables names into dim_names and then register the correlation from lhs to those dimension names.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3277\n\n\n\n\n\n\nconvertUnsafe(stmt) \n\u00b6\n\n\nRemove unsafe array access Symbols from the incoming \"stmt\".\nReturns the updated statement if something was modifed, else returns \"nothing\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:951\n\n\n\n\n\n\nconvertUnsafeOrElse(stmt) \n\u00b6\n\n\nTry to remove unsafe array access Symbols from the incoming \"stmt\".  If successful, then return the updated\nstatement, else return the unmodified statement.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:970\n\n\n\n\n\n\nconvertUnsafeWalk(x::Expr,  state,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nThe AstWalk callback to find unsafe arrayset and arrayref variants and\nreplace them with the regular Julia versions.  Sets the \"found\" flag\nin the state when such a replacement is performed.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:919\n\n\n\n\n\n\ncopy_propagate(node::ANY,  data::ParallelAccelerator.ParallelIR.CopyPropagateState,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nIn each basic block, if there is a \"copy\" (i.e., something of the form \"a = b\") then put\nthat in copies as copies[a] = b.  Then, later in the basic block if you see the symbol\n\"a\" then replace it with \"b\".  Note that this is not SSA so \"a\" may be written again\nand if it is then it must be removed from copies.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2849\n\n\n\n\n\n\ncount_assignments(x,  symbol_assigns::Dict{Symbol, Int64},  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAstWalk callback to count the number of static times that a symbol is assigne within a method.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:920\n\n\n\n\n\n\ncreate1D_array_access_desc(array::SymbolNode) \n\u00b6\n\n\nCreate an array access descriptor for \"array\".\nPresumes that for point \"i\" in the iteration space that only index \"i\" is accessed.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:124\n\n\n\n\n\n\ncreate2D_array_access_desc(array::SymbolNode) \n\u00b6\n\n\nCreate an array access descriptor for \"array\".\nPresumes that for points \"(i,j)\" in the iteration space that only indices \"(i,j)\" is accessed.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:134\n\n\n\n\n\n\ncreateInstructionCountEstimate(the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nTakes a parfor and walks the body of the parfor and estimates the number of instruction needed for one instance of that body.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:557\n\n\n\n\n\n\ncreateLoweredAliasMap(dict1) \n\u00b6\n\n\nTake a single-step alias map, e.g., a=\nb, b=\nc, and create a lowered dictionary, a=\nc, b=\nc, that\nmaps each array to the transitively lowered array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1840\n\n\n\n\n\n\ncreateMapLhsToParfor(parfor_assignment,  the_parfor,  is_multi::Bool,  sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nCreates a mapping between variables on the left-hand side of an assignment where the right-hand side is a parfor\nand the arrays or scalars in that parfor that get assigned to the corresponding parts of the left-hand side.\nReturns a tuple where the first element is a map for arrays between left-hand side and parfor and the second\nelement is a map for reduction scalars between left-hand side and parfor.\nis_multi is true if the assignment is a fusion assignment.\nparfor_assignment is the AST of the whole expression.\nthe_parfor is the PIRParForAst type part of the incoming assignment.\nsym_to_type is an out parameter that maps symbols in the output mapping to their types.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1774\n\n\n\n\n\n\ncreateStateVar(state,  name,  typ,  access) \n\u00b6\n\n\nAdd a local variable to the current function's lambdaInfo.\nReturns a symbol node of the new variable.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:639\n\n\n\n\n\n\ncreateTempForArray(array_sn::Union{GenSym, Symbol, SymbolNode},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nCreate a temporary variable that is parfor private to hold the value of an element of an array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:647\n\n\n\n\n\n\ncreateTempForRangeOffset(num_used,  ranges::Array{ParallelAccelerator.ParallelIR.RangeData, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nCreate a variable to hold the offset of a range offset from the start of the array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:322\n\n\n\n\n\n\ncreateTempForRangedArray(array_sn::Union{GenSym, Symbol, SymbolNode},  range::Array{Union{GenSym, SymbolNode}, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nCreate a temporary variable that is parfor private to hold the value of an element of an array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:338\n\n\n\n\n\n\ncreate_array_access_desc(array::SymbolNode) \n\u00b6\n\n\nCreate an array access descriptor for \"array\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:144\n\n\n\n\n\n\ncreate_equivalence_classes(node::Expr,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level_number::Int64,  is_top_level::Bool,  read::Bool) \n\u00b6\n\n\nAstWalk callback to determine the array equivalence classes.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3405\n\n\n\n\n\n\ndfsVisit(swd::ParallelAccelerator.ParallelIR.StatementWithDeps,  vtime::Int64,  topo_sort::Array{ParallelAccelerator.ParallelIR.StatementWithDeps, N}) \n\u00b6\n\n\nConstruct a topological sort of the dependence graph.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3863\n\n\n\n\n\n\nestimateInstrCount(ast::Expr,  state::ParallelAccelerator.ParallelIR.eic_state,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAstWalk callback for estimating the instruction count.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:474\n\n\n\n\n\n\nextractArrayEquivalencies(node::Expr,  state) \n\u00b6\n\n\n\"node\" is a domainIR node.  Take the arrays used in this node, create an array equivalence for them if they \ndon't already have one and make sure they all share one equivalence class.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3215\n\n\n\n\n\n\nfindSelectedDimensions(inputInfo::Array{ParallelAccelerator.ParallelIR.InputInfo, 1},  state) \n\u00b6\n\n\nGiven all the InputInfo for a Domain IR operation being lowered to Parallel IR,\ndetermine the number of output dimensions for those arrays taking into account\nthat singly selected trailing dimensinos are eliminated.  Make sure that all such\narrays have the same output dimensions because this will match the loop nest size.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:745\n\n\n\n\n\n\nflattenParfor(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst) \n\u00b6\n\n\nTakes a new array of body statements in the process of construction in \"new_body\" and takes a parfor to add to that\nbody.  This parfor is in the nested (parfor code is in the parfor node itself) temporary form we use for fusion although \npre-statements and post-statements are already elevated by this point.  We replace this nested form with a non-nested\nform where we have a parfor_start and parfor_end to delineate the parfor code.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-flatten.jl:94\n\n\n\n\n\n\nfrom_assertEqShape(node::Expr,  state) \n\u00b6\n\n\nCreate array equivalences from an assertEqShape AST node.\nThere are two arrays in the args to assertEqShape.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2604\n\n\n\n\n\n\nfrom_assignment(lhs,  rhs,  depth,  state) \n\u00b6\n\n\nProcess an assignment expression.\nStarts by recurisvely processing the right-hand side of the assignment.\nEliminates the assignment of a=b if a is dead afterwards and b has no side effects.\n    Does some array equivalence class work which may be redundant given that we now run a separate equivalence class pass so consider removing that part of this code.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2685\n\n\n\n\n\n\nfrom_call(ast::Array{Any, 1},  depth,  state) \n\u00b6\n\n\nProcess a call AST node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2807\n\n\n\n\n\n\nfrom_expr(ast::Expr,  depth,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level) \n\u00b6\n\n\nThe main ParallelIR function for processing some node in the AST.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4546\n\n\n\n\n\n\nfrom_lambda(lambda::Expr,  depth,  state) \n\u00b6\n\n\nProcess a :lambda Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:946\n\n\n\n\n\n\nfrom_root(function_name,  ast::Expr) \n\u00b6\n\n\nThe main ENTRY point into ParallelIR.\n1) Do liveness analysis.\n2) Convert mmap to mmap! where possible.\n3) Do some code rearrangement (e.g., hoisting) to maximize later fusion.\n4) Create array equivalence classes within the function.\n5) Rearrange statements within a basic block to push domain operations to the bottom so more fusion.\n6) Call the main from_expr to process the AST for the function.  This will\na) Lower domain IR to parallel IR AST nodes.\nb) Fuse parallel IR nodes where possible.\nc) Convert to task IR nodes if task mode enabled.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4208\n\n\n\n\n\n\nfullyLowerAlias(dict::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  input::Union{GenSym, Symbol}) \n\u00b6\n\n\nGiven an \"input\" Symbol, use that Symbol as key to a dictionary.  While such a Symbol is present\nin the dictionary replace it with the corresponding value from the dict.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1829\n\n\n\n\n\n\nfuse(body,  body_index,  cur,  state) \n\u00b6\n\n\nTest whether we can fuse the two most recent parfor statements and if so to perform that fusion.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1871\n\n\n\n\n\n\ngenerate_instr_count(function_name,  signature) \n\u00b6\n\n\nTry to figure out the instruction count for a given call.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:398\n\n\n\n\n\n\ngetArrayElemType(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturns the element type of an Array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:611\n\n\n\n\n\n\ngetArrayElemType(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturns the element type of an Array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:604\n\n\n\n\n\n\ngetArrayElemType(atyp::DataType) \n\u00b6\n\n\nReturns the element type of an Array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:591\n\n\n\n\n\n\ngetArrayNumDims(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturn the number of dimensions of an Array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:628\n\n\n\n\n\n\ngetArrayNumDims(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturn the number of dimensions of an Array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:619\n\n\n\n\n\n\ngetConstDims(num_dim_inputs,  inputInfo::ParallelAccelerator.ParallelIR.InputInfo) \n\u00b6\n\n\nIn the case where a domain IR operation on an array creates a lower dimensional output,\nthe indexing expression needs the expression that selects those constant trailing dimensions\nthat are being dropped.  This function returns an array of those constant expressions for\nthe trailing dimensions.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:766\n\n\n\n\n\n\ngetCorrelation(sng::Union{GenSym, Symbol, SymbolNode},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nGet the equivalence class of a domain IR input in inputInfo.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1747\n\n\n\n\n\n\ngetFirstArrayLens(prestatements,  num_dims) \n\u00b6\n\n\nGet the variable which holds the length of the first input array to a parfor.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1438\n\n\n\n\n\n\ngetIO(stmt_ids,  bb_statements) \n\u00b6\n\n\nGiven a set of statement IDs and liveness information for the statements of the function, determine\nwhich symbols are needed at input and which symbols are purely local to the functio.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:840\n\n\n\n\n\n\ngetInputSet(node::ParallelAccelerator.ParallelIR.PIRParForAst) \n\u00b6\n\n\nReturns a Set with all the arrays read by this parfor.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1106\n\n\n\n\n\n\ngetLhsFromAssignment(assignment) \n\u00b6\n\n\nGet the left-hand side of an assignment expression.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1077\n\n\n\n\n\n\ngetLhsOutputSet(lhs,  assignment) \n\u00b6\n\n\nGet the real outputs of an assignment statement.\nIf the assignment expression is normal then the output is just the left-hand side.\nIf the assignment expression is augmented with a FusionSentinel then the real outputs\nare the 4+ arguments to the expression.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1121\n\n\n\n\n\n\ngetMaxLabel(max_label,  stmts::Array{Any, 1}) \n\u00b6\n\n\nScan the body of a function in \"stmts\" and return the max label in a LabelNode AST seen in the body.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4026\n\n\n\n\n\n\ngetNonBlock(head_preds,  back_edge) \n\u00b6\n\n\nFind the basic block before the entry to a loop.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:5\n\n\n\n\n\n\ngetOrAddArrayCorrelation(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturn a correlation set for an array.  If the array was not previously added then add it and return it.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:802\n\n\n\n\n\n\ngetOrAddRangeCorrelation(ranges::Array{ParallelAccelerator.ParallelIR.RangeExprs, 1},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nGets (or adds if absent) the range correlation for the given array of RangeExprs.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:813\n\n\n\n\n\n\ngetOrAddSymbolCorrelation(array::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state,  dims::Array{Union{GenSym, Symbol}, 1}) \n\u00b6\n\n\nA new array is being created with an explicit size specification in dims.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:832\n\n\n\n\n\n\ngetParforCorrelation(parfor,  state) \n\u00b6\n\n\nGet the equivalence class of the first array who length is extracted in the pre-statements of the specified \"parfor\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1740\n\n\n\n\n\n\ngetParforNode(node) \n\u00b6\n\n\nGet the parfor object from either a bare parfor or one part of an assignment.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1059\n\n\n\n\n\n\ngetPrivateSet(body::Array{Any, 1}) \n\u00b6\n\n\nGo through the body of a parfor and collect those Symbols, GenSyms, etc. that are assigned to within the parfor except reduction variables.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:898\n\n\n\n\n\n\ngetPrivateSetInner(x::Expr,  state::Set{Union{GenSym, Symbol, SymbolNode}},  top_level_number::Int64,  is_top_level::Bool,  read::Bool) \n\u00b6\n\n\nThe AstWalk callback function for getPrivateSet.\nFor each AST in a parfor body, if the node is an assignment or loop head node then add the written entity to the state.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:868\n\n\n\n\n\n\ngetRhsFromAssignment(assignment) \n\u00b6\n\n\nGet the right-hand side of an assignment expression.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1070\n\n\n\n\n\n\ngetSName(ssn::Symbol) \n\u00b6\n\n\nGet the name of a symbol whether the input is a Symbol or SymbolNode or :(::) Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2237\n\n\n\n\n\n\nget_one(ast::Array{T, N}) \n\u00b6\n\n\nTake something returned from AstWalk and assert it should be an array but in this\ncontext that the array should also be of length 1 and then return that single element.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4700\n\n\n\n\n\n\nget_unique_num() \n\u00b6\n\n\nIf we need to generate a name and make sure it is unique then include an monotonically increasing number.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:853\n\n\n\n\n\n\nhasNoSideEffects(node::Union{GenSym, LambdaStaticData, Number, Symbol, SymbolNode}) \n\u00b6\n\n\nSometimes statements we exist in the AST of the form a=Expr where a is a Symbol that isn't live past the assignment\nand we'd like to eliminate the whole assignment statement but we have to know that the right-hand side has no\nside effects before we can do that.  This function says whether the right-hand side passed into it has side effects\nor not.  Several common function calls that otherwise we wouldn't know are safe are explicitly checked for.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2547\n\n\n\n\n\n\nhasSymbol(ssn::Symbol) \n\u00b6\n\n\nReturns true if the incoming AST node can be interpreted as a Symbol.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2218\n\n\n\n\n\n\nhoistAllocation(ast::Array{Any, 1},  lives,  domLoop::CompilerTools.Loops.DomLoops,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nTry to hoist allocations outside the loop if possible.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3698\n\n\n\n\n\n\ninsert_no_deps_beginning(node,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nWorks with remove_no_deps below to move statements with no dependencies to the beginning of the AST.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3055\n\n\n\n\n\n\nintermediate_from_exprs(ast::Array{Any, 1},  depth,  state) \n\u00b6\n\n\nProcess an array of expressions that aren't from a :body Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2288\n\n\n\n\n\n\nisArrayType(typ) \n\u00b6\n\n\nReturns true if the incoming type in \"typ\" is an array type.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:584\n\n\n\n\n\n\nisArrayType(x::SymbolNode) \n\u00b6\n\n\nReturns true if a given SymbolNode \"x\" is an Array type.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2316\n\n\n\n\n\n\nisArrayref(x) \n\u00b6\n\n\nIs a node an arrayref node?\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1356\n\n\n\n\n\n\nisArrayrefCall(x::Expr) \n\u00b6\n\n\nIs a node a call to arrayref.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1377\n\n\n\n\n\n\nisArrayset(x) \n\u00b6\n\n\nIs a node an arrayset node?\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1346\n\n\n\n\n\n\nisArraysetCall(x::Expr) \n\u00b6\n\n\nIs a node a call to arrayset.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1366\n\n\n\n\n\n\nisAssignmentNode(node::Expr) \n\u00b6\n\n\nIs a node an assignment expression node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:987\n\n\n\n\n\n\nisBareParfor(node::Expr) \n\u00b6\n\n\nIs this a parfor node not part of an assignment statement.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1009\n\n\n\n\n\n\nisDomainNode(ast::Expr) \n\u00b6\n\n\nReturns true if the given \"ast\" node is a DomainIR operation.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3882\n\n\n\n\n\n\nisFusionAssignment(x::Expr) \n\u00b6\n\n\nCheck if an assignement is a fusion assignment.\n    In regular assignments, there are only two args, the left and right hand sides.\n    In fusion assignments, we introduce a third arg that is marked by an object of FusionSentinel type.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1700\n\n\n\n\n\n\nisLoopheadNode(node::Expr) \n\u00b6\n\n\nIs a node a loophead expression node (a form of assignment).\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:998\n\n\n\n\n\n\nisParforAssignmentNode(node::Expr) \n\u00b6\n\n\nIs a node an assignment expression with a parfor node as the right-hand side.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1033\n\n\n\n\n\n\nisSymbolsUsed(vars,  top_level_numbers::Array{Int64, 1},  state) \n\u00b6\n\n\nReturns true if any variable in the collection \"vars\" is used in any statement whose top level number is in \"top_level_numbers\".\n    We use expr_state \"state\" to get the block liveness information from which we use \"def\" and \"use\" to determine if a variable\n        usage is present.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1716\n\n\n\n\n\n\nis_eliminated_arraylen(x::Expr) \n\u00b6\n\n\nReturns true if the input node is an assignment node where the right-hand side is a call to arraysize.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1589\n\n\n\n\n\n\nisbitstuple(a::Tuple) \n\u00b6\n\n\nReturns true if input \"a\" is a tuple and each element of the tuple of isbits type.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4493\n\n\n\n\n\n\niterations_equals_inputs(node::ParallelAccelerator.ParallelIR.PIRParForAst) \n\u00b6\n\n\nReturns true if the domain operation mapped to this parfor has the property that the iteration space\nis identical to the dimenions of the inputs.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1086\n\n\n\n\n\n\nlambdaFromDomainLambda(domain_lambda,  dl_inputs) \n\u00b6\n\n\nForm a Julia :lambda Expr from a DomainLambda.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4038\n\n\n\n\n\n\nmakePrivateParfor(var_name::Symbol,  state) \n\u00b6\n\n\nTakes an existing variable whose name is in \"var_name\" and adds the descriptor flag ISPRIVATEPARFORLOOP to declare the\nvariable to be parfor loop private and eventually go in an OMP private clause.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:659\n\n\n\n\n\n\nmakeTasks(start_index,  stop_index,  body,  bb_live_info,  state,  task_graph_mode) \n\u00b6\n\n\nFor a given start and stop index in some body and liveness information, form a set of tasks.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:759\n\n\n\n\n\n\nmaxFusion(bl::CompilerTools.LivenessAnalysis.BlockLiveness) \n\u00b6\n\n\nFor every basic block, try to push domain IR statements down and non-domain IR statements up so that domain nodes\nare next to each other and can be fused.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3926\n\n\n\n\n\n\nmergeLambdaIntoOuterState(state,  inner_lambda::Expr) \n\u00b6\n\n\nPull the information from the inner lambda into the outer lambda.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1218\n\n\n\n\n\n\nmerge_correlations(state,  unchanging,  eliminate) \n\u00b6\n\n\nIf we somehow determine that two sets of correlations are actually the same length then merge one into the other.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:764\n\n\n\n\n\n\nmk_alloc_array_1d_expr(elem_type,  atype,  length) \n\u00b6\n\n\nReturn an expression that allocates and initializes a 1D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and a \"length\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:496\n\n\n\n\n\n\nmk_alloc_array_2d_expr(elem_type,  atype,  length1,  length2) \n\u00b6\n\n\nReturn an expression that allocates and initializes a 2D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and two dimensions of length in \"length1\" and \"length2\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:534\n\n\n\n\n\n\nmk_alloc_array_3d_expr(elem_type,  atype,  length1,  length2,  length3) \n\u00b6\n\n\nReturn an expression that allocates and initializes a 3D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and two dimensions of length in \"length1\" and \"length2\" and \"length3\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:560\n\n\n\n\n\n\nmk_arraylen_expr(x::ParallelAccelerator.ParallelIR.InputInfo,  dim::Int64) \n\u00b6\n\n\nCreate an expression whose value is the length of the input array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:447\n\n\n\n\n\n\nmk_arraylen_expr(x::Union{GenSym, Symbol, SymbolNode},  dim::Int64) \n\u00b6\n\n\nCreate an expression whose value is the length of the input array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:440\n\n\n\n\n\n\nmk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturn an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:54\n\n\n\n\n\n\nmk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1}) \n\u00b6\n\n\nReturn an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:54\n\n\n\n\n\n\nmk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1}) \n\u00b6\n\n\nReturn an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:54\n\n\n\n\n\n\nmk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturn a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:85\n\n\n\n\n\n\nmk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1}) \n\u00b6\n\n\nReturn a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:85\n\n\n\n\n\n\nmk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1}) \n\u00b6\n\n\nReturn a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:85\n\n\n\n\n\n\nmk_assignment_expr(lhs::Union{GenSym, Symbol, SymbolNode},  rhs,  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nCreate an assignment expression AST node given a left and right-hand side.\nThe left-hand side has to be a symbol node from which we extract the type so as to type the new Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:353\n\n\n\n\n\n\nmk_colon_expr(start_expr,  skip_expr,  end_expr) \n\u00b6\n\n\nReturns an expression to construct a :colon object that contains the start of a range, the end and the skip expression.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:878\n\n\n\n\n\n\nmk_convert(new_type,  ex) \n\u00b6\n\n\nReturns an expression that convert \"ex\" into a another type \"new_type\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:473\n\n\n\n\n\n\nmk_gotoifnot_expr(cond,  goto_label) \n\u00b6\n\n\nReturns a :gotoifnot Expr given a condition \"cond\" and a label \"goto_label\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:900\n\n\n\n\n\n\nmk_next_expr(colon_sym,  start_sym) \n\u00b6\n\n\nReturns a :next call Expr that gets the next element of an iteration range from a :colon object.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:892\n\n\n\n\n\n\nmk_parallelir_ref(sym) \n\u00b6\n\n\nCreate an expression that references something inside ParallelIR.\nIn other words, returns an expression the equivalent of ParallelAccelerator.ParallelIR.sym where sym is an input argument to this function.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:465\n\n\n\n\n\n\nmk_parallelir_ref(sym,  ref_type) \n\u00b6\n\n\nCreate an expression that references something inside ParallelIR.\nIn other words, returns an expression the equivalent of ParallelAccelerator.ParallelIR.sym where sym is an input argument to this function.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:465\n\n\n\n\n\n\nmk_parfor_args_from_mmap!(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  with_indices,  domain_oprs,  state) \n\u00b6\n\n\nThe main routine that converts a mmap! AST node to a parfor AST node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:498\n\n\n\n\n\n\nmk_parfor_args_from_mmap(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  domain_oprs,  state) \n\u00b6\n\n\nThe main routine that converts a mmap AST node to a parfor AST node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:789\n\n\n\n\n\n\nmk_parfor_args_from_reduce(input_args::Array{Any, 1},  state) \n\u00b6\n\n\nThe main routine that converts a reduce AST node to a parfor AST node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:119\n\n\n\n\n\n\nmk_return_expr(outs) \n\u00b6\n\n\nGiven an array of outputs in \"outs\", form a return expression.\nIf there is only one out then the args of :return is just that expression.\nIf there are multiple outs then form a tuple of them and that tuple goes in :return args.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:338\n\n\n\n\n\n\nmk_start_expr(colon_sym) \n\u00b6\n\n\nReturns an expression to get the start of an iteration range from a :colon object.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:885\n\n\n\n\n\n\nmk_svec_expr(parts...) \n\u00b6\n\n\nMake a svec expression.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:487\n\n\n\n\n\n\nmk_tuple_expr(tuple_fields,  typ) \n\u00b6\n\n\nReturn an expression which creates a tuple.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1151\n\n\n\n\n\n\nmk_tupleref_expr(tuple_var,  index,  typ) \n\u00b6\n\n\nCreate an expression which returns the index'th element of the tuple whose name is contained in tuple_var.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:480\n\n\n\n\n\n\nmk_untyped_assignment(lhs,  rhs) \n\u00b6\n\n\nOnly used to create fake expression to force lhs to be seen as written rather than read.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:370\n\n\n\n\n\n\nmmapInline(ast::Expr,  lives,  uniqSet) \n\u00b6\n\n\nIf a definition of a mmap is only used once and not aliased, it can be inlined into its\n\n\nuse side as long as its dependencies have not been changed.\n\n\nFIXME: is the implementation still correct when branches are present?\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3621\n\n\n\n\n\n\nmmapToMmap!(ast,  lives,  uniqSet) \n\u00b6\n\n\nPerforms the mmap to mmap! phase.\nIf the arguments of a mmap dies aftewards, and is not aliased, then\nwe can safely change the mmap to mmap!.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3764\n\n\n\n\n\n\nmustRemainLastStatementInBlock(node::GotoNode) \n\u00b6\n\n\nReturns true if the given AST \"node\" must remain the last statement in a basic block.\nThis is true if the node is a GotoNode or a :gotoifnot Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3910\n\n\n\n\n\n\nnameToSymbolNode(name::Symbol,  sym_to_type) \n\u00b6\n\n\nForms a SymbolNode given a symbol in \"name\" and get the type of that symbol from the incoming dictionary \"sym_to_type\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1159\n\n\n\n\n\n\nnested_function_exprs(max_label,  domain_lambda,  dl_inputs) \n\u00b6\n\n\nA routine similar to the main parallel IR entry put but designed to process the lambda part of\ndomain IR AST nodes.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4067\n\n\n\n\n\n\nnext_label(state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nReturns the next usable label for the current function.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:738\n\n\n\n\n\n\noneIfOnly(x) \n\u00b6\n\n\nReturns a single element of an array if there is only one or the array otherwise.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1860\n\n\n\n\n\n\nparforToTask(parfor_index,  bb_statements,  body,  state) \n\u00b6\n\n\nGiven a parfor statement index in \"parfor_index\" in the \"body\"'s statements, create a TaskInfo node for this parfor.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:1190\n\n\n\n\n\n\npirPrintDl(dbg_level,  dl) \n\u00b6\n\n\nDebug print the parts of a DomainLambda.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4017\n\n\n\n\n\n\npir_alias_cb(ast::Expr,  state,  cbdata) \n\u00b6\n\n\nAn AliasAnalysis callback (similar to LivenessAnalysis callback) that handles ParallelIR introduced AST node types.\nFor each ParallelIR specific node type, form an array of expressions that AliasAnalysis\n    can analyze to reflect the aliases of the given AST node.\n    If we read a symbol it is sufficient to just return that symbol as one of the expressions.\n    If we write a symbol, then form a fake mk_assignment_expr just to get liveness to realize the symbol is written.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4884\n\n\n\n\n\n\npir_live_cb(ast::Expr,  cbdata::ANY) \n\u00b6\n\n\nA LivenessAnalysis callback that handles ParallelIR introduced AST node types.\nFor each ParallelIR specific node type, form an array of expressions that liveness\ncan analysis to reflect the read/write set of the given AST node.\nIf we read a symbol it is sufficient to just return that symbol as one of the expressions.\nIf we write a symbol, then form a fake mk_assignment_expr just to get liveness to realize the symbol is written.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2412\n\n\n\n\n\n\npir_live_cb_def(x) \n\u00b6\n\n\nJust call the AST walker for symbol for parallel IR nodes with no state.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:939\n\n\n\n\n\n\nprintBody(dlvl,  body::Array{Any, 1}) \n\u00b6\n\n\nPretty print the args part of the \"body\" of a :lambda Expr at a given debug level in \"dlvl\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2327\n\n\n\n\n\n\nprintLambda(dlvl,  node::Expr) \n\u00b6\n\n\nPretty print a :lambda Expr in \"node\" at a given debug level in \"dlvl\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2340\n\n\n\n\n\n\nprocessAndUpdateBody(lambda::Expr,  f::Function,  state) \n\u00b6\n\n\nApply a function \"f\" that takes the :body from the :lambda and returns a new :body that is stored back into the :lambda.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3295\n\n\n\n\n\n\nrangeSize(start,  skip,  last) \n\u00b6\n\n\nCompute size of a range.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:432\n\n\n\n\n\n\nrangeToRangeData(range::Expr,  pre_offsets::Array{Expr, 1},  arr,  range_num::Int64,  state) \n\u00b6\n\n\nConvert a :range Expr introduced by Domain IR into a Parallel IR data structure RangeData.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:354\n\n\n\n\n\n\nrecreateLoops(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state,  newLambdaInfo) \n\u00b6\n\n\nIn threads mode, we can't have parfor_start and parfor_end in the code since Julia has to compile the code itself and so\nwe have to reconstruct a loop infrastructure based on the parfor's loop nest information.  This function takes a parfor\nand outputs that parfor to the new function body as regular Julia loops.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:1156\n\n\n\n\n\n\nrecreateLoopsInternal(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  loop_nest_level,  next_available_label,  state,  newLambdaInfo) \n\u00b6\n\n\nThis is a recursive routine to reconstruct a regular Julia loop nest from the loop nests described in PIRParForAst.\nOne call of this routine handles one level of the loop nest.\nIf the incoming loop nest level is more than the number of loops nests in the parfor then that is the spot to\ninsert the body of the parfor into the new function body in \"new_body\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:1020\n\n\n\n\n\n\nrememberTypeForSym(sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  sym::Union{GenSym, Symbol},  typ::DataType) \n\u00b6\n\n\nAdd to the map of symbol names to types.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1679\n\n\n\n\n\n\nremoveAssertEqShape(args::Array{Any, 1},  state) \n\u00b6\n\n\nImplements one of the main ParallelIR passes to remove assertEqShape AST nodes from the body if they are statically known to be in the same equivalence class.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2588\n\n\n\n\n\n\nremoveNothingStmts(args::Array{Any, 1},  state) \n\u00b6\n\n\nEmpty statements can be added to the AST by some passes in ParallelIR.\nThis pass over the statements of the :body excludes such \"nothing\" statements from the new :body.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3306\n\n\n\n\n\n\nremove_dead(node,  data::ParallelAccelerator.ParallelIR.RemoveDeadState,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAn AstWalk callback that uses liveness information in \"data\" to remove dead stores.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2988\n\n\n\n\n\n\nremove_extra_allocs(ast) \n\u00b6\n\n\nremoves extra allocations\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4363\n\n\n\n\n\n\nremove_no_deps(node::ANY,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nThis routine gathers up nodes that do not use\n\n\nany variable and removes them from the AST into top_level_no_deps.  This works in conjunction with\n\n\ninsert_no_deps_beginning above to move these statements with no dependencies to the beginning of the AST\n\n\nwhere they can't prevent fusion.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3071\n\n\n\n\n\n\nreplaceParforWithDict(parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  gensym_map) \n\u00b6\n\n\nNot currently used but might need it at some point.\nSearch a whole PIRParForAst object and replace one SymAllGen with another.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:216\n\n\n\n\n\n\nrun_as_task() \n\u00b6\n\n\nReturn true if run_as_task_decrement would return true but don't update the run_as_tasks count.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:229\n\n\n\n\n\n\nrun_as_task_decrement() \n\u00b6\n\n\nIf run_as_tasks is positive then convert this parfor to a task and decrement the count so that only the\noriginal number run_as_tasks if the number of tasks created.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:215\n\n\n\n\n\n\nselectToRangeData(select::Expr,  pre_offsets::Array{Expr, 1},  state) \n\u00b6\n\n\nConvert the range(s) part of a :select Expr introduced by Domain IR into an array of Parallel IR data structures RangeData.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-mk-parfor.jl:371\n\n\n\n\n\n\nseqTask(body_indices,  bb_statements,  body,  state) \n\u00b6\n\n\nForm a task out of a range of sequential statements.\nThis is not currently implemented.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:1538\n\n\n\n\n\n\nshow(io::IO,  pnode::ParallelAccelerator.ParallelIR.PIRParForAst) \n\u00b6\n\n\nOverload of Base.show to pretty print for parfor AST nodes.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:273\n\n\n\n\n\n\nsimpleIndex(dict) \n\u00b6\n\n\nReturns true if all array references use singular index variables and nothing more complicated involving,\nfor example, addition or subtraction by a constant.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:668\n\n\n\n\n\n\nsub_arraylen_walk(x::Expr,  replacement,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAstWalk callback that does the work of substitute_arraylen on a node-by-node basis.\nreplacement is an array containing the length of the dimensions of the arrays a part of this parfor.\nIf we see a call to create an array, replace the length params with those in the common set in \"replacement\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1620\n\n\n\n\n\n\nsub_arrayset_walk(x::Expr,  cbd,  top_level_number,  is_top_level,  read) \n\u00b6\n\n\nAstWalk callback that does the work of substitute_arrayset on a node-by-node basis.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1388\n\n\n\n\n\n\nsub_cur_body_walk(x::Expr,  cbd::ParallelAccelerator.ParallelIR.cur_body_data,  top_level_number::Int64,  is_top_level::Bool,  read::Bool) \n\u00b6\n\n\nAstWalk callback that does the work of substitute_cur_body on a node-by-node basis.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1471\n\n\n\n\n\n\nsubstitute_arraylen(x,  replacement) \n\u00b6\n\n\nreplacement is an array containing the length of the dimensions of the arrays a part of this parfor.\nIf we see a call to create an array, replace the length params with those in the common set in \"replacement\".\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1652\n\n\n\n\n\n\nsubstitute_arrayset(x,  arrays_set_in_cur_body,  output_items_with_aliases) \n\u00b6\n\n\nModify the body of a parfor.\ntemp_map holds a map of array names whose arraysets should be turned into a mapped variable instead of the arrayset. a[i] = b. a=\nc. becomes c = b\nmap_for_non_eliminated holds arrays for which we need to add a variable to save the value but we can't eiminate the arrayset. a[i] = b. a=\nc. becomes c = a[i] = b\n    map_drop_arrayset drops the arrayset without replacing with a variable.  This is because a variable was previously added here with a map_for_non_eliminated case.\n    a[i] = b. becomes b\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1433\n\n\n\n\n\n\nsubstitute_cur_body(x,  temp_map::Dict{Union{GenSym, Symbol}, Union{GenSym, SymbolNode}},  index_map::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  arrays_set_in_cur_body::Set{Union{GenSym, Symbol}},  replace_array_name_in_arrayset::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  state::ParallelAccelerator.ParallelIR.expr_state) \n\u00b6\n\n\nMake changes to the second parfor body in the process of parfor fusion.\ntemp_map holds array names for which arrayrefs should be converted to a variable.  a[i].  a=\nb. becomes b\n    index_map holds maps between index variables.  The second parfor is modified to use the index variable of the first parfor.\n    arrays_set_in_cur_body           # Used as output.  Collects the arrays set in the current body.\n    replace_array_name_in_arrayset   # Map from one array to another.  Replace first array with second when used in arrayset context.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1575\n\n\n\n\n\n\ntaskableParfor(node) \n\u00b6\n\n\nReturns true if the \"node\" is a parfor and the task limit hasn't been exceeded.\nAlso controls whether stencils or reduction can become tasks.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:278\n\n\n\n\n\n\ntoSNGen(x::Symbol,  typ) \n\u00b6\n\n\nIf we have the type, convert a Symbol to SymbolNode.\nIf we have a GenSym then we have to keep it.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2788\n\n\n\n\n\n\ntoSymGen(x::Symbol) \n\u00b6\n\n\nIn various places we need a SymGen type which is the union of Symbol and GenSym.\nThis function takes a Symbol, SymbolNode, or GenSym and return either a Symbol or GenSym.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:699\n\n\n\n\n\n\ntoSymNodeGen(x::Symbol,  typ) \n\u00b6\n\n\nForm a SymbolNode with the given typ if possible or a GenSym if that is what is passed in.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:718\n\n\n\n\n\n\nuncompressed_ast(l::LambdaStaticData) \n\u00b6\n\n\nConvert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:914\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.CopyPropagateState \n\u00b6\n\n\nState to aide in the copy propagation phase.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2831\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.DirWalk \n\u00b6\n\n\nWraps the callback and opaque data passed from the user of ParallelIR's AstWalk.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:4707\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.DomainOperation \n\u00b6\n\n\nHolds information about domain operations part of a parfor node.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:95\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.EquivalenceClasses \n\u00b6\n\n\nHolds a dictionary from an array symbol to an integer corresponding to an equivalence class.\nAll array symbol in the same equivalence class are known to have the same shape.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:105\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.FusionSentinel \n\u00b6\n\n\nJust used to hold a spot in an array to indicate the this is a special assignment expression with embedded real array output names from a fusion.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1690\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.InProgress \n\u00b6\n\n\nA sentinel in the instruction count estimation process.\nBefore recursively processing a call, we add a sentinel for that function so that if we see that\nsentinel later we know we've tried to recursively process it and so can bail out by setting\nfully_analyzed to false.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:346\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.InputInfo \n\u00b6\n\n\nType used by mk_parfor_args... functions to hold information about input arrays.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:391\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.InsertTaskNode \n\u00b6\n\n\nA data type containing the information that CGen uses to generate a call to pert_insert_divisible_task.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:197\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.PIRParForStartEnd \n\u00b6\n\n\nAfter lowering, it is necessary to make the parfor body top-level statements so that basic blocks\ncan be correctly identified and labels correctly found.  There is a phase in parallel IR where we \ntake a PIRParForAst node and split it into a parfor_start node followed by the body as top-level\nstatements followed by parfor_end (also a top-level statement).\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:238\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.RangeData \n\u00b6\n\n\nHolds the information from one Domain IR :range Expr.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:377\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.RemoveDeadState \n\u00b6\n\n\nHolds liveness information for the remove_dead AstWalk phase.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:2981\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.RemoveNoDepsState \n\u00b6\n\n\nState for the remove_no_deps and insert_no_deps_beginning phases.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3041\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.ReplacedRegion \n\u00b6\n\n\nStore information about a section of a body that will be translated into a task.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:21\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.RhsDead \n\u00b6\n\n\nMarks an assignment statement where the left-hand side can take over the storage from the right-hand side.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:577\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.StatementWithDeps \n\u00b6\n\n\nType for dependence graph creation and topological sorting.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:3848\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.TaskInfo \n\u00b6\n\n\nStructure for storing information about task formation.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:36\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.cur_body_data \n\u00b6\n\n\nHolds the data for substitute_cur_body AST walk.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1460\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.cuw_state \n\u00b6\n\n\nJust to hold the \"found\" Bool that says whether a unsafe variant was replaced with a regular version.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:907\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.expr_state \n\u00b6\n\n\nState passed around while converting an AST from domain to parallel IR.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:245\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.pir_arg_metadata \n\u00b6\n\n\nA Julia representation of the argument metadata that will be passed to the runtime.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:157\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.pir_array_access_desc \n\u00b6\n\n\nDescribes an array.\nrow_major is true if the array is stored in row major format.\ndim_info describes which portion of the array is accessed for a given point in the iteration space.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:111\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.pir_grain_size \n\u00b6\n\n\nA Julia representation of the grain size that will be passed to the runtime.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:178\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.pir_range \n\u00b6\n\n\nTranslated to pert_range_Nd_t in the task runtime.\nThis represents an iteration space.\ndim is the number of dimensions in the iteration space.\nlower_bounds contains the lower bound of the iteration space in each dimension.\nupper_bounds contains the upper bound of the iteration space in each dimension.\nlower_bounds and upper_bounds can be expressions.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:56\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.pir_range_actual \n\u00b6\n\n\nSimilar to pir_range but used in circumstances where the expressions must have already been evaluated.\nTherefore the arrays are typed as Int64.\nUp to 3 dimensional iteration space constructors are supported to make it easier to do code generation later.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir-task.jl:70\n\n\n\n\n\n\nParallelAccelerator.ParallelIR.sub_arrayset_data \n\u00b6\n\n\nHolds data for modifying arrayset calls.\n\n\nsource:\n\n\nParallelAccelerator/src/parallel-ir.jl:1338", 
            "title": "ParallelIR"
        }, 
        {
            "location": "/ParallelIR/#parallelacceleratorparallelir", 
            "text": "", 
            "title": "ParallelAccelerator.ParallelIR"
        }, 
        {
            "location": "/ParallelIR/#exported", 
            "text": "AstWalk(ast,  callback,  cbdata)  \u00b6  ParallelIR version of AstWalk.\nInvokes the DomainIR version of AstWalk and provides the parallel IR AstWalk callback AstWalkCallback.  Parallel IR AstWalk calls Domain IR AstWalk which in turn calls CompilerTools.AstWalker.AstWalk.\nFor each AST node, CompilerTools.AstWalker.AstWalk calls Domain IR callback to give it a chance to handle the node if it is a Domain IR node.\nLikewise, Domain IR callback first calls Parallel IR callback to give it a chance to handle Parallel IR nodes.\nThe Parallel IR callback similarly first calls the user-level callback to give it a chance to process the node.\nIf a callback returns \"nothing\" it means it didn't modify that node and that the previous code should process it.\nThe Parallel IR callback will return \"nothing\" if the node isn't a Parallel IR node.\nThe Domain IR callback will return \"nothing\" if the node isn't a Domain IR node.  source:  ParallelAccelerator/src/parallel-ir.jl:4876    PIRInplace(x)  \u00b6  If set to non-zero, perform the phase where non-inplace maps are converted to inplace maps to reduce allocations.  source:  ParallelAccelerator/src/parallel-ir.jl:3816    PIRNumSimplify(x)  \u00b6  Specify the number of passes over the AST that do things like hoisting and other rearranging to maximize fusion.  source:  ParallelAccelerator/src/parallel-ir.jl:1672    PIRRunAsTasks(x)  \u00b6  Debugging feature to specify the number of tasks to create and to stop thereafter.  source:  ParallelAccelerator/src/parallel-ir.jl:1853    PIRSetFuseLimit(x)  \u00b6  Control how many parfor can be fused for testing purposes.\n    -1 means fuse all possible parfors.\n    0  means don't fuse any parfors.\n    1+ means fuse the specified number of parfors but then stop fusing beyond that.  source:  ParallelAccelerator/src/parallel-ir.jl:1667    PIRShortcutArrayAssignment(x)  \u00b6  Enables an experimental mode where if there is a statement a = b and they are arrays and b is not live-out then \nuse a special assignment node like a move assignment in C++.  source:  ParallelAccelerator/src/parallel-ir.jl:3842    PIRTaskGraphMode(x)  \u00b6  Control how blocks of code are made into tasks.  source:  ParallelAccelerator/src/parallel-ir-task.jl:589    from_exprs(ast::Array{Any, 1},  depth,  state)  \u00b6  Process an array of expressions.\nDifferentiate between top-level arrays of statements and arrays of expression that may occur elsewhere than the :body Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:2274    ParallelAccelerator.ParallelIR.PIRLoopNest  \u00b6  Holds the information about a loop in a parfor node.  source:  ParallelAccelerator/src/parallel-ir.jl:76    ParallelAccelerator.ParallelIR.PIRParForAst  \u00b6  The parfor AST node type.\nWhile we are lowering domain IR to parfors and fusing we use this representation because it\nmakes it easier to associate related statements before and after the loop to the loop itself.  source:  ParallelAccelerator/src/parallel-ir.jl:174    ParallelAccelerator.ParallelIR.PIRReduction  \u00b6  Holds the information about a reduction in a parfor node.  source:  ParallelAccelerator/src/parallel-ir.jl:86", 
            "title": "Exported"
        }, 
        {
            "location": "/ParallelIR/#internal", 
            "text": "AstWalkCallback(x::Expr,  dw::ParallelAccelerator.ParallelIR.DirWalk,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)  \u00b6  AstWalk callback that handles ParallelIR AST node types.  source:  ParallelAccelerator/src/parallel-ir.jl:4724    EquivalenceClassesAdd(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  sym::Symbol)  \u00b6  Add a symbol as part of a new equivalence class if the symbol wasn't already in an equivalence class.\nReturn the equivalence class for the symbol.  source:  ParallelAccelerator/src/parallel-ir.jl:139    EquivalenceClassesClear(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses)  \u00b6  Clear an equivalence class.  source:  ParallelAccelerator/src/parallel-ir.jl:153    EquivalenceClassesMerge(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  merge_to::Symbol,  merge_from::Symbol)  \u00b6  At some point we realize that two arrays must have the same dimensions but up until that point\nwe might not have known that.  In which case they will start in different equivalence classes,\nmerge_to and merge_from, but need to be combined into one equivalence class.\nGo through the equivalence class dictionary and for any symbol belonging to the merge_from\nequivalence class, change it to now belong to the merge_to equivalence class.  source:  ParallelAccelerator/src/parallel-ir.jl:123    PIRBbReorder(x)  \u00b6  If set to non-zero, perform the bubble-sort like reordering phase to coalesce more parfor nodes together for fusion.  source:  ParallelAccelerator/src/parallel-ir.jl:3832    PIRHoistAllocation(x)  \u00b6  If set to non-zero, perform the rearrangement phase that tries to moves alllocations outside of loops.  source:  ParallelAccelerator/src/parallel-ir.jl:3824    TypedExpr(typ,  rest...)  \u00b6  This should pretty always be used instead of Expr(...) to form an expression as it forces the typ to be provided.  source:  ParallelAccelerator/src/parallel-ir.jl:67    addUnknownArray(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Given an array whose name is in \"x\", allocate a new equivalence class for this array.  source:  ParallelAccelerator/src/parallel-ir.jl:746    addUnknownRange(x::Array{Any, 1},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Given an array of RangeExprs describing loop nest ranges, allocate a new equivalence class for this range.  source:  ParallelAccelerator/src/parallel-ir.jl:755    add_merge_correlations(old_sym::Union{GenSym, Symbol},  new_sym::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  If we somehow determine that two arrays must be the same length then \nget the equivalence classes for the two arrays and merge those equivalence classes together.  source:  ParallelAccelerator/src/parallel-ir.jl:792    asArray(x)  \u00b6  Return one element array with element x.  source:  ParallelAccelerator/src/parallel-ir.jl:4715    augment_sn(dim::Int64,  index_vars,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})  \u00b6  Make sure the index parameters to arrayref or arrayset are Int64 or SymbolNode.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:29    call_instruction_count(args,  state::ParallelAccelerator.ParallelIR.eic_state,  debug_level)  \u00b6  Generate an instruction count estimate for a call instruction.  source:  ParallelAccelerator/src/parallel-ir-task.jl:352    checkAndAddSymbolCorrelation(lhs::Union{GenSym, Symbol},  state,  dim_array)  \u00b6  Make sure all the dimensions are SymbolNodes.\nMake sure each dimension variable is assigned to only once in the function.\nExtract just the dimension variables names into dim_names and then register the correlation from lhs to those dimension names.  source:  ParallelAccelerator/src/parallel-ir.jl:3277    convertUnsafe(stmt)  \u00b6  Remove unsafe array access Symbols from the incoming \"stmt\".\nReturns the updated statement if something was modifed, else returns \"nothing\".  source:  ParallelAccelerator/src/parallel-ir-task.jl:951    convertUnsafeOrElse(stmt)  \u00b6  Try to remove unsafe array access Symbols from the incoming \"stmt\".  If successful, then return the updated\nstatement, else return the unmodified statement.  source:  ParallelAccelerator/src/parallel-ir-task.jl:970    convertUnsafeWalk(x::Expr,  state,  top_level_number,  is_top_level,  read)  \u00b6  The AstWalk callback to find unsafe arrayset and arrayref variants and\nreplace them with the regular Julia versions.  Sets the \"found\" flag\nin the state when such a replacement is performed.  source:  ParallelAccelerator/src/parallel-ir-task.jl:919    copy_propagate(node::ANY,  data::ParallelAccelerator.ParallelIR.CopyPropagateState,  top_level_number,  is_top_level,  read)  \u00b6  In each basic block, if there is a \"copy\" (i.e., something of the form \"a = b\") then put\nthat in copies as copies[a] = b.  Then, later in the basic block if you see the symbol\n\"a\" then replace it with \"b\".  Note that this is not SSA so \"a\" may be written again\nand if it is then it must be removed from copies.  source:  ParallelAccelerator/src/parallel-ir.jl:2849    count_assignments(x,  symbol_assigns::Dict{Symbol, Int64},  top_level_number,  is_top_level,  read)  \u00b6  AstWalk callback to count the number of static times that a symbol is assigne within a method.  source:  ParallelAccelerator/src/parallel-ir.jl:920    create1D_array_access_desc(array::SymbolNode)  \u00b6  Create an array access descriptor for \"array\".\nPresumes that for point \"i\" in the iteration space that only index \"i\" is accessed.  source:  ParallelAccelerator/src/parallel-ir-task.jl:124    create2D_array_access_desc(array::SymbolNode)  \u00b6  Create an array access descriptor for \"array\".\nPresumes that for points \"(i,j)\" in the iteration space that only indices \"(i,j)\" is accessed.  source:  ParallelAccelerator/src/parallel-ir-task.jl:134    createInstructionCountEstimate(the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Takes a parfor and walks the body of the parfor and estimates the number of instruction needed for one instance of that body.  source:  ParallelAccelerator/src/parallel-ir-task.jl:557    createLoweredAliasMap(dict1)  \u00b6  Take a single-step alias map, e.g., a= b, b= c, and create a lowered dictionary, a= c, b= c, that\nmaps each array to the transitively lowered array.  source:  ParallelAccelerator/src/parallel-ir.jl:1840    createMapLhsToParfor(parfor_assignment,  the_parfor,  is_multi::Bool,  sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Creates a mapping between variables on the left-hand side of an assignment where the right-hand side is a parfor\nand the arrays or scalars in that parfor that get assigned to the corresponding parts of the left-hand side.\nReturns a tuple where the first element is a map for arrays between left-hand side and parfor and the second\nelement is a map for reduction scalars between left-hand side and parfor.\nis_multi is true if the assignment is a fusion assignment.\nparfor_assignment is the AST of the whole expression.\nthe_parfor is the PIRParForAst type part of the incoming assignment.\nsym_to_type is an out parameter that maps symbols in the output mapping to their types.  source:  ParallelAccelerator/src/parallel-ir.jl:1774    createStateVar(state,  name,  typ,  access)  \u00b6  Add a local variable to the current function's lambdaInfo.\nReturns a symbol node of the new variable.  source:  ParallelAccelerator/src/parallel-ir.jl:639    createTempForArray(array_sn::Union{GenSym, Symbol, SymbolNode},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Create a temporary variable that is parfor private to hold the value of an element of an array.  source:  ParallelAccelerator/src/parallel-ir.jl:647    createTempForRangeOffset(num_used,  ranges::Array{ParallelAccelerator.ParallelIR.RangeData, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Create a variable to hold the offset of a range offset from the start of the array.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:322    createTempForRangedArray(array_sn::Union{GenSym, Symbol, SymbolNode},  range::Array{Union{GenSym, SymbolNode}, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Create a temporary variable that is parfor private to hold the value of an element of an array.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:338    create_array_access_desc(array::SymbolNode)  \u00b6  Create an array access descriptor for \"array\".  source:  ParallelAccelerator/src/parallel-ir-task.jl:144    create_equivalence_classes(node::Expr,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)  \u00b6  AstWalk callback to determine the array equivalence classes.  source:  ParallelAccelerator/src/parallel-ir.jl:3405    dfsVisit(swd::ParallelAccelerator.ParallelIR.StatementWithDeps,  vtime::Int64,  topo_sort::Array{ParallelAccelerator.ParallelIR.StatementWithDeps, N})  \u00b6  Construct a topological sort of the dependence graph.  source:  ParallelAccelerator/src/parallel-ir.jl:3863    estimateInstrCount(ast::Expr,  state::ParallelAccelerator.ParallelIR.eic_state,  top_level_number,  is_top_level,  read)  \u00b6  AstWalk callback for estimating the instruction count.  source:  ParallelAccelerator/src/parallel-ir-task.jl:474    extractArrayEquivalencies(node::Expr,  state)  \u00b6  \"node\" is a domainIR node.  Take the arrays used in this node, create an array equivalence for them if they \ndon't already have one and make sure they all share one equivalence class.  source:  ParallelAccelerator/src/parallel-ir.jl:3215    findSelectedDimensions(inputInfo::Array{ParallelAccelerator.ParallelIR.InputInfo, 1},  state)  \u00b6  Given all the InputInfo for a Domain IR operation being lowered to Parallel IR,\ndetermine the number of output dimensions for those arrays taking into account\nthat singly selected trailing dimensinos are eliminated.  Make sure that all such\narrays have the same output dimensions because this will match the loop nest size.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:745    flattenParfor(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst)  \u00b6  Takes a new array of body statements in the process of construction in \"new_body\" and takes a parfor to add to that\nbody.  This parfor is in the nested (parfor code is in the parfor node itself) temporary form we use for fusion although \npre-statements and post-statements are already elevated by this point.  We replace this nested form with a non-nested\nform where we have a parfor_start and parfor_end to delineate the parfor code.  source:  ParallelAccelerator/src/parallel-ir-flatten.jl:94    from_assertEqShape(node::Expr,  state)  \u00b6  Create array equivalences from an assertEqShape AST node.\nThere are two arrays in the args to assertEqShape.  source:  ParallelAccelerator/src/parallel-ir.jl:2604    from_assignment(lhs,  rhs,  depth,  state)  \u00b6  Process an assignment expression.\nStarts by recurisvely processing the right-hand side of the assignment.\nEliminates the assignment of a=b if a is dead afterwards and b has no side effects.\n    Does some array equivalence class work which may be redundant given that we now run a separate equivalence class pass so consider removing that part of this code.  source:  ParallelAccelerator/src/parallel-ir.jl:2685    from_call(ast::Array{Any, 1},  depth,  state)  \u00b6  Process a call AST node.  source:  ParallelAccelerator/src/parallel-ir.jl:2807    from_expr(ast::Expr,  depth,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level)  \u00b6  The main ParallelIR function for processing some node in the AST.  source:  ParallelAccelerator/src/parallel-ir.jl:4546    from_lambda(lambda::Expr,  depth,  state)  \u00b6  Process a :lambda Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:946    from_root(function_name,  ast::Expr)  \u00b6  The main ENTRY point into ParallelIR.\n1) Do liveness analysis.\n2) Convert mmap to mmap! where possible.\n3) Do some code rearrangement (e.g., hoisting) to maximize later fusion.\n4) Create array equivalence classes within the function.\n5) Rearrange statements within a basic block to push domain operations to the bottom so more fusion.\n6) Call the main from_expr to process the AST for the function.  This will\na) Lower domain IR to parallel IR AST nodes.\nb) Fuse parallel IR nodes where possible.\nc) Convert to task IR nodes if task mode enabled.  source:  ParallelAccelerator/src/parallel-ir.jl:4208    fullyLowerAlias(dict::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  input::Union{GenSym, Symbol})  \u00b6  Given an \"input\" Symbol, use that Symbol as key to a dictionary.  While such a Symbol is present\nin the dictionary replace it with the corresponding value from the dict.  source:  ParallelAccelerator/src/parallel-ir.jl:1829    fuse(body,  body_index,  cur,  state)  \u00b6  Test whether we can fuse the two most recent parfor statements and if so to perform that fusion.  source:  ParallelAccelerator/src/parallel-ir.jl:1871    generate_instr_count(function_name,  signature)  \u00b6  Try to figure out the instruction count for a given call.  source:  ParallelAccelerator/src/parallel-ir-task.jl:398    getArrayElemType(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Returns the element type of an Array.  source:  ParallelAccelerator/src/parallel-ir.jl:611    getArrayElemType(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Returns the element type of an Array.  source:  ParallelAccelerator/src/parallel-ir.jl:604    getArrayElemType(atyp::DataType)  \u00b6  Returns the element type of an Array.  source:  ParallelAccelerator/src/parallel-ir.jl:591    getArrayNumDims(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Return the number of dimensions of an Array.  source:  ParallelAccelerator/src/parallel-ir.jl:628    getArrayNumDims(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Return the number of dimensions of an Array.  source:  ParallelAccelerator/src/parallel-ir.jl:619    getConstDims(num_dim_inputs,  inputInfo::ParallelAccelerator.ParallelIR.InputInfo)  \u00b6  In the case where a domain IR operation on an array creates a lower dimensional output,\nthe indexing expression needs the expression that selects those constant trailing dimensions\nthat are being dropped.  This function returns an array of those constant expressions for\nthe trailing dimensions.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:766    getCorrelation(sng::Union{GenSym, Symbol, SymbolNode},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Get the equivalence class of a domain IR input in inputInfo.  source:  ParallelAccelerator/src/parallel-ir.jl:1747    getFirstArrayLens(prestatements,  num_dims)  \u00b6  Get the variable which holds the length of the first input array to a parfor.  source:  ParallelAccelerator/src/parallel-ir.jl:1438    getIO(stmt_ids,  bb_statements)  \u00b6  Given a set of statement IDs and liveness information for the statements of the function, determine\nwhich symbols are needed at input and which symbols are purely local to the functio.  source:  ParallelAccelerator/src/parallel-ir-task.jl:840    getInputSet(node::ParallelAccelerator.ParallelIR.PIRParForAst)  \u00b6  Returns a Set with all the arrays read by this parfor.  source:  ParallelAccelerator/src/parallel-ir.jl:1106    getLhsFromAssignment(assignment)  \u00b6  Get the left-hand side of an assignment expression.  source:  ParallelAccelerator/src/parallel-ir.jl:1077    getLhsOutputSet(lhs,  assignment)  \u00b6  Get the real outputs of an assignment statement.\nIf the assignment expression is normal then the output is just the left-hand side.\nIf the assignment expression is augmented with a FusionSentinel then the real outputs\nare the 4+ arguments to the expression.  source:  ParallelAccelerator/src/parallel-ir.jl:1121    getMaxLabel(max_label,  stmts::Array{Any, 1})  \u00b6  Scan the body of a function in \"stmts\" and return the max label in a LabelNode AST seen in the body.  source:  ParallelAccelerator/src/parallel-ir.jl:4026    getNonBlock(head_preds,  back_edge)  \u00b6  Find the basic block before the entry to a loop.  source:  ParallelAccelerator/src/parallel-ir-task.jl:5    getOrAddArrayCorrelation(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Return a correlation set for an array.  If the array was not previously added then add it and return it.  source:  ParallelAccelerator/src/parallel-ir.jl:802    getOrAddRangeCorrelation(ranges::Array{ParallelAccelerator.ParallelIR.RangeExprs, 1},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Gets (or adds if absent) the range correlation for the given array of RangeExprs.  source:  ParallelAccelerator/src/parallel-ir.jl:813    getOrAddSymbolCorrelation(array::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state,  dims::Array{Union{GenSym, Symbol}, 1})  \u00b6  A new array is being created with an explicit size specification in dims.  source:  ParallelAccelerator/src/parallel-ir.jl:832    getParforCorrelation(parfor,  state)  \u00b6  Get the equivalence class of the first array who length is extracted in the pre-statements of the specified \"parfor\".  source:  ParallelAccelerator/src/parallel-ir.jl:1740    getParforNode(node)  \u00b6  Get the parfor object from either a bare parfor or one part of an assignment.  source:  ParallelAccelerator/src/parallel-ir.jl:1059    getPrivateSet(body::Array{Any, 1})  \u00b6  Go through the body of a parfor and collect those Symbols, GenSyms, etc. that are assigned to within the parfor except reduction variables.  source:  ParallelAccelerator/src/parallel-ir.jl:898    getPrivateSetInner(x::Expr,  state::Set{Union{GenSym, Symbol, SymbolNode}},  top_level_number::Int64,  is_top_level::Bool,  read::Bool)  \u00b6  The AstWalk callback function for getPrivateSet.\nFor each AST in a parfor body, if the node is an assignment or loop head node then add the written entity to the state.  source:  ParallelAccelerator/src/parallel-ir.jl:868    getRhsFromAssignment(assignment)  \u00b6  Get the right-hand side of an assignment expression.  source:  ParallelAccelerator/src/parallel-ir.jl:1070    getSName(ssn::Symbol)  \u00b6  Get the name of a symbol whether the input is a Symbol or SymbolNode or :(::) Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:2237    get_one(ast::Array{T, N})  \u00b6  Take something returned from AstWalk and assert it should be an array but in this\ncontext that the array should also be of length 1 and then return that single element.  source:  ParallelAccelerator/src/parallel-ir.jl:4700    get_unique_num()  \u00b6  If we need to generate a name and make sure it is unique then include an monotonically increasing number.  source:  ParallelAccelerator/src/parallel-ir.jl:853    hasNoSideEffects(node::Union{GenSym, LambdaStaticData, Number, Symbol, SymbolNode})  \u00b6  Sometimes statements we exist in the AST of the form a=Expr where a is a Symbol that isn't live past the assignment\nand we'd like to eliminate the whole assignment statement but we have to know that the right-hand side has no\nside effects before we can do that.  This function says whether the right-hand side passed into it has side effects\nor not.  Several common function calls that otherwise we wouldn't know are safe are explicitly checked for.  source:  ParallelAccelerator/src/parallel-ir.jl:2547    hasSymbol(ssn::Symbol)  \u00b6  Returns true if the incoming AST node can be interpreted as a Symbol.  source:  ParallelAccelerator/src/parallel-ir.jl:2218    hoistAllocation(ast::Array{Any, 1},  lives,  domLoop::CompilerTools.Loops.DomLoops,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Try to hoist allocations outside the loop if possible.  source:  ParallelAccelerator/src/parallel-ir.jl:3698    insert_no_deps_beginning(node,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read)  \u00b6  Works with remove_no_deps below to move statements with no dependencies to the beginning of the AST.  source:  ParallelAccelerator/src/parallel-ir.jl:3055    intermediate_from_exprs(ast::Array{Any, 1},  depth,  state)  \u00b6  Process an array of expressions that aren't from a :body Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:2288    isArrayType(typ)  \u00b6  Returns true if the incoming type in \"typ\" is an array type.  source:  ParallelAccelerator/src/parallel-ir.jl:584    isArrayType(x::SymbolNode)  \u00b6  Returns true if a given SymbolNode \"x\" is an Array type.  source:  ParallelAccelerator/src/parallel-ir.jl:2316    isArrayref(x)  \u00b6  Is a node an arrayref node?  source:  ParallelAccelerator/src/parallel-ir.jl:1356    isArrayrefCall(x::Expr)  \u00b6  Is a node a call to arrayref.  source:  ParallelAccelerator/src/parallel-ir.jl:1377    isArrayset(x)  \u00b6  Is a node an arrayset node?  source:  ParallelAccelerator/src/parallel-ir.jl:1346    isArraysetCall(x::Expr)  \u00b6  Is a node a call to arrayset.  source:  ParallelAccelerator/src/parallel-ir.jl:1366    isAssignmentNode(node::Expr)  \u00b6  Is a node an assignment expression node.  source:  ParallelAccelerator/src/parallel-ir.jl:987    isBareParfor(node::Expr)  \u00b6  Is this a parfor node not part of an assignment statement.  source:  ParallelAccelerator/src/parallel-ir.jl:1009    isDomainNode(ast::Expr)  \u00b6  Returns true if the given \"ast\" node is a DomainIR operation.  source:  ParallelAccelerator/src/parallel-ir.jl:3882    isFusionAssignment(x::Expr)  \u00b6  Check if an assignement is a fusion assignment.\n    In regular assignments, there are only two args, the left and right hand sides.\n    In fusion assignments, we introduce a third arg that is marked by an object of FusionSentinel type.  source:  ParallelAccelerator/src/parallel-ir.jl:1700    isLoopheadNode(node::Expr)  \u00b6  Is a node a loophead expression node (a form of assignment).  source:  ParallelAccelerator/src/parallel-ir.jl:998    isParforAssignmentNode(node::Expr)  \u00b6  Is a node an assignment expression with a parfor node as the right-hand side.  source:  ParallelAccelerator/src/parallel-ir.jl:1033    isSymbolsUsed(vars,  top_level_numbers::Array{Int64, 1},  state)  \u00b6  Returns true if any variable in the collection \"vars\" is used in any statement whose top level number is in \"top_level_numbers\".\n    We use expr_state \"state\" to get the block liveness information from which we use \"def\" and \"use\" to determine if a variable\n        usage is present.  source:  ParallelAccelerator/src/parallel-ir.jl:1716    is_eliminated_arraylen(x::Expr)  \u00b6  Returns true if the input node is an assignment node where the right-hand side is a call to arraysize.  source:  ParallelAccelerator/src/parallel-ir.jl:1589    isbitstuple(a::Tuple)  \u00b6  Returns true if input \"a\" is a tuple and each element of the tuple of isbits type.  source:  ParallelAccelerator/src/parallel-ir.jl:4493    iterations_equals_inputs(node::ParallelAccelerator.ParallelIR.PIRParForAst)  \u00b6  Returns true if the domain operation mapped to this parfor has the property that the iteration space\nis identical to the dimenions of the inputs.  source:  ParallelAccelerator/src/parallel-ir.jl:1086    lambdaFromDomainLambda(domain_lambda,  dl_inputs)  \u00b6  Form a Julia :lambda Expr from a DomainLambda.  source:  ParallelAccelerator/src/parallel-ir.jl:4038    makePrivateParfor(var_name::Symbol,  state)  \u00b6  Takes an existing variable whose name is in \"var_name\" and adds the descriptor flag ISPRIVATEPARFORLOOP to declare the\nvariable to be parfor loop private and eventually go in an OMP private clause.  source:  ParallelAccelerator/src/parallel-ir.jl:659    makeTasks(start_index,  stop_index,  body,  bb_live_info,  state,  task_graph_mode)  \u00b6  For a given start and stop index in some body and liveness information, form a set of tasks.  source:  ParallelAccelerator/src/parallel-ir-task.jl:759    maxFusion(bl::CompilerTools.LivenessAnalysis.BlockLiveness)  \u00b6  For every basic block, try to push domain IR statements down and non-domain IR statements up so that domain nodes\nare next to each other and can be fused.  source:  ParallelAccelerator/src/parallel-ir.jl:3926    mergeLambdaIntoOuterState(state,  inner_lambda::Expr)  \u00b6  Pull the information from the inner lambda into the outer lambda.  source:  ParallelAccelerator/src/parallel-ir.jl:1218    merge_correlations(state,  unchanging,  eliminate)  \u00b6  If we somehow determine that two sets of correlations are actually the same length then merge one into the other.  source:  ParallelAccelerator/src/parallel-ir.jl:764    mk_alloc_array_1d_expr(elem_type,  atype,  length)  \u00b6  Return an expression that allocates and initializes a 1D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and a \"length\".  source:  ParallelAccelerator/src/parallel-ir.jl:496    mk_alloc_array_2d_expr(elem_type,  atype,  length1,  length2)  \u00b6  Return an expression that allocates and initializes a 2D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and two dimensions of length in \"length1\" and \"length2\".  source:  ParallelAccelerator/src/parallel-ir.jl:534    mk_alloc_array_3d_expr(elem_type,  atype,  length1,  length2,  length3)  \u00b6  Return an expression that allocates and initializes a 3D Julia array that has an element type specified by\n\"elem_type\", an array type of \"atype\" and two dimensions of length in \"length1\" and \"length2\" and \"length3\".  source:  ParallelAccelerator/src/parallel-ir.jl:560    mk_arraylen_expr(x::ParallelAccelerator.ParallelIR.InputInfo,  dim::Int64)  \u00b6  Create an expression whose value is the length of the input array.  source:  ParallelAccelerator/src/parallel-ir.jl:447    mk_arraylen_expr(x::Union{GenSym, Symbol, SymbolNode},  dim::Int64)  \u00b6  Create an expression whose value is the length of the input array.  source:  ParallelAccelerator/src/parallel-ir.jl:440    mk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Return an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:54    mk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1})  \u00b6  Return an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:54    mk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})  \u00b6  Return an expression that corresponds to getting the index_var index from the array array_name.\nIf \"inbounds\" is true then use the faster :unsafe_arrayref call that doesn't do a bounds check.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:54    mk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:85    mk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1})  \u00b6  Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:85    mk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})  \u00b6  Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\nThe paramater \"inbounds\" is true if this access is known to be within the bounds of the array.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:85    mk_assignment_expr(lhs::Union{GenSym, Symbol, SymbolNode},  rhs,  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Create an assignment expression AST node given a left and right-hand side.\nThe left-hand side has to be a symbol node from which we extract the type so as to type the new Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:353    mk_colon_expr(start_expr,  skip_expr,  end_expr)  \u00b6  Returns an expression to construct a :colon object that contains the start of a range, the end and the skip expression.  source:  ParallelAccelerator/src/parallel-ir-task.jl:878    mk_convert(new_type,  ex)  \u00b6  Returns an expression that convert \"ex\" into a another type \"new_type\".  source:  ParallelAccelerator/src/parallel-ir.jl:473    mk_gotoifnot_expr(cond,  goto_label)  \u00b6  Returns a :gotoifnot Expr given a condition \"cond\" and a label \"goto_label\".  source:  ParallelAccelerator/src/parallel-ir-task.jl:900    mk_next_expr(colon_sym,  start_sym)  \u00b6  Returns a :next call Expr that gets the next element of an iteration range from a :colon object.  source:  ParallelAccelerator/src/parallel-ir-task.jl:892    mk_parallelir_ref(sym)  \u00b6  Create an expression that references something inside ParallelIR.\nIn other words, returns an expression the equivalent of ParallelAccelerator.ParallelIR.sym where sym is an input argument to this function.  source:  ParallelAccelerator/src/parallel-ir.jl:465    mk_parallelir_ref(sym,  ref_type)  \u00b6  Create an expression that references something inside ParallelIR.\nIn other words, returns an expression the equivalent of ParallelAccelerator.ParallelIR.sym where sym is an input argument to this function.  source:  ParallelAccelerator/src/parallel-ir.jl:465    mk_parfor_args_from_mmap!(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  with_indices,  domain_oprs,  state)  \u00b6  The main routine that converts a mmap! AST node to a parfor AST node.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:498    mk_parfor_args_from_mmap(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  domain_oprs,  state)  \u00b6  The main routine that converts a mmap AST node to a parfor AST node.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:789    mk_parfor_args_from_reduce(input_args::Array{Any, 1},  state)  \u00b6  The main routine that converts a reduce AST node to a parfor AST node.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:119    mk_return_expr(outs)  \u00b6  Given an array of outputs in \"outs\", form a return expression.\nIf there is only one out then the args of :return is just that expression.\nIf there are multiple outs then form a tuple of them and that tuple goes in :return args.  source:  ParallelAccelerator/src/parallel-ir.jl:338    mk_start_expr(colon_sym)  \u00b6  Returns an expression to get the start of an iteration range from a :colon object.  source:  ParallelAccelerator/src/parallel-ir-task.jl:885    mk_svec_expr(parts...)  \u00b6  Make a svec expression.  source:  ParallelAccelerator/src/parallel-ir.jl:487    mk_tuple_expr(tuple_fields,  typ)  \u00b6  Return an expression which creates a tuple.  source:  ParallelAccelerator/src/parallel-ir.jl:1151    mk_tupleref_expr(tuple_var,  index,  typ)  \u00b6  Create an expression which returns the index'th element of the tuple whose name is contained in tuple_var.  source:  ParallelAccelerator/src/parallel-ir.jl:480    mk_untyped_assignment(lhs,  rhs)  \u00b6  Only used to create fake expression to force lhs to be seen as written rather than read.  source:  ParallelAccelerator/src/parallel-ir.jl:370    mmapInline(ast::Expr,  lives,  uniqSet)  \u00b6", 
            "title": "Internal"
        }, 
        {
            "location": "/ParallelIR/#if-a-definition-of-a-mmap-is-only-used-once-and-not-aliased-it-can-be-inlined-into-its", 
            "text": "", 
            "title": "If a definition of a mmap is only used once and not aliased, it can be inlined into its"
        }, 
        {
            "location": "/ParallelIR/#use-side-as-long-as-its-dependencies-have-not-been-changed", 
            "text": "", 
            "title": "use side as long as its dependencies have not been changed."
        }, 
        {
            "location": "/ParallelIR/#fixme-is-the-implementation-still-correct-when-branches-are-present", 
            "text": "source:  ParallelAccelerator/src/parallel-ir.jl:3621    mmapToMmap!(ast,  lives,  uniqSet)  \u00b6  Performs the mmap to mmap! phase.\nIf the arguments of a mmap dies aftewards, and is not aliased, then\nwe can safely change the mmap to mmap!.  source:  ParallelAccelerator/src/parallel-ir.jl:3764    mustRemainLastStatementInBlock(node::GotoNode)  \u00b6  Returns true if the given AST \"node\" must remain the last statement in a basic block.\nThis is true if the node is a GotoNode or a :gotoifnot Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:3910    nameToSymbolNode(name::Symbol,  sym_to_type)  \u00b6  Forms a SymbolNode given a symbol in \"name\" and get the type of that symbol from the incoming dictionary \"sym_to_type\".  source:  ParallelAccelerator/src/parallel-ir.jl:1159    nested_function_exprs(max_label,  domain_lambda,  dl_inputs)  \u00b6  A routine similar to the main parallel IR entry put but designed to process the lambda part of\ndomain IR AST nodes.  source:  ParallelAccelerator/src/parallel-ir.jl:4067    next_label(state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Returns the next usable label for the current function.  source:  ParallelAccelerator/src/parallel-ir.jl:738    oneIfOnly(x)  \u00b6  Returns a single element of an array if there is only one or the array otherwise.  source:  ParallelAccelerator/src/parallel-ir.jl:1860    parforToTask(parfor_index,  bb_statements,  body,  state)  \u00b6  Given a parfor statement index in \"parfor_index\" in the \"body\"'s statements, create a TaskInfo node for this parfor.  source:  ParallelAccelerator/src/parallel-ir-task.jl:1190    pirPrintDl(dbg_level,  dl)  \u00b6  Debug print the parts of a DomainLambda.  source:  ParallelAccelerator/src/parallel-ir.jl:4017    pir_alias_cb(ast::Expr,  state,  cbdata)  \u00b6  An AliasAnalysis callback (similar to LivenessAnalysis callback) that handles ParallelIR introduced AST node types.\nFor each ParallelIR specific node type, form an array of expressions that AliasAnalysis\n    can analyze to reflect the aliases of the given AST node.\n    If we read a symbol it is sufficient to just return that symbol as one of the expressions.\n    If we write a symbol, then form a fake mk_assignment_expr just to get liveness to realize the symbol is written.  source:  ParallelAccelerator/src/parallel-ir.jl:4884    pir_live_cb(ast::Expr,  cbdata::ANY)  \u00b6  A LivenessAnalysis callback that handles ParallelIR introduced AST node types.\nFor each ParallelIR specific node type, form an array of expressions that liveness\ncan analysis to reflect the read/write set of the given AST node.\nIf we read a symbol it is sufficient to just return that symbol as one of the expressions.\nIf we write a symbol, then form a fake mk_assignment_expr just to get liveness to realize the symbol is written.  source:  ParallelAccelerator/src/parallel-ir.jl:2412    pir_live_cb_def(x)  \u00b6  Just call the AST walker for symbol for parallel IR nodes with no state.  source:  ParallelAccelerator/src/parallel-ir.jl:939    printBody(dlvl,  body::Array{Any, 1})  \u00b6  Pretty print the args part of the \"body\" of a :lambda Expr at a given debug level in \"dlvl\".  source:  ParallelAccelerator/src/parallel-ir.jl:2327    printLambda(dlvl,  node::Expr)  \u00b6  Pretty print a :lambda Expr in \"node\" at a given debug level in \"dlvl\".  source:  ParallelAccelerator/src/parallel-ir.jl:2340    processAndUpdateBody(lambda::Expr,  f::Function,  state)  \u00b6  Apply a function \"f\" that takes the :body from the :lambda and returns a new :body that is stored back into the :lambda.  source:  ParallelAccelerator/src/parallel-ir.jl:3295    rangeSize(start,  skip,  last)  \u00b6  Compute size of a range.  source:  ParallelAccelerator/src/parallel-ir.jl:432    rangeToRangeData(range::Expr,  pre_offsets::Array{Expr, 1},  arr,  range_num::Int64,  state)  \u00b6  Convert a :range Expr introduced by Domain IR into a Parallel IR data structure RangeData.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:354    recreateLoops(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state,  newLambdaInfo)  \u00b6  In threads mode, we can't have parfor_start and parfor_end in the code since Julia has to compile the code itself and so\nwe have to reconstruct a loop infrastructure based on the parfor's loop nest information.  This function takes a parfor\nand outputs that parfor to the new function body as regular Julia loops.  source:  ParallelAccelerator/src/parallel-ir-task.jl:1156    recreateLoopsInternal(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  loop_nest_level,  next_available_label,  state,  newLambdaInfo)  \u00b6  This is a recursive routine to reconstruct a regular Julia loop nest from the loop nests described in PIRParForAst.\nOne call of this routine handles one level of the loop nest.\nIf the incoming loop nest level is more than the number of loops nests in the parfor then that is the spot to\ninsert the body of the parfor into the new function body in \"new_body\".  source:  ParallelAccelerator/src/parallel-ir-task.jl:1020    rememberTypeForSym(sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  sym::Union{GenSym, Symbol},  typ::DataType)  \u00b6  Add to the map of symbol names to types.  source:  ParallelAccelerator/src/parallel-ir.jl:1679    removeAssertEqShape(args::Array{Any, 1},  state)  \u00b6  Implements one of the main ParallelIR passes to remove assertEqShape AST nodes from the body if they are statically known to be in the same equivalence class.  source:  ParallelAccelerator/src/parallel-ir.jl:2588    removeNothingStmts(args::Array{Any, 1},  state)  \u00b6  Empty statements can be added to the AST by some passes in ParallelIR.\nThis pass over the statements of the :body excludes such \"nothing\" statements from the new :body.  source:  ParallelAccelerator/src/parallel-ir.jl:3306    remove_dead(node,  data::ParallelAccelerator.ParallelIR.RemoveDeadState,  top_level_number,  is_top_level,  read)  \u00b6  An AstWalk callback that uses liveness information in \"data\" to remove dead stores.  source:  ParallelAccelerator/src/parallel-ir.jl:2988    remove_extra_allocs(ast)  \u00b6  removes extra allocations  source:  ParallelAccelerator/src/parallel-ir.jl:4363    remove_no_deps(node::ANY,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read)  \u00b6", 
            "title": "FIXME: is the implementation still correct when branches are present?"
        }, 
        {
            "location": "/ParallelIR/#this-routine-gathers-up-nodes-that-do-not-use", 
            "text": "", 
            "title": "This routine gathers up nodes that do not use"
        }, 
        {
            "location": "/ParallelIR/#any-variable-and-removes-them-from-the-ast-into-top_level_no_deps-this-works-in-conjunction-with", 
            "text": "", 
            "title": "any variable and removes them from the AST into top_level_no_deps.  This works in conjunction with"
        }, 
        {
            "location": "/ParallelIR/#insert_no_deps_beginning-above-to-move-these-statements-with-no-dependencies-to-the-beginning-of-the-ast", 
            "text": "", 
            "title": "insert_no_deps_beginning above to move these statements with no dependencies to the beginning of the AST"
        }, 
        {
            "location": "/ParallelIR/#where-they-cant-prevent-fusion", 
            "text": "source:  ParallelAccelerator/src/parallel-ir.jl:3071    replaceParforWithDict(parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  gensym_map)  \u00b6  Not currently used but might need it at some point.\nSearch a whole PIRParForAst object and replace one SymAllGen with another.  source:  ParallelAccelerator/src/parallel-ir.jl:216    run_as_task()  \u00b6  Return true if run_as_task_decrement would return true but don't update the run_as_tasks count.  source:  ParallelAccelerator/src/parallel-ir-task.jl:229    run_as_task_decrement()  \u00b6  If run_as_tasks is positive then convert this parfor to a task and decrement the count so that only the\noriginal number run_as_tasks if the number of tasks created.  source:  ParallelAccelerator/src/parallel-ir-task.jl:215    selectToRangeData(select::Expr,  pre_offsets::Array{Expr, 1},  state)  \u00b6  Convert the range(s) part of a :select Expr introduced by Domain IR into an array of Parallel IR data structures RangeData.  source:  ParallelAccelerator/src/parallel-ir-mk-parfor.jl:371    seqTask(body_indices,  bb_statements,  body,  state)  \u00b6  Form a task out of a range of sequential statements.\nThis is not currently implemented.  source:  ParallelAccelerator/src/parallel-ir-task.jl:1538    show(io::IO,  pnode::ParallelAccelerator.ParallelIR.PIRParForAst)  \u00b6  Overload of Base.show to pretty print for parfor AST nodes.  source:  ParallelAccelerator/src/parallel-ir.jl:273    simpleIndex(dict)  \u00b6  Returns true if all array references use singular index variables and nothing more complicated involving,\nfor example, addition or subtraction by a constant.  source:  ParallelAccelerator/src/parallel-ir.jl:668    sub_arraylen_walk(x::Expr,  replacement,  top_level_number,  is_top_level,  read)  \u00b6  AstWalk callback that does the work of substitute_arraylen on a node-by-node basis.\nreplacement is an array containing the length of the dimensions of the arrays a part of this parfor.\nIf we see a call to create an array, replace the length params with those in the common set in \"replacement\".  source:  ParallelAccelerator/src/parallel-ir.jl:1620    sub_arrayset_walk(x::Expr,  cbd,  top_level_number,  is_top_level,  read)  \u00b6  AstWalk callback that does the work of substitute_arrayset on a node-by-node basis.  source:  ParallelAccelerator/src/parallel-ir.jl:1388    sub_cur_body_walk(x::Expr,  cbd::ParallelAccelerator.ParallelIR.cur_body_data,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)  \u00b6  AstWalk callback that does the work of substitute_cur_body on a node-by-node basis.  source:  ParallelAccelerator/src/parallel-ir.jl:1471    substitute_arraylen(x,  replacement)  \u00b6  replacement is an array containing the length of the dimensions of the arrays a part of this parfor.\nIf we see a call to create an array, replace the length params with those in the common set in \"replacement\".  source:  ParallelAccelerator/src/parallel-ir.jl:1652    substitute_arrayset(x,  arrays_set_in_cur_body,  output_items_with_aliases)  \u00b6  Modify the body of a parfor.\ntemp_map holds a map of array names whose arraysets should be turned into a mapped variable instead of the arrayset. a[i] = b. a= c. becomes c = b\nmap_for_non_eliminated holds arrays for which we need to add a variable to save the value but we can't eiminate the arrayset. a[i] = b. a= c. becomes c = a[i] = b\n    map_drop_arrayset drops the arrayset without replacing with a variable.  This is because a variable was previously added here with a map_for_non_eliminated case.\n    a[i] = b. becomes b  source:  ParallelAccelerator/src/parallel-ir.jl:1433    substitute_cur_body(x,  temp_map::Dict{Union{GenSym, Symbol}, Union{GenSym, SymbolNode}},  index_map::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  arrays_set_in_cur_body::Set{Union{GenSym, Symbol}},  replace_array_name_in_arrayset::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  state::ParallelAccelerator.ParallelIR.expr_state)  \u00b6  Make changes to the second parfor body in the process of parfor fusion.\ntemp_map holds array names for which arrayrefs should be converted to a variable.  a[i].  a= b. becomes b\n    index_map holds maps between index variables.  The second parfor is modified to use the index variable of the first parfor.\n    arrays_set_in_cur_body           # Used as output.  Collects the arrays set in the current body.\n    replace_array_name_in_arrayset   # Map from one array to another.  Replace first array with second when used in arrayset context.  source:  ParallelAccelerator/src/parallel-ir.jl:1575    taskableParfor(node)  \u00b6  Returns true if the \"node\" is a parfor and the task limit hasn't been exceeded.\nAlso controls whether stencils or reduction can become tasks.  source:  ParallelAccelerator/src/parallel-ir-task.jl:278    toSNGen(x::Symbol,  typ)  \u00b6  If we have the type, convert a Symbol to SymbolNode.\nIf we have a GenSym then we have to keep it.  source:  ParallelAccelerator/src/parallel-ir.jl:2788    toSymGen(x::Symbol)  \u00b6  In various places we need a SymGen type which is the union of Symbol and GenSym.\nThis function takes a Symbol, SymbolNode, or GenSym and return either a Symbol or GenSym.  source:  ParallelAccelerator/src/parallel-ir.jl:699    toSymNodeGen(x::Symbol,  typ)  \u00b6  Form a SymbolNode with the given typ if possible or a GenSym if that is what is passed in.  source:  ParallelAccelerator/src/parallel-ir.jl:718    uncompressed_ast(l::LambdaStaticData)  \u00b6  Convert a compressed LambdaStaticData format into the uncompressed AST format.  source:  ParallelAccelerator/src/parallel-ir.jl:914    ParallelAccelerator.ParallelIR.CopyPropagateState  \u00b6  State to aide in the copy propagation phase.  source:  ParallelAccelerator/src/parallel-ir.jl:2831    ParallelAccelerator.ParallelIR.DirWalk  \u00b6  Wraps the callback and opaque data passed from the user of ParallelIR's AstWalk.  source:  ParallelAccelerator/src/parallel-ir.jl:4707    ParallelAccelerator.ParallelIR.DomainOperation  \u00b6  Holds information about domain operations part of a parfor node.  source:  ParallelAccelerator/src/parallel-ir.jl:95    ParallelAccelerator.ParallelIR.EquivalenceClasses  \u00b6  Holds a dictionary from an array symbol to an integer corresponding to an equivalence class.\nAll array symbol in the same equivalence class are known to have the same shape.  source:  ParallelAccelerator/src/parallel-ir.jl:105    ParallelAccelerator.ParallelIR.FusionSentinel  \u00b6  Just used to hold a spot in an array to indicate the this is a special assignment expression with embedded real array output names from a fusion.  source:  ParallelAccelerator/src/parallel-ir.jl:1690    ParallelAccelerator.ParallelIR.InProgress  \u00b6  A sentinel in the instruction count estimation process.\nBefore recursively processing a call, we add a sentinel for that function so that if we see that\nsentinel later we know we've tried to recursively process it and so can bail out by setting\nfully_analyzed to false.  source:  ParallelAccelerator/src/parallel-ir-task.jl:346    ParallelAccelerator.ParallelIR.InputInfo  \u00b6  Type used by mk_parfor_args... functions to hold information about input arrays.  source:  ParallelAccelerator/src/parallel-ir.jl:391    ParallelAccelerator.ParallelIR.InsertTaskNode  \u00b6  A data type containing the information that CGen uses to generate a call to pert_insert_divisible_task.  source:  ParallelAccelerator/src/parallel-ir-task.jl:197    ParallelAccelerator.ParallelIR.PIRParForStartEnd  \u00b6  After lowering, it is necessary to make the parfor body top-level statements so that basic blocks\ncan be correctly identified and labels correctly found.  There is a phase in parallel IR where we \ntake a PIRParForAst node and split it into a parfor_start node followed by the body as top-level\nstatements followed by parfor_end (also a top-level statement).  source:  ParallelAccelerator/src/parallel-ir.jl:238    ParallelAccelerator.ParallelIR.RangeData  \u00b6  Holds the information from one Domain IR :range Expr.  source:  ParallelAccelerator/src/parallel-ir.jl:377    ParallelAccelerator.ParallelIR.RemoveDeadState  \u00b6  Holds liveness information for the remove_dead AstWalk phase.  source:  ParallelAccelerator/src/parallel-ir.jl:2981    ParallelAccelerator.ParallelIR.RemoveNoDepsState  \u00b6  State for the remove_no_deps and insert_no_deps_beginning phases.  source:  ParallelAccelerator/src/parallel-ir.jl:3041    ParallelAccelerator.ParallelIR.ReplacedRegion  \u00b6  Store information about a section of a body that will be translated into a task.  source:  ParallelAccelerator/src/parallel-ir-task.jl:21    ParallelAccelerator.ParallelIR.RhsDead  \u00b6  Marks an assignment statement where the left-hand side can take over the storage from the right-hand side.  source:  ParallelAccelerator/src/parallel-ir-task.jl:577    ParallelAccelerator.ParallelIR.StatementWithDeps  \u00b6  Type for dependence graph creation and topological sorting.  source:  ParallelAccelerator/src/parallel-ir.jl:3848    ParallelAccelerator.ParallelIR.TaskInfo  \u00b6  Structure for storing information about task formation.  source:  ParallelAccelerator/src/parallel-ir-task.jl:36    ParallelAccelerator.ParallelIR.cur_body_data  \u00b6  Holds the data for substitute_cur_body AST walk.  source:  ParallelAccelerator/src/parallel-ir.jl:1460    ParallelAccelerator.ParallelIR.cuw_state  \u00b6  Just to hold the \"found\" Bool that says whether a unsafe variant was replaced with a regular version.  source:  ParallelAccelerator/src/parallel-ir-task.jl:907    ParallelAccelerator.ParallelIR.expr_state  \u00b6  State passed around while converting an AST from domain to parallel IR.  source:  ParallelAccelerator/src/parallel-ir.jl:245    ParallelAccelerator.ParallelIR.pir_arg_metadata  \u00b6  A Julia representation of the argument metadata that will be passed to the runtime.  source:  ParallelAccelerator/src/parallel-ir-task.jl:157    ParallelAccelerator.ParallelIR.pir_array_access_desc  \u00b6  Describes an array.\nrow_major is true if the array is stored in row major format.\ndim_info describes which portion of the array is accessed for a given point in the iteration space.  source:  ParallelAccelerator/src/parallel-ir-task.jl:111    ParallelAccelerator.ParallelIR.pir_grain_size  \u00b6  A Julia representation of the grain size that will be passed to the runtime.  source:  ParallelAccelerator/src/parallel-ir-task.jl:178    ParallelAccelerator.ParallelIR.pir_range  \u00b6  Translated to pert_range_Nd_t in the task runtime.\nThis represents an iteration space.\ndim is the number of dimensions in the iteration space.\nlower_bounds contains the lower bound of the iteration space in each dimension.\nupper_bounds contains the upper bound of the iteration space in each dimension.\nlower_bounds and upper_bounds can be expressions.  source:  ParallelAccelerator/src/parallel-ir-task.jl:56    ParallelAccelerator.ParallelIR.pir_range_actual  \u00b6  Similar to pir_range but used in circumstances where the expressions must have already been evaluated.\nTherefore the arrays are typed as Int64.\nUp to 3 dimensional iteration space constructors are supported to make it easier to do code generation later.  source:  ParallelAccelerator/src/parallel-ir-task.jl:70    ParallelAccelerator.ParallelIR.sub_arrayset_data  \u00b6  Holds data for modifying arrayset calls.  source:  ParallelAccelerator/src/parallel-ir.jl:1338", 
            "title": "where they can't prevent fusion."
        }, 
        {
            "location": "/api-index/", 
            "text": "API-INDEX\n\n\nMODULE: ParallelAccelerator.Driver\n\n\n\n\nExported\n\n\ncaptureOperators(func,  ast,  sig)\n  A pass that translates supported operators and function calls to\n\n\nrunStencilMacro(func,  ast,  sig)\n  Pass that translates runStencil call in the same way as a macro would do.\n\n\ntoCartesianArray(func,  ast,  sig)\n  Pass for comprehension to cartesianarray translation.\n\n\nMODULE: ParallelAccelerator.API.Stencil\n\n\n\n\nExported\n\n\nrunStencil(inputs...)\n  \"runStencil\" takes arguments in the form of \"(kernel_function, A, B, C, ...,\n\n\n\n\nInternal\n\n\nprocess_node(node,  state,  top_level_number,  is_top_level,  read)\n  This function is a AstWalker callback.\n\n\n@comprehend(ast)\n  Translate all comprehension in an AST into equivalent code that uses cartesianarray call.\n\n\nMODULE: CompilerTools.ReadWriteSet\n\n\n\n\nExported\n\n\nfrom_exprs(ast::Array{T, N})\n  Walk through an array of expressions.\n\n\nfrom_exprs(ast::Array{T, N},  callback::Union{Function, Void},  cbdata::ANY)\n  Walk through an array of expressions.\n\n\nfrom_exprs(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)\n  Walk through an array of expressions.\n\n\nisRead(sym::Union{GenSym, Symbol},  rws::CompilerTools.ReadWriteSet.ReadWriteSetType)\n  Return true if some symbol in \"sym\" is read either as a scalar or array within the computed ReadWriteSetType.\n\n\nisWritten(sym::Union{GenSym, Symbol},  rws::CompilerTools.ReadWriteSet.ReadWriteSetType)\n  Return true if some symbol in \"sym\" is written either as a scalar or array within the computed ReadWriteSetType.\n\n\nCompilerTools.ReadWriteSet.AccessSet\n  Holds which scalars and which array are accessed and for array which index expressions are used.\n\n\nCompilerTools.ReadWriteSet.ReadWriteSetType\n  Stores which scalars and arrays are read or written in some code region.\n\n\n\n\nInternal\n\n\naddIndexExpr!(this_dict,  array_name,  index_expr)\n  Takes a dictionary of symbol to an array of index expression.\n\n\nfrom_assignment(ast::Array{Any, 1},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)\n  Process an assignment AST node.\n\n\nfrom_call(ast::Array{Any, 1},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)\n  Process :call Expr nodes to find arrayref and arrayset calls and adding the corresponding index expressions to the read and write sets respectively.\n\n\nfrom_coloncolon(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)\n  Process a :(::) AST node.\n\n\nfrom_expr(ast::ANY)\n  Walk through one AST node.\n\n\nfrom_expr(ast::ANY,  callback::Union{Function, Void},  cbdata::ANY)\n  Walk through one AST node.\n\n\nfrom_expr(ast::LambdaStaticData,  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)\n  The main routine that switches on all the various AST node types.\n\n\nfrom_lambda(ast::Expr,  depth,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)\n  Walk through a lambda expression.\n\n\nfrom_tuple(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)\n  Walk through a tuple.\n\n\ntoSymGen(x::Union{GenSym, Symbol})\n  In various places we need a SymGen type which is the union of Symbol and GenSym.\n\n\ntryCallback(ast::ANY,  callback::Union{Function, Void},  cbdata::ANY,  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType)\n  If an AST node is not recognized then we try the passing the node to the callback to see if \n\n\nuncompressed_ast(l::LambdaStaticData)\n  Convert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nMODULE: CompilerTools.AstWalker\n\n\n\n\nExported\n\n\nAstWalk(ast::ANY,  callback,  cbdata::ANY)\n  Entry point into the code to perform an AST walk.\n\n\n\n\nInternal\n\n\nfrom_assignment(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)\n  AstWalk through an assignment expression.\n\n\nfrom_body(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)\n  AstWalk through a function body.\n\n\nfrom_call(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)\n  AstWalk through a call expression.\n\n\nfrom_expr(ast::ANY,  depth,  callback,  cbdata::ANY,  top_level_number,  is_top_level,  read)\n  The main routine that switches on all the various AST node types.\n\n\nfrom_exprs(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)\n  AstWalk through an array of expressions.\n\n\nfrom_lambda(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)\n  AstWalk through a lambda expression.\n\n\nuncompressed_ast(l::LambdaStaticData)\n  Convert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nMODULE: CompilerTools.CFGs\n\n\n\n\nExported\n\n\nfind_bb_for_statement(top_number::Int64,  bl::CompilerTools.CFGs.CFG)\n  Find the basic block that contains a given statement number.\n\n\nfrom_exprs(ast::Array{Any, 1},  depth,  state,  callback,  cbdata)\n  Process an array of expressions.\n\n\nshow(io::IO,  bb::CompilerTools.CFGs.BasicBlock)\n  Overload of Base.show to pretty-print a CFGS.BasicBlock object.\n\n\nshow(io::IO,  bl::CompilerTools.CFGs.CFG)\n  Overload of Base.show to pretty-print a CFG object.\n\n\nshow(io::IO,  tls::CompilerTools.CFGs.TopLevelStatement)\n  Overload of Base.show to pretty-print a TopLevelStatement.\n\n\n\n\nInternal\n\n\nTypedExpr(typ,  rest...)\n  Creates a typed Expr AST node.\n\n\naddStatement(top_level,  state,  ast::ANY)\n  Adds a top-level statement just encountered during a partial walk of the AST.\n\n\naddStatementToEndOfBlock(bl::CompilerTools.CFGs.CFG,  block,  stmt)\n  Given a CFG \"bl\" and a basic \"block\", add statement \"stmt\" to the end of that block.\n\n\nchangeEndingLabel(bb,  after::CompilerTools.CFGs.BasicBlock,  new_bb::CompilerTools.CFGs.BasicBlock)\n  BasicBlock bb currently is known to contain a jump to the BasicBlock after.\n\n\ncompute_dfn(basic_blocks)\n  Computes the depth first numbering of the basic block graph.\n\n\ncompute_dfn_internal(basic_blocks,  cur_bb,  cur_dfn,  visited,  bbs_df_order)\n  The recursive heart of depth first numbering.\n\n\ncompute_dominators(bl::CompilerTools.CFGs.CFG)\n  Compute the dominators of the CFG.\n\n\ncompute_inverse_dominators(bl::CompilerTools.CFGs.CFG)\n  Compute the inverse dominators of the CFG.\n\n\nconnect(from,  to,  fallthrough)\n  Connect the \"from\" input argument basic block to the \"to\" input argument basic block.\n\n\nconnect_finish(state)\n  Connect the current basic block as a fallthrough to the final invisible basic block (-2).\n\n\ncreateFunctionBody(bl::CompilerTools.CFGs.CFG)\n  Create the array of statements that go in a :body Expr given a CFG \"bl\".\n\n\ndump_bb(bl::CompilerTools.CFGs.CFG)\n  Prints a CFG \"bl\" with varying degrees of verbosity from debug level 2 up to 4.\n\n\nfindReachable(reachable,  cur::Int64,  bbs::Dict{Int64, CompilerTools.CFGs.BasicBlock})\n  Process a basic block and add its successors to the set of reachable blocks\n\n\nfind_top_number(top_number::Int64,  bl::CompilerTools.CFGs.CFG)\n  Search for a statement with the given number in the CFG \"bl\".\n\n\nfrom_ast(ast)\n  The main entry point to construct a control-flow graph.\n\n\nfrom_expr(ast,  callback,  cbdata)\n  Another entry point to construct a control-flow graph but one that allows you to pass a callback and some opaque object\n\n\nfrom_expr(ast::LambdaStaticData,  depth,  state,  top_level,  callback,  cbdata)\n  The main routine that switches on all the various AST node types.\n\n\nfrom_goto(label,  state,  callback,  cbdata)\n  Process a GotoNode for CFG construction.\n\n\nfrom_if(args,  depth,  state,  callback,  cbdata)\n  Process a :gotoifnot Expr not for CFG construction.\n\n\nfrom_label(label,  state,  callback,  cbdata)\n  Process LabelNode for CFG construction.\n\n\nfrom_lambda(ast::Array{Any, 1},  depth,  state,  callback,  cbdata)\n  To help construct the CFG given a lambda, we recursively process the body of the lambda.\n\n\nfrom_return(args,  depth,  state,  callback,  cbdata)\n  Process a :return Expr for CFG construction.\n\n\ngetBbBodyOrder(bl::CompilerTools.CFGs.CFG)\n  Determine a valid and reasonable order of basic blocks in which to reconstruct a :body Expr.\n\n\ngetDistinctStatementNum(bl::CompilerTools.CFGs.CFG)\n  Get a possible new statement number by finding the maximum statement value in any BasicBlock in the given CFG and adding 1.\n\n\ngetMaxBB(bl::CompilerTools.CFGs.CFG)\n  Returns the maximum basic block label for the given CFG.\n\n\ngetMaxStatementNum(bb::CompilerTools.CFGs.BasicBlock)\n  Get the maximum statement index for a given BasicBlock.\n\n\ngetMinBB(bl::CompilerTools.CFGs.CFG)\n  Returns the minimum basic block label for the given CFG.\n\n\ninsertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64)\n  Given a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,\n\n\ninsertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64,  excludeBackEdge::Bool)\n  Given a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,\n\n\ninsertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64,  excludeBackEdge::Bool,  back_edge)\n  Given a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,\n\n\ninsertBetween(bl::CompilerTools.CFGs.CFG,  before::Int64,  after::Int64)\n  Insert a new basic block into the CFG \"bl\" between the basic blocks whose labels are \"before\" and \"after\".\n\n\ninsertStatementAfter(bl::CompilerTools.CFGs.CFG,  block,  stmt_idx,  new_stmt)\n  For a given CFG \"bl\" and a \"block\" in that CFG, add a new statement \"new_stmt\" to the basic block\n\n\ninsertStatementBefore(bl::CompilerTools.CFGs.CFG,  block,  stmt_idx,  new_stmt)\n  For a given CFG \"bl\" and a \"block\" in that CFG, add a new statement \"new_stmt\" to the basic block\n\n\ninsertat!(a,  value,  idx)\n  Insert into an array \"a\" with a given \"value\" at the specified index \"idx\".\n\n\nnot_handled(a,  b)\n  A default callback that handles no extra AST node types.\n\n\nremoveUselessBlocks(bbs::Dict{Int64, CompilerTools.CFGs.BasicBlock})\n  This function simplifies the dict of basic blocks \"bbs\".\n\n\nreplaceSucc(cur_bb::CompilerTools.CFGs.BasicBlock,  orig_succ::CompilerTools.CFGs.BasicBlock,  new_succ::CompilerTools.CFGs.BasicBlock)\n  For a given basic block \"cur_bb\", replace one of its successors \"orig_succ\" with a different successor \"new_succ\".\n\n\nuncompressed_ast(l::LambdaStaticData)\n  Convert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nupdate_label(x::Expr,  state::CompilerTools.CFGs.UpdateLabelState,  top_level_number,  is_top_level,  read)\n  An AstWalk callback that pattern matches GotoNode's and :gotoifnot Expr nodes and determines if the\n\n\nwrapInConditional(bl::CompilerTools.CFGs.CFG,  cond_gotoifnot::Expr,  first::Int64,  merge::Int64)\n  Modifies the CFG to create a conditional (i.e., if statement) that wraps a certain region of the CFG whose entry block is\n\n\nwrapInConditional(bl::CompilerTools.CFGs.CFG,  cond_gotoifnot::Expr,  first::Int64,  merge::Int64,  back_edge::Union{CompilerTools.CFGs.BasicBlock, Void})\n  Modifies the CFG to create a conditional (i.e., if statement) that wraps a certain region of the CFG whose entry block is\n\n\nCompilerTools.CFGs.BasicBlock\n  Data structure to hold information about one basic block in the control-flow graph.\n\n\nCompilerTools.CFGs.CFG\n  The main data structure to hold information about the control flow graph.\n\n\nCompilerTools.CFGs.TopLevelStatement\n  Data structure to hold the index (relative to the beginning of the body of the function) of a top-level statement\n\n\nCompilerTools.CFGs.UpdateLabelState\n  The opaque callback data type for the update_label callback.\n\n\nCompilerTools.CFGs.expr_state\n  Collects information about the CFG as it is being constructed.\n\n\nMODULE: CompilerTools.LambdaHandling\n\n\n\n\nExported\n\n\naddEscapingVariable(s::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Adds a new escaping variable with the given Symbol \"s\", type \"typ\", descriptor \"desc\" in LambdaInfo \"li\".\n\n\naddEscapingVariable(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Adds a new escaping variable from a VarDef in parameter \"vd\" into LambdaInfo \"li\".\n\n\naddGenSym(typ,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Add a new GenSym to the LambdaInfo in \"li\" with the given type in \"typ\".\n\n\naddLocalVariable(s::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Adds a new local variable with the given Symbol \"s\", type \"typ\", descriptor \"desc\" in LambdaInfo \"li\".\n\n\naddLocalVariable(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Adds a local variable from a VarDef to the given LambdaInfo.\n\n\ngetBody(lambda::Expr)\n  Returns the body expression part of a lambda expression.\n\n\ngetDesc(x::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Returns the descriptor for a local variable or input parameter \"x\" from LambdaInfo in \"li\".\n\n\ngetRefParams(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo)\n  Returns an array of Symbols corresponding to those parameters to the method that are going to be passed by reference.\n\n\ngetReturnType(li::CompilerTools.LambdaHandling.LambdaInfo)\n  Returns the type of the lambda as stored in LambdaInfo \"li\" and as extracted during lambdaExprToLambdaInfo.\n\n\ngetType(x::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Returns the type of a Symbol or GenSym in \"x\" from LambdaInfo in \"li\".\n\n\ngetVarDef(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Returns the VarDef for a Symbol in LambdaInfo in \"li\"\n\n\nisEscapingVariable(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Returns true if the Symbol in \"s\" is an escaping variable in LambdaInfo in \"li\".\n\n\nisInputParameter(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Returns true if the Symbol in \"s\" is an input parameter in LambdaInfo in \"li\".\n\n\nisLocalGenSym(s::GenSym,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Returns true if the GenSym in \"s\" is a GenSym in LambdaInfo in \"li\".\n\n\nisLocalVariable(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Returns true if the Symbol in \"s\" is a local variable in LambdaInfo in \"li\".\n\n\nlambdaExprToLambdaInfo(lambda::Expr)\n  Convert a lambda expression into our internal storage format, LambdaInfo.\n\n\nlambdaInfoToLambdaExpr(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo,  body)\n  Convert our internal storage format, LambdaInfo, back into a lambda expression.\n\n\nlambdaTypeinf(lambda::LambdaStaticData,  typs::Tuple)\n  Force type inference on a LambdaStaticData object.\n\n\nreplaceExprWithDict!(expr::ANY,  dict::Dict{Union{GenSym, Symbol}, Any})\n  Replace the symbols in an expression \"expr\" with those defined in the\n\n\nreplaceExprWithDict!(expr::ANY,  dict::Dict{Union{GenSym, Symbol}, Any},  AstWalkFunc)\n  Replace the symbols in an expression \"expr\" with those defined in the\n\n\nreplaceExprWithDict(expr,  dict::Dict{Union{GenSym, Symbol}, Any})\n  Replace the symbols in an expression \"expr\" with those defined in the\n\n\nupdateAssignedDesc(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo,  symbol_assigns::Dict{Symbol, Int64})\n  Update the descriptor part of the VarDef dealing with whether the variable is assigned or not in the function.\n\n\nCompilerTools.LambdaHandling.LambdaInfo\n  An internal format for storing a lambda expression's args[1] and args[2].\n\n\nCompilerTools.LambdaHandling.VarDef\n  Represents the triple stored in a lambda's args[2][1].\n\n\nSymGen\n  Type aliases for different unions of Symbol, SymbolNode, and GenSym.\n\n\n\n\nInternal\n\n\naddDescFlag(s::Symbol,  desc_flag::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Add one or more bitfields in \"desc_flag\" to the descriptor for a variable.\n\n\naddInputParameter(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Add Symbol \"s\" as input parameter to LambdaInfo \"li\".\n\n\naddInputParameters(collection,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Add all variable in \"collection\" as input parameters to LambdaInfo \"li\".\n\n\naddLocalVar(name::AbstractString,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Add a local variable to the function corresponding to LambdaInfo in \"li\" with name (as String), type and descriptor.\n\n\naddLocalVar(name::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Add a local variable to the function corresponding to LambdaInfo in \"li\" with name (as Symbol), type and descriptor.\n\n\naddLocalVariables(collection,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Add multiple local variables from some collection type.\n\n\ncount_symbols(x::Symbol,  state::CompilerTools.LambdaHandling.CountSymbolState,  top_level_number,  is_top_level,  read)\n  Adds symbols and gensyms to their corresponding sets in CountSymbolState when they are seen in the AST.\n\n\ncreateMeta(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo)\n  Create the args[2] part of a lambda expression given an object of our internal storage format LambdaInfo.\n\n\ncreateVarDict(x::Array{Any, 1})\n  Convert the lambda expression's args[2][1] from Array{Array{Any,1},1} to a Dict{Symbol,VarDef}.\n\n\ndictToArray(x::Dict{Symbol, CompilerTools.LambdaHandling.VarDef})\n  Convert the Dict{Symbol,VarDef} internal storage format from a dictionary back into an array of Any triples.\n\n\neliminateUnusedLocals!(li::CompilerTools.LambdaHandling.LambdaInfo,  body::Expr)\n  Eliminates unused symbols from the LambdaInfo var_defs.\n\n\neliminateUnusedLocals!(li::CompilerTools.LambdaHandling.LambdaInfo,  body::Expr,  AstWalkFunc)\n  Eliminates unused symbols from the LambdaInfo var_defs.\n\n\ngetLocalVariables(li::CompilerTools.LambdaHandling.LambdaInfo)\n  Returns an array of Symbols for local variables.\n\n\nmergeLambdaInfo(outer::CompilerTools.LambdaHandling.LambdaInfo,  inner::CompilerTools.LambdaHandling.LambdaInfo)\n  Merge \"inner\" lambdaInfo into \"outer\", and \"outer\" is changed as result.  Note\n\n\nremoveLocalVar(name::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Remove a local variable from lambda \"li\" given the variable's \"name\".\n\n\nshow(io::IO,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Pretty print a LambdaInfo.\n\n\nCompilerTools.LambdaHandling.CountSymbolState\n  Holds symbols and gensyms that are seen in a given AST when using the specified callback to handle non-standard Julia AST types.\n\n\nMODULE: CompilerTools.LivenessAnalysis\n\n\n\n\nExported\n\n\nfind_bb_for_statement(top_number::Int64,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  Search for a basic block containing a statement with the given top-level number in the liveness information.\n\n\nshow(io::IO,  bb::CompilerTools.LivenessAnalysis.BasicBlock)\n  Overload of Base.show to pretty-print a LivenessAnalysis.BasicBlock.\n\n\nshow(io::IO,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  Overload of Base.show to pretty-print BlockLiveness type.\n\n\nshow(io::IO,  tls::CompilerTools.LivenessAnalysis.TopLevelStatement)\n  Overload of Base.show to pretty-print a LivenessAnalysis.TopLevelStatement.\n\n\nCompilerTools.LivenessAnalysis.BlockLiveness\n  The main return type from LivenessAnalysis.\n\n\n\n\nInternal\n\n\nTypedExpr(typ,  rest...)\n  Convenience function to create an Expr and make sure the type is filled in as well.\n\n\naddUnmodifiedParams(func,  signature::Array{DataType, 1},  unmodifieds,  state::CompilerTools.LivenessAnalysis.expr_state)\n  Add an entry the dictionary of which arguments can be modified by which functions.\n\n\nadd_access(bb,  sym,  read)\n  Called when AST traversal finds some Symbol \"sym\" in a basic block \"bb\".\n\n\ncompute_live_ranges(state::CompilerTools.LivenessAnalysis.expr_state,  dfn)\n  Compute the live_in and live_out information for each basic block and statement.\n\n\ncountSymbolDefs(s,  lives)\n  Count the number of times that the symbol in \"s\" is defined in all the basic blocks.\n\n\ncreate_unmodified_args_dict()\n  Convert the function_descriptions table into a dictionary that can be passed to\n\n\ndef(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  Get the def information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.\n\n\ndump_bb(bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  Dump a bunch of debugging information about BlockLiveness.\n\n\nfind_top_number(top_number::Int64,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  Search for a statement with the given top-level number in the liveness information.\n\n\nfromCFG(live_res,  cfg::CompilerTools.CFGs.CFG,  callback::Function,  cbdata::ANY)\n  Extract liveness information from the CFG.\n\n\nfrom_assignment(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)\n  Walk through an assignment expression.\n\n\nfrom_call(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)\n  Walk through a call expression.\n\n\nfrom_expr(ast::Expr)\n  This function gives you the option of calling the ENTRY point from_expr with an ast and several optional named arguments.\n\n\nfrom_expr(ast::Expr,  callback)\n  ENTRY point to liveness analysis.\n\n\nfrom_expr(ast::Expr,  callback,  cbdata::ANY)\n  ENTRY point to liveness analysis.\n\n\nfrom_expr(ast::Expr,  callback,  cbdata::ANY,  no_mod)\n  ENTRY point to liveness analysis.\n\n\nfrom_expr(ast::LambdaStaticData,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)\n  Generic routine for how to walk most AST node types.\n\n\nfrom_exprs(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)\n  Walk through an array of expressions.\n\n\nfrom_if(args,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)\n  Process a gotoifnot which is just a recursive processing of its first arg which is the conditional.\n\n\nfrom_lambda(ast::Expr,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)\n  Walk through a lambda expression.\n\n\nfrom_return(args,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)\n  Process a return Expr node which is just a recursive processing of all of its args.\n\n\ngetUnmodifiedArgs(func::ANY,  args,  arg_type_tuple::Array{DataType, 1},  state::CompilerTools.LivenessAnalysis.expr_state)\n  For a given function and signature, return which parameters can be modified by the function.\n\n\nget_function_from_string(mod::AbstractString,  func::AbstractString)\n  Takes a module and a function both as Strings. Looks up the specified module as\n\n\nget_info_internal(x::Union{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.LivenessAnalysis.TopLevelStatement},  bl::CompilerTools.LivenessAnalysis.BlockLiveness,  field)\n  The live_in, live_out, def, and use routines are all effectively the same but just extract a different field name.\n\n\nisDef(x::Union{GenSym, Symbol},  live_info)\n  Query if the symbol in argument \"x\" is defined in live_info which can be a BasicBlock or TopLevelStatement.\n\n\nisPassedByRef(x,  state::CompilerTools.LivenessAnalysis.expr_state)\n  Returns true if a parameter is passed by reference.\n\n\nlive_in(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  Get the live_in information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.\n\n\nlive_out(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  Get the live_out information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.\n\n\nnot_handled(a,  b)\n  The default callback that processes no non-standard Julia AST nodes.\n\n\nrecompute_live_ranges(state,  dfn)\n  Clear the live_in and live_out data corresponding to all basic blocks and statements and then recompute liveness information.\n\n\ntypeOfOpr(x::ANY,  li::CompilerTools.LambdaHandling.LambdaInfo)\n  Get the type of some AST node.\n\n\nuncompressed_ast(l::LambdaStaticData)\n  Convert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nuse(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  Get the use information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.\n\n\nCompilerTools.LivenessAnalysis.AccessSummary\n  Sometimes if new AST nodes are introduced then we need to ask for their def and use set as a whole\n\n\nCompilerTools.LivenessAnalysis.BasicBlock\n  Liveness information for a BasicBlock.\n\n\nCompilerTools.LivenessAnalysis.TopLevelStatement\n  Liveness information for a TopLevelStatement in the CFG.\n\n\nCompilerTools.LivenessAnalysis.expr_state\n  Holds the state during the AST traversal.\n\n\nMODULE: ParallelAccelerator.Comprehension\n\n\n\n\nExported\n\n\n@comprehend(ast)\n  Translate all comprehension in an AST into equivalent code that uses cartesianarray call.\n\n\n\n\nInternal\n\n\ncomprehension_to_cartesianarray(ast)\n  Translate an ast whose head is :comprehension into equivalent code that uses cartesianarray call.\n\n\nprocess_node(node,  state,  top_level_number,  is_top_level,  read)\n  This function is a AstWalker callback.\n\n\nMODULE: ParallelAccelerator.DistributedIR\n\n\n\n\nInternal\n\n\ncheckParforsForDistribution(state::ParallelAccelerator.DistributedIR.DistIrState)\n  All arrays of a parfor should distributable for it to be distributable.\n\n\nget_arr_dist_info(node::Expr,  state,  top_level_number,  is_top_level,  read)\n  mark sequential arrays\n\n\nMODULE: ParallelAccelerator.API.Capture\n\n\n\n\nInternal\n\n\nprocess_node(node::Expr,  state,  top_level_number,  is_top_level,  read)\n  At macro level, we translate function calls and operators that matches operator names\n\n\nMODULE: ParallelAccelerator.DomainIR\n\n\n\n\nInternal\n\n\nlookupConstDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})\n  Look up a definition of a variable only when it is const or assigned once.\n\n\nlookupConstDefForArg(state::ParallelAccelerator.DomainIR.IRState,  s)\n  Look up a definition of a variable recursively until the RHS is no-longer just a variable.\n\n\nlookupDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})\n  Look up a definition of a variable.\n\n\nlookupDefInAllScopes(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})\n  Look up a definition of a variable throughout nested states until a definition is found.\n\n\nupdateDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode},  rhs)\n  Update the definition of a variable.\n\n\nMODULE: CompilerTools.DebugMsg\n\n\n\n\nExported\n\n\ninit()\n  A module using DebugMsg must call DebugMsg.init(), which expands to several local definitions\n\n\n\n\nInternal\n\n\nPROSPECT_DEV_MODE\n  When this module is first loaded, we check if PROSPECT_DEV_MODE is set in environment.\n\n\nMODULE: ParallelAccelerator.ParallelIR\n\n\n\n\nExported\n\n\nAstWalk(ast,  callback,  cbdata)\n  ParallelIR version of AstWalk.\n\n\nPIRInplace(x)\n  If set to non-zero, perform the phase where non-inplace maps are converted to inplace maps to reduce allocations.\n\n\nPIRNumSimplify(x)\n  Specify the number of passes over the AST that do things like hoisting and other rearranging to maximize fusion.\n\n\nPIRRunAsTasks(x)\n  Debugging feature to specify the number of tasks to create and to stop thereafter.\n\n\nPIRSetFuseLimit(x)\n  Control how many parfor can be fused for testing purposes.\n\n\nPIRShortcutArrayAssignment(x)\n  Enables an experimental mode where if there is a statement a = b and they are arrays and b is not live-out then \n\n\nPIRTaskGraphMode(x)\n  Control how blocks of code are made into tasks.\n\n\nfrom_exprs(ast::Array{Any, 1},  depth,  state)\n  Process an array of expressions.\n\n\nParallelAccelerator.ParallelIR.PIRLoopNest\n  Holds the information about a loop in a parfor node.\n\n\nParallelAccelerator.ParallelIR.PIRParForAst\n  The parfor AST node type.\n\n\nParallelAccelerator.ParallelIR.PIRReduction\n  Holds the information about a reduction in a parfor node.\n\n\n\n\nInternal\n\n\nAstWalkCallback(x::Expr,  dw::ParallelAccelerator.ParallelIR.DirWalk,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)\n  AstWalk callback that handles ParallelIR AST node types.\n\n\nEquivalenceClassesAdd(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  sym::Symbol)\n  Add a symbol as part of a new equivalence class if the symbol wasn't already in an equivalence class.\n\n\nEquivalenceClassesClear(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses)\n  Clear an equivalence class.\n\n\nEquivalenceClassesMerge(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  merge_to::Symbol,  merge_from::Symbol)\n  At some point we realize that two arrays must have the same dimensions but up until that point\n\n\nPIRBbReorder(x)\n  If set to non-zero, perform the bubble-sort like reordering phase to coalesce more parfor nodes together for fusion.\n\n\nPIRHoistAllocation(x)\n  If set to non-zero, perform the rearrangement phase that tries to moves alllocations outside of loops.\n\n\nTypedExpr(typ,  rest...)\n  This should pretty always be used instead of Expr(...) to form an expression as it forces the typ to be provided.\n\n\naddUnknownArray(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)\n  Given an array whose name is in \"x\", allocate a new equivalence class for this array.\n\n\naddUnknownRange(x::Array{Any, 1},  state::ParallelAccelerator.ParallelIR.expr_state)\n  Given an array of RangeExprs describing loop nest ranges, allocate a new equivalence class for this range.\n\n\nadd_merge_correlations(old_sym::Union{GenSym, Symbol},  new_sym::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)\n  If we somehow determine that two arrays must be the same length then \n\n\nasArray(x)\n  Return one element array with element x.\n\n\naugment_sn(dim::Int64,  index_vars,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})\n  Make sure the index parameters to arrayref or arrayset are Int64 or SymbolNode.\n\n\ncall_instruction_count(args,  state::ParallelAccelerator.ParallelIR.eic_state,  debug_level)\n  Generate an instruction count estimate for a call instruction.\n\n\ncheckAndAddSymbolCorrelation(lhs::Union{GenSym, Symbol},  state,  dim_array)\n  Make sure all the dimensions are SymbolNodes.\n\n\nconvertUnsafe(stmt)\n  Remove unsafe array access Symbols from the incoming \"stmt\".\n\n\nconvertUnsafeOrElse(stmt)\n  Try to remove unsafe array access Symbols from the incoming \"stmt\".  If successful, then return the updated\n\n\nconvertUnsafeWalk(x::Expr,  state,  top_level_number,  is_top_level,  read)\n  The AstWalk callback to find unsafe arrayset and arrayref variants and\n\n\ncopy_propagate(node::ANY,  data::ParallelAccelerator.ParallelIR.CopyPropagateState,  top_level_number,  is_top_level,  read)\n  In each basic block, if there is a \"copy\" (i.e., something of the form \"a = b\") then put\n\n\ncount_assignments(x,  symbol_assigns::Dict{Symbol, Int64},  top_level_number,  is_top_level,  read)\n  AstWalk callback to count the number of static times that a symbol is assigne within a method.\n\n\ncreate1D_array_access_desc(array::SymbolNode)\n  Create an array access descriptor for \"array\".\n\n\ncreate2D_array_access_desc(array::SymbolNode)\n  Create an array access descriptor for \"array\".\n\n\ncreateInstructionCountEstimate(the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Takes a parfor and walks the body of the parfor and estimates the number of instruction needed for one instance of that body.\n\n\ncreateLoweredAliasMap(dict1)\n  Take a single-step alias map, e.g., a=\nb, b=\nc, and create a lowered dictionary, a=\nc, b=\nc, that\n\n\ncreateMapLhsToParfor(parfor_assignment,  the_parfor,  is_multi::Bool,  sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  state::ParallelAccelerator.ParallelIR.expr_state)\n  Creates a mapping between variables on the left-hand side of an assignment where the right-hand side is a parfor\n\n\ncreateStateVar(state,  name,  typ,  access)\n  Add a local variable to the current function's lambdaInfo.\n\n\ncreateTempForArray(array_sn::Union{GenSym, Symbol, SymbolNode},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Create a temporary variable that is parfor private to hold the value of an element of an array.\n\n\ncreateTempForRangeOffset(num_used,  ranges::Array{ParallelAccelerator.ParallelIR.RangeData, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Create a variable to hold the offset of a range offset from the start of the array.\n\n\ncreateTempForRangedArray(array_sn::Union{GenSym, Symbol, SymbolNode},  range::Array{Union{GenSym, SymbolNode}, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Create a temporary variable that is parfor private to hold the value of an element of an array.\n\n\ncreate_array_access_desc(array::SymbolNode)\n  Create an array access descriptor for \"array\".\n\n\ncreate_equivalence_classes(node::Expr,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)\n  AstWalk callback to determine the array equivalence classes.\n\n\ndfsVisit(swd::ParallelAccelerator.ParallelIR.StatementWithDeps,  vtime::Int64,  topo_sort::Array{ParallelAccelerator.ParallelIR.StatementWithDeps, N})\n  Construct a topological sort of the dependence graph.\n\n\nestimateInstrCount(ast::Expr,  state::ParallelAccelerator.ParallelIR.eic_state,  top_level_number,  is_top_level,  read)\n  AstWalk callback for estimating the instruction count.\n\n\nextractArrayEquivalencies(node::Expr,  state)\n  \"node\" is a domainIR node.  Take the arrays used in this node, create an array equivalence for them if they \n\n\nfindSelectedDimensions(inputInfo::Array{ParallelAccelerator.ParallelIR.InputInfo, 1},  state)\n  Given all the InputInfo for a Domain IR operation being lowered to Parallel IR,\n\n\nflattenParfor(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst)\n  Takes a new array of body statements in the process of construction in \"new_body\" and takes a parfor to add to that\n\n\nfrom_assertEqShape(node::Expr,  state)\n  Create array equivalences from an assertEqShape AST node.\n\n\nfrom_assignment(lhs,  rhs,  depth,  state)\n  Process an assignment expression.\n\n\nfrom_call(ast::Array{Any, 1},  depth,  state)\n  Process a call AST node.\n\n\nfrom_expr(ast::Expr,  depth,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level)\n  The main ParallelIR function for processing some node in the AST.\n\n\nfrom_lambda(lambda::Expr,  depth,  state)\n  Process a :lambda Expr.\n\n\nfrom_root(function_name,  ast::Expr)\n  The main ENTRY point into ParallelIR.\n\n\nfullyLowerAlias(dict::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  input::Union{GenSym, Symbol})\n  Given an \"input\" Symbol, use that Symbol as key to a dictionary.  While such a Symbol is present\n\n\nfuse(body,  body_index,  cur,  state)\n  Test whether we can fuse the two most recent parfor statements and if so to perform that fusion.\n\n\ngenerate_instr_count(function_name,  signature)\n  Try to figure out the instruction count for a given call.\n\n\ngetArrayElemType(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Returns the element type of an Array.\n\n\ngetArrayElemType(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Returns the element type of an Array.\n\n\ngetArrayElemType(atyp::DataType)\n  Returns the element type of an Array.\n\n\ngetArrayNumDims(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Return the number of dimensions of an Array.\n\n\ngetArrayNumDims(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Return the number of dimensions of an Array.\n\n\ngetConstDims(num_dim_inputs,  inputInfo::ParallelAccelerator.ParallelIR.InputInfo)\n  In the case where a domain IR operation on an array creates a lower dimensional output,\n\n\ngetCorrelation(sng::Union{GenSym, Symbol, SymbolNode},  state::ParallelAccelerator.ParallelIR.expr_state)\n  Get the equivalence class of a domain IR input in inputInfo.\n\n\ngetFirstArrayLens(prestatements,  num_dims)\n  Get the variable which holds the length of the first input array to a parfor.\n\n\ngetIO(stmt_ids,  bb_statements)\n  Given a set of statement IDs and liveness information for the statements of the function, determine\n\n\ngetInputSet(node::ParallelAccelerator.ParallelIR.PIRParForAst)\n  Returns a Set with all the arrays read by this parfor.\n\n\ngetLhsFromAssignment(assignment)\n  Get the left-hand side of an assignment expression.\n\n\ngetLhsOutputSet(lhs,  assignment)\n  Get the real outputs of an assignment statement.\n\n\ngetMaxLabel(max_label,  stmts::Array{Any, 1})\n  Scan the body of a function in \"stmts\" and return the max label in a LabelNode AST seen in the body.\n\n\ngetNonBlock(head_preds,  back_edge)\n  Find the basic block before the entry to a loop.\n\n\ngetOrAddArrayCorrelation(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)\n  Return a correlation set for an array.  If the array was not previously added then add it and return it.\n\n\ngetOrAddRangeCorrelation(ranges::Array{ParallelAccelerator.ParallelIR.RangeExprs, 1},  state::ParallelAccelerator.ParallelIR.expr_state)\n  Gets (or adds if absent) the range correlation for the given array of RangeExprs.\n\n\ngetOrAddSymbolCorrelation(array::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state,  dims::Array{Union{GenSym, Symbol}, 1})\n  A new array is being created with an explicit size specification in dims.\n\n\ngetParforCorrelation(parfor,  state)\n  Get the equivalence class of the first array who length is extracted in the pre-statements of the specified \"parfor\".\n\n\ngetParforNode(node)\n  Get the parfor object from either a bare parfor or one part of an assignment.\n\n\ngetPrivateSet(body::Array{Any, 1})\n  Go through the body of a parfor and collect those Symbols, GenSyms, etc. that are assigned to within the parfor except reduction variables.\n\n\ngetPrivateSetInner(x::Expr,  state::Set{Union{GenSym, Symbol, SymbolNode}},  top_level_number::Int64,  is_top_level::Bool,  read::Bool)\n  The AstWalk callback function for getPrivateSet.\n\n\ngetRhsFromAssignment(assignment)\n  Get the right-hand side of an assignment expression.\n\n\ngetSName(ssn::Symbol)\n  Get the name of a symbol whether the input is a Symbol or SymbolNode or :(::) Expr.\n\n\nget_one(ast::Array{T, N})\n  Take something returned from AstWalk and assert it should be an array but in this\n\n\nget_unique_num()\n  If we need to generate a name and make sure it is unique then include an monotonically increasing number.\n\n\nhasNoSideEffects(node::Union{GenSym, LambdaStaticData, Number, Symbol, SymbolNode})\n  Sometimes statements we exist in the AST of the form a=Expr where a is a Symbol that isn't live past the assignment\n\n\nhasSymbol(ssn::Symbol)\n  Returns true if the incoming AST node can be interpreted as a Symbol.\n\n\nhoistAllocation(ast::Array{Any, 1},  lives,  domLoop::CompilerTools.Loops.DomLoops,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Try to hoist allocations outside the loop if possible.\n\n\ninsert_no_deps_beginning(node,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read)\n  Works with remove_no_deps below to move statements with no dependencies to the beginning of the AST.\n\n\nintermediate_from_exprs(ast::Array{Any, 1},  depth,  state)\n  Process an array of expressions that aren't from a :body Expr.\n\n\nisArrayType(typ)\n  Returns true if the incoming type in \"typ\" is an array type.\n\n\nisArrayType(x::SymbolNode)\n  Returns true if a given SymbolNode \"x\" is an Array type.\n\n\nisArrayref(x)\n  Is a node an arrayref node?\n\n\nisArrayrefCall(x::Expr)\n  Is a node a call to arrayref.\n\n\nisArrayset(x)\n  Is a node an arrayset node?\n\n\nisArraysetCall(x::Expr)\n  Is a node a call to arrayset.\n\n\nisAssignmentNode(node::Expr)\n  Is a node an assignment expression node.\n\n\nisBareParfor(node::Expr)\n  Is this a parfor node not part of an assignment statement.\n\n\nisDomainNode(ast::Expr)\n  Returns true if the given \"ast\" node is a DomainIR operation.\n\n\nisFusionAssignment(x::Expr)\n  Check if an assignement is a fusion assignment.\n\n\nisLoopheadNode(node::Expr)\n  Is a node a loophead expression node (a form of assignment).\n\n\nisParforAssignmentNode(node::Expr)\n  Is a node an assignment expression with a parfor node as the right-hand side.\n\n\nisSymbolsUsed(vars,  top_level_numbers::Array{Int64, 1},  state)\n  Returns true if any variable in the collection \"vars\" is used in any statement whose top level number is in \"top_level_numbers\".\n\n\nis_eliminated_arraylen(x::Expr)\n  Returns true if the input node is an assignment node where the right-hand side is a call to arraysize.\n\n\nisbitstuple(a::Tuple)\n  Returns true if input \"a\" is a tuple and each element of the tuple of isbits type.\n\n\niterations_equals_inputs(node::ParallelAccelerator.ParallelIR.PIRParForAst)\n  Returns true if the domain operation mapped to this parfor has the property that the iteration space\n\n\nlambdaFromDomainLambda(domain_lambda,  dl_inputs)\n  Form a Julia :lambda Expr from a DomainLambda.\n\n\nmakePrivateParfor(var_name::Symbol,  state)\n  Takes an existing variable whose name is in \"var_name\" and adds the descriptor flag ISPRIVATEPARFORLOOP to declare the\n\n\nmakeTasks(start_index,  stop_index,  body,  bb_live_info,  state,  task_graph_mode)\n  For a given start and stop index in some body and liveness information, form a set of tasks.\n\n\nmaxFusion(bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  For every basic block, try to push domain IR statements down and non-domain IR statements up so that domain nodes\n\n\nmergeLambdaIntoOuterState(state,  inner_lambda::Expr)\n  Pull the information from the inner lambda into the outer lambda.\n\n\nmerge_correlations(state,  unchanging,  eliminate)\n  If we somehow determine that two sets of correlations are actually the same length then merge one into the other.\n\n\nmk_alloc_array_1d_expr(elem_type,  atype,  length)\n  Return an expression that allocates and initializes a 1D Julia array that has an element type specified by\n\n\nmk_alloc_array_2d_expr(elem_type,  atype,  length1,  length2)\n  Return an expression that allocates and initializes a 2D Julia array that has an element type specified by\n\n\nmk_alloc_array_3d_expr(elem_type,  atype,  length1,  length2,  length3)\n  Return an expression that allocates and initializes a 3D Julia array that has an element type specified by\n\n\nmk_arraylen_expr(x::ParallelAccelerator.ParallelIR.InputInfo,  dim::Int64)\n  Create an expression whose value is the length of the input array.\n\n\nmk_arraylen_expr(x::Union{GenSym, Symbol, SymbolNode},  dim::Int64)\n  Create an expression whose value is the length of the input array.\n\n\nmk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Return an expression that corresponds to getting the index_var index from the array array_name.\n\n\nmk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1})\n  Return an expression that corresponds to getting the index_var index from the array array_name.\n\n\nmk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})\n  Return an expression that corresponds to getting the index_var index from the array array_name.\n\n\nmk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\n\n\nmk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1})\n  Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\n\n\nmk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})\n  Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".\n\n\nmk_assignment_expr(lhs::Union{GenSym, Symbol, SymbolNode},  rhs,  state::ParallelAccelerator.ParallelIR.expr_state)\n  Create an assignment expression AST node given a left and right-hand side.\n\n\nmk_colon_expr(start_expr,  skip_expr,  end_expr)\n  Returns an expression to construct a :colon object that contains the start of a range, the end and the skip expression.\n\n\nmk_convert(new_type,  ex)\n  Returns an expression that convert \"ex\" into a another type \"new_type\".\n\n\nmk_gotoifnot_expr(cond,  goto_label)\n  Returns a :gotoifnot Expr given a condition \"cond\" and a label \"goto_label\".\n\n\nmk_next_expr(colon_sym,  start_sym)\n  Returns a :next call Expr that gets the next element of an iteration range from a :colon object.\n\n\nmk_parallelir_ref(sym)\n  Create an expression that references something inside ParallelIR.\n\n\nmk_parallelir_ref(sym,  ref_type)\n  Create an expression that references something inside ParallelIR.\n\n\nmk_parfor_args_from_mmap!(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  with_indices,  domain_oprs,  state)\n  The main routine that converts a mmap! AST node to a parfor AST node.\n\n\nmk_parfor_args_from_mmap(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  domain_oprs,  state)\n  The main routine that converts a mmap AST node to a parfor AST node.\n\n\nmk_parfor_args_from_reduce(input_args::Array{Any, 1},  state)\n  The main routine that converts a reduce AST node to a parfor AST node.\n\n\nmk_return_expr(outs)\n  Given an array of outputs in \"outs\", form a return expression.\n\n\nmk_start_expr(colon_sym)\n  Returns an expression to get the start of an iteration range from a :colon object.\n\n\nmk_svec_expr(parts...)\n  Make a svec expression.\n\n\nmk_tuple_expr(tuple_fields,  typ)\n  Return an expression which creates a tuple.\n\n\nmk_tupleref_expr(tuple_var,  index,  typ)\n  Create an expression which returns the index'th element of the tuple whose name is contained in tuple_var.\n\n\nmk_untyped_assignment(lhs,  rhs)\n  Only used to create fake expression to force lhs to be seen as written rather than read.\n\n\nmmapInline(ast::Expr,  lives,  uniqSet)\n  # If a definition of a mmap is only used once and not aliased, it can be inlined into its\n\n\nmmapToMmap!(ast,  lives,  uniqSet)\n  Performs the mmap to mmap! phase.\n\n\nmustRemainLastStatementInBlock(node::GotoNode)\n  Returns true if the given AST \"node\" must remain the last statement in a basic block.\n\n\nnameToSymbolNode(name::Symbol,  sym_to_type)\n  Forms a SymbolNode given a symbol in \"name\" and get the type of that symbol from the incoming dictionary \"sym_to_type\".\n\n\nnested_function_exprs(max_label,  domain_lambda,  dl_inputs)\n  A routine similar to the main parallel IR entry put but designed to process the lambda part of\n\n\nnext_label(state::ParallelAccelerator.ParallelIR.expr_state)\n  Returns the next usable label for the current function.\n\n\noneIfOnly(x)\n  Returns a single element of an array if there is only one or the array otherwise.\n\n\nparforToTask(parfor_index,  bb_statements,  body,  state)\n  Given a parfor statement index in \"parfor_index\" in the \"body\"'s statements, create a TaskInfo node for this parfor.\n\n\npirPrintDl(dbg_level,  dl)\n  Debug print the parts of a DomainLambda.\n\n\npir_alias_cb(ast::Expr,  state,  cbdata)\n  An AliasAnalysis callback (similar to LivenessAnalysis callback) that handles ParallelIR introduced AST node types.\n\n\npir_live_cb(ast::Expr,  cbdata::ANY)\n  A LivenessAnalysis callback that handles ParallelIR introduced AST node types.\n\n\npir_live_cb_def(x)\n  Just call the AST walker for symbol for parallel IR nodes with no state.\n\n\nprintBody(dlvl,  body::Array{Any, 1})\n  Pretty print the args part of the \"body\" of a :lambda Expr at a given debug level in \"dlvl\".\n\n\nprintLambda(dlvl,  node::Expr)\n  Pretty print a :lambda Expr in \"node\" at a given debug level in \"dlvl\".\n\n\nprocessAndUpdateBody(lambda::Expr,  f::Function,  state)\n  Apply a function \"f\" that takes the :body from the :lambda and returns a new :body that is stored back into the :lambda.\n\n\nrangeSize(start,  skip,  last)\n  Compute size of a range.\n\n\nrangeToRangeData(range::Expr,  pre_offsets::Array{Expr, 1},  arr,  range_num::Int64,  state)\n  Convert a :range Expr introduced by Domain IR into a Parallel IR data structure RangeData.\n\n\nrecreateLoops(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state,  newLambdaInfo)\n  In threads mode, we can't have parfor_start and parfor_end in the code since Julia has to compile the code itself and so\n\n\nrecreateLoopsInternal(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  loop_nest_level,  next_available_label,  state,  newLambdaInfo)\n  This is a recursive routine to reconstruct a regular Julia loop nest from the loop nests described in PIRParForAst.\n\n\nrememberTypeForSym(sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  sym::Union{GenSym, Symbol},  typ::DataType)\n  Add to the map of symbol names to types.\n\n\nremoveAssertEqShape(args::Array{Any, 1},  state)\n  Implements one of the main ParallelIR passes to remove assertEqShape AST nodes from the body if they are statically known to be in the same equivalence class.\n\n\nremoveNothingStmts(args::Array{Any, 1},  state)\n  Empty statements can be added to the AST by some passes in ParallelIR.\n\n\nremove_dead(node,  data::ParallelAccelerator.ParallelIR.RemoveDeadState,  top_level_number,  is_top_level,  read)\n  An AstWalk callback that uses liveness information in \"data\" to remove dead stores.\n\n\nremove_extra_allocs(ast)\n  removes extra allocations\n\n\nremove_no_deps(node::ANY,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read)\n  # This routine gathers up nodes that do not use\n\n\nreplaceParforWithDict(parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  gensym_map)\n  Not currently used but might need it at some point.\n\n\nrun_as_task()\n  Return true if run_as_task_decrement would return true but don't update the run_as_tasks count.\n\n\nrun_as_task_decrement()\n  If run_as_tasks is positive then convert this parfor to a task and decrement the count so that only the\n\n\nselectToRangeData(select::Expr,  pre_offsets::Array{Expr, 1},  state)\n  Convert the range(s) part of a :select Expr introduced by Domain IR into an array of Parallel IR data structures RangeData.\n\n\nseqTask(body_indices,  bb_statements,  body,  state)\n  Form a task out of a range of sequential statements.\n\n\nshow(io::IO,  pnode::ParallelAccelerator.ParallelIR.PIRParForAst)\n  Overload of Base.show to pretty print for parfor AST nodes.\n\n\nsimpleIndex(dict)\n  Returns true if all array references use singular index variables and nothing more complicated involving,\n\n\nsub_arraylen_walk(x::Expr,  replacement,  top_level_number,  is_top_level,  read)\n  AstWalk callback that does the work of substitute_arraylen on a node-by-node basis.\n\n\nsub_arrayset_walk(x::Expr,  cbd,  top_level_number,  is_top_level,  read)\n  AstWalk callback that does the work of substitute_arrayset on a node-by-node basis.\n\n\nsub_cur_body_walk(x::Expr,  cbd::ParallelAccelerator.ParallelIR.cur_body_data,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)\n  AstWalk callback that does the work of substitute_cur_body on a node-by-node basis.\n\n\nsubstitute_arraylen(x,  replacement)\n  replacement is an array containing the length of the dimensions of the arrays a part of this parfor.\n\n\nsubstitute_arrayset(x,  arrays_set_in_cur_body,  output_items_with_aliases)\n  Modify the body of a parfor.\n\n\nsubstitute_cur_body(x,  temp_map::Dict{Union{GenSym, Symbol}, Union{GenSym, SymbolNode}},  index_map::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  arrays_set_in_cur_body::Set{Union{GenSym, Symbol}},  replace_array_name_in_arrayset::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  state::ParallelAccelerator.ParallelIR.expr_state)\n  Make changes to the second parfor body in the process of parfor fusion.\n\n\ntaskableParfor(node)\n  Returns true if the \"node\" is a parfor and the task limit hasn't been exceeded.\n\n\ntoSNGen(x::Symbol,  typ)\n  If we have the type, convert a Symbol to SymbolNode.\n\n\ntoSymGen(x::Symbol)\n  In various places we need a SymGen type which is the union of Symbol and GenSym.\n\n\ntoSymNodeGen(x::Symbol,  typ)\n  Form a SymbolNode with the given typ if possible or a GenSym if that is what is passed in.\n\n\nuncompressed_ast(l::LambdaStaticData)\n  Convert a compressed LambdaStaticData format into the uncompressed AST format.\n\n\nParallelAccelerator.ParallelIR.CopyPropagateState\n  State to aide in the copy propagation phase.\n\n\nParallelAccelerator.ParallelIR.DirWalk\n  Wraps the callback and opaque data passed from the user of ParallelIR's AstWalk.\n\n\nParallelAccelerator.ParallelIR.DomainOperation\n  Holds information about domain operations part of a parfor node.\n\n\nParallelAccelerator.ParallelIR.EquivalenceClasses\n  Holds a dictionary from an array symbol to an integer corresponding to an equivalence class.\n\n\nParallelAccelerator.ParallelIR.FusionSentinel\n  Just used to hold a spot in an array to indicate the this is a special assignment expression with embedded real array output names from a fusion.\n\n\nParallelAccelerator.ParallelIR.InProgress\n  A sentinel in the instruction count estimation process.\n\n\nParallelAccelerator.ParallelIR.InputInfo\n  Type used by mk_parfor_args... functions to hold information about input arrays.\n\n\nParallelAccelerator.ParallelIR.InsertTaskNode\n  A data type containing the information that CGen uses to generate a call to pert_insert_divisible_task.\n\n\nParallelAccelerator.ParallelIR.PIRParForStartEnd\n  After lowering, it is necessary to make the parfor body top-level statements so that basic blocks\n\n\nParallelAccelerator.ParallelIR.RangeData\n  Holds the information from one Domain IR :range Expr.\n\n\nParallelAccelerator.ParallelIR.RemoveDeadState\n  Holds liveness information for the remove_dead AstWalk phase.\n\n\nParallelAccelerator.ParallelIR.RemoveNoDepsState\n  State for the remove_no_deps and insert_no_deps_beginning phases.\n\n\nParallelAccelerator.ParallelIR.ReplacedRegion\n  Store information about a section of a body that will be translated into a task.\n\n\nParallelAccelerator.ParallelIR.RhsDead\n  Marks an assignment statement where the left-hand side can take over the storage from the right-hand side.\n\n\nParallelAccelerator.ParallelIR.StatementWithDeps\n  Type for dependence graph creation and topological sorting.\n\n\nParallelAccelerator.ParallelIR.TaskInfo\n  Structure for storing information about task formation.\n\n\nParallelAccelerator.ParallelIR.cur_body_data\n  Holds the data for substitute_cur_body AST walk.\n\n\nParallelAccelerator.ParallelIR.cuw_state\n  Just to hold the \"found\" Bool that says whether a unsafe variant was replaced with a regular version.\n\n\nParallelAccelerator.ParallelIR.expr_state\n  State passed around while converting an AST from domain to parallel IR.\n\n\nParallelAccelerator.ParallelIR.pir_arg_metadata\n  A Julia representation of the argument metadata that will be passed to the runtime.\n\n\nParallelAccelerator.ParallelIR.pir_array_access_desc\n  Describes an array.\n\n\nParallelAccelerator.ParallelIR.pir_grain_size\n  A Julia representation of the grain size that will be passed to the runtime.\n\n\nParallelAccelerator.ParallelIR.pir_range\n  Translated to pert_range_Nd_t in the task runtime.\n\n\nParallelAccelerator.ParallelIR.pir_range_actual\n  Similar to pir_range but used in circumstances where the expressions must have already been evaluated.\n\n\nParallelAccelerator.ParallelIR.sub_arrayset_data\n  Holds data for modifying arrayset calls.\n\n\nMODULE: CompilerTools.OptFramework\n\n\n\n\nExported\n\n\naddOptPass(func,  level)\n  Same as the other addOptPass but with a pass call back function and pass level as input.\n\n\naddOptPass(pass::CompilerTools.OptFramework.OptPass)\n  Add an optimization pass. If this is going to be called multiple times then you need some external way of corrdinating the code/modules that are calling this function so that optimization passes are added in some sane order.\n\n\n@acc(ast1, ast2...)\n  The @acc macro comes in two forms:\n\n\n@noacc(ast)\n  The macro @noacc can be used at call site to specifically run the non-accelerated copy of an accelerated function. It has no effect and gives a warning when the given function is not found to have been accelerated. We do not support nested @acc or @noacc. \n\n\n\n\nInternal\n\n\nTypedExpr(typ,  rest...)\n  Creates a typed Expr AST node.\n\n\ncleanupASTLabels(ast)\n  Clean up the labels in AST by renaming them, and removing duplicates.\n\n\nconvertCodeToLevel(ast::ANY,  sig::ANY,  old_level,  new_level,  func)\n  convert AST from \"old_level\" to \"new_level\". The input \"ast\" can be either Expr or Function type. In the latter case, the result AST will be obtained from this function using an matching signature \"sig\". The last \"func\" is a skeleton function that is used internally to facility such conversion.\n\n\nconvert_expr(per_site_opt_set,  ast)\n  When @acc is used at a function's callsite, we use AstWalk to search for callsites via the opt_calls_insert_trampoline callback and to then insert trampolines.  That updated expression containing trampoline calls is then returned as the generated code from the @acc macro.\n\n\nconvert_function(per_site_opt_set,  opt_set,  macros,  ast)\n  When @acc is used at a function definition, it creates a trampoline function, when called with a specific set of signature types, will try to optimize the original function, and call it with the real arguments.  The input \"ast\" should be an AST of the original function at macro level, which will be   replaced by the trampoline. \n\n\ncreate_label_map(x,  state::CompilerTools.OptFramework.lmstate,  top_level_number,  is_top_level,  read)\n  An AstWalk callback that collects information about labels in an AST.\n\n\ndumpLevel(level)\n  pretty print pass level number as string.\n\n\nevalPerSiteOptSet(per_site_opt_set)\n  Statically evaluate per-site optimization passes setting, and return the result.\n\n\nfindOriginalFunc(mod::Module,  name::Symbol)\n  Find the original (before @acc macro) function for a wrapper function in the given module. \n\n\nfindTargetFunc(mod::Module,  name::Symbol)\n  Find the optimizing target function (after @acc macro) for a wrapper function in the given module. \n\n\ngetCodeAtLevel(func,  sig,  level)\n  Retrieve the AST of the given function \"func\" and signature \"sig\" for at the given pass \"level\".\n\n\nidentical{T}(t::Type{T},  x::T)\n  A hack to get around Julia's type inference. This is essentially an identity conversion,\n\n\nmakeWrapperFunc(new_fname::Symbol,  real_fname::Symbol,  call_sig_args::Array{Any, 1},  per_site_opt_set)\n  Define a wrapper function with the name given by \"new_func\" that when called will try to optimize the \"real_func\" function, and run it with given parameters in \"call_sig_args\". The input \"per_site_opt_set\" can be either nothing, or a quoted Expr that refers to an array of OptPass.\n\n\nopt_calls_insert_trampoline(x,  per_site_opt_set,  top_level_number,  is_top_level,  read)\n  An AstWalk callback function.\n\n\nprocessFuncCall(func::ANY,  call_sig_arg_tuple::ANY,  per_site_opt_set::ANY)\n  Takes a function, a signature, and a set of optimizations and applies that set of optimizations to the function,\n\n\nremoveDupLabels(stmts)\n  Sometimes update_labels creates two label nodes that are the same.\n\n\nsetOptPasses(passes::Array{CompilerTools.OptFramework.OptPass, 1})\n  Set the default set of optimization passes to apply with the @acc macro. \n\n\ntfuncPresent(func,  tt)\n  Makes sure that a newly created function is correctly present in the internal Julia method table.\n\n\nupdate_labels(x,  state::CompilerTools.OptFramework.lmstate,  top_level_number,  is_top_level,  read)\n  An AstWalk callback that applies the label map created during create_label_map AstWalk.\n\n\nCompilerTools.OptFramework.OptPass\n  A data structure that holds information about one high-level optimization pass to run.\n\n\nCompilerTools.OptFramework.lmstate\n  The callback state variable used by create_label_map and update_labels.\n\n\ngOptFrameworkDict\n  A global memo-table that maps both: the triple (function, signature, optPasses) to the trampoline function, and the trampoline function to the real function.\n\n\nMODULE: CompilerTools.UDChains\n\n\n\n\nInternal\n\n\ngetOrCreate(live::Dict{Symbol, Set{T}},  s::Symbol)\n  Get the set of definition blocks reaching this block for a given symbol \"s\".\n\n\ngetOrCreate(udchains::Dict{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.UDChains.UDInfo},  bb::CompilerTools.LivenessAnalysis.BasicBlock)\n  Get the UDInfo for a specified basic block \"bb\" or create one if it doesn't already exist.\n\n\ngetUDChains(bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  Get the Use-Definition chains at a basic block level given LivenessAnalysis.BlockLiveness as input in \"bl\".\n\n\nprintLabels(level,  dict)\n  Print a live in or live out dictionary in a nice way if the debug level is set high enough.\n\n\nprintSet(level,  s)\n  Print the set part of a live in or live out dictiononary in a nice way if the debug level is set high enough.\n\n\nprintUDInfo(level,  ud)\n  Print UDChains in a nice way if the debug level is set high enough.\n\n\nCompilerTools.UDChains.UDInfo\n  Contains the UDchains for one basic block.\n\n\nMODULE: CompilerTools.Loops\n\n\n\n\nExported\n\n\nCompilerTools.Loops.DomLoops\n  A type that holds information about which basic blocks dominate which other blocks.\n\n\nCompilerTools.Loops.Loop\n  A type to hold information about a loop.\n\n\n\n\nInternal\n\n\ncompute_dom_loops(bl::CompilerTools.CFGs.CFG)\n  Find the loops in a CFGs.CFG in \"bl\".\n\n\nfindLoopInvariants(l::CompilerTools.Loops.Loop,  udinfo::Dict{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.UDChains.UDInfo},  bl::CompilerTools.LivenessAnalysis.BlockLiveness)\n  Finds those computations within a loop that are iteration invariant.\n\n\nfindLoopMembers(head,  back_edge,  bbs)\n  Find all the members of the loop as specified by the \"head\" basic block and the \"back_edge\" basic block.\n\n\nflm_internal(cur_bb,  members,  bbs)\n  Add to the \"members\" of the loop being accumulated given \"cur_bb\" which is known to be a member of the loop.\n\n\nisInLoop(dl::CompilerTools.Loops.DomLoops,  bb::Int64)\n  Takes a DomLoops object containing loop information about the function.\n\n\nMODULE: ParallelAccelerator\n\n\n\n\nInternal\n\n\ninit\n()\n  Called when the package is loaded to do initialization.\n\n\nembed()\n  This version of embed tries to use JULIA_HOME to find the root of the source distribution.\n\n\nembed(julia_root)\n  Call this function if you want to embed binary-code of ParallelAccelerator into your Julia build to speed-up @acc compilation time.\n\n\ngetPackageRoot()\n  Generate a file path to the directory above the one containing this source file.\n\n\ngetPseMode()\n  Return internal mode number by looking up environment variable \"PROSPECT_MODE\".\n\n\ngetTaskMode()\n  Return internal mode number by looking up environment variable \"PROSPECT_TASK_MODE\".", 
            "title": "Api index"
        }, 
        {
            "location": "/api-index/#api-index", 
            "text": "", 
            "title": "API-INDEX"
        }, 
        {
            "location": "/api-index/#module-parallelacceleratordriver", 
            "text": "", 
            "title": "MODULE: ParallelAccelerator.Driver"
        }, 
        {
            "location": "/api-index/#exported", 
            "text": "captureOperators(func,  ast,  sig)   A pass that translates supported operators and function calls to  runStencilMacro(func,  ast,  sig)   Pass that translates runStencil call in the same way as a macro would do.  toCartesianArray(func,  ast,  sig)   Pass for comprehension to cartesianarray translation.", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#module-parallelacceleratorapistencil", 
            "text": "", 
            "title": "MODULE: ParallelAccelerator.API.Stencil"
        }, 
        {
            "location": "/api-index/#exported_1", 
            "text": "runStencil(inputs...)   \"runStencil\" takes arguments in the form of \"(kernel_function, A, B, C, ...,", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal", 
            "text": "process_node(node,  state,  top_level_number,  is_top_level,  read)   This function is a AstWalker callback.  @comprehend(ast)   Translate all comprehension in an AST into equivalent code that uses cartesianarray call.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-compilertoolsreadwriteset", 
            "text": "", 
            "title": "MODULE: CompilerTools.ReadWriteSet"
        }, 
        {
            "location": "/api-index/#exported_2", 
            "text": "from_exprs(ast::Array{T, N})   Walk through an array of expressions.  from_exprs(ast::Array{T, N},  callback::Union{Function, Void},  cbdata::ANY)   Walk through an array of expressions.  from_exprs(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)   Walk through an array of expressions.  isRead(sym::Union{GenSym, Symbol},  rws::CompilerTools.ReadWriteSet.ReadWriteSetType)   Return true if some symbol in \"sym\" is read either as a scalar or array within the computed ReadWriteSetType.  isWritten(sym::Union{GenSym, Symbol},  rws::CompilerTools.ReadWriteSet.ReadWriteSetType)   Return true if some symbol in \"sym\" is written either as a scalar or array within the computed ReadWriteSetType.  CompilerTools.ReadWriteSet.AccessSet   Holds which scalars and which array are accessed and for array which index expressions are used.  CompilerTools.ReadWriteSet.ReadWriteSetType   Stores which scalars and arrays are read or written in some code region.", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal_1", 
            "text": "addIndexExpr!(this_dict,  array_name,  index_expr)   Takes a dictionary of symbol to an array of index expression.  from_assignment(ast::Array{Any, 1},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)   Process an assignment AST node.  from_call(ast::Array{Any, 1},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)   Process :call Expr nodes to find arrayref and arrayset calls and adding the corresponding index expressions to the read and write sets respectively.  from_coloncolon(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)   Process a :(::) AST node.  from_expr(ast::ANY)   Walk through one AST node.  from_expr(ast::ANY,  callback::Union{Function, Void},  cbdata::ANY)   Walk through one AST node.  from_expr(ast::LambdaStaticData,  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)   The main routine that switches on all the various AST node types.  from_lambda(ast::Expr,  depth,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)   Walk through a lambda expression.  from_tuple(ast::Array{T, N},  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType,  callback::Union{Function, Void},  cbdata::ANY)   Walk through a tuple.  toSymGen(x::Union{GenSym, Symbol})   In various places we need a SymGen type which is the union of Symbol and GenSym.  tryCallback(ast::ANY,  callback::Union{Function, Void},  cbdata::ANY,  depth::Integer,  rws::CompilerTools.ReadWriteSet.ReadWriteSetType)   If an AST node is not recognized then we try the passing the node to the callback to see if   uncompressed_ast(l::LambdaStaticData)   Convert a compressed LambdaStaticData format into the uncompressed AST format.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-compilertoolsastwalker", 
            "text": "", 
            "title": "MODULE: CompilerTools.AstWalker"
        }, 
        {
            "location": "/api-index/#exported_3", 
            "text": "AstWalk(ast::ANY,  callback,  cbdata::ANY)   Entry point into the code to perform an AST walk.", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal_2", 
            "text": "from_assignment(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)   AstWalk through an assignment expression.  from_body(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)   AstWalk through a function body.  from_call(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)   AstWalk through a call expression.  from_expr(ast::ANY,  depth,  callback,  cbdata::ANY,  top_level_number,  is_top_level,  read)   The main routine that switches on all the various AST node types.  from_exprs(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)   AstWalk through an array of expressions.  from_lambda(ast::Array{Any, 1},  depth,  callback,  cbdata::ANY,  top_level_number,  read)   AstWalk through a lambda expression.  uncompressed_ast(l::LambdaStaticData)   Convert a compressed LambdaStaticData format into the uncompressed AST format.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-compilertoolscfgs", 
            "text": "", 
            "title": "MODULE: CompilerTools.CFGs"
        }, 
        {
            "location": "/api-index/#exported_4", 
            "text": "find_bb_for_statement(top_number::Int64,  bl::CompilerTools.CFGs.CFG)   Find the basic block that contains a given statement number.  from_exprs(ast::Array{Any, 1},  depth,  state,  callback,  cbdata)   Process an array of expressions.  show(io::IO,  bb::CompilerTools.CFGs.BasicBlock)   Overload of Base.show to pretty-print a CFGS.BasicBlock object.  show(io::IO,  bl::CompilerTools.CFGs.CFG)   Overload of Base.show to pretty-print a CFG object.  show(io::IO,  tls::CompilerTools.CFGs.TopLevelStatement)   Overload of Base.show to pretty-print a TopLevelStatement.", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal_3", 
            "text": "TypedExpr(typ,  rest...)   Creates a typed Expr AST node.  addStatement(top_level,  state,  ast::ANY)   Adds a top-level statement just encountered during a partial walk of the AST.  addStatementToEndOfBlock(bl::CompilerTools.CFGs.CFG,  block,  stmt)   Given a CFG \"bl\" and a basic \"block\", add statement \"stmt\" to the end of that block.  changeEndingLabel(bb,  after::CompilerTools.CFGs.BasicBlock,  new_bb::CompilerTools.CFGs.BasicBlock)   BasicBlock bb currently is known to contain a jump to the BasicBlock after.  compute_dfn(basic_blocks)   Computes the depth first numbering of the basic block graph.  compute_dfn_internal(basic_blocks,  cur_bb,  cur_dfn,  visited,  bbs_df_order)   The recursive heart of depth first numbering.  compute_dominators(bl::CompilerTools.CFGs.CFG)   Compute the dominators of the CFG.  compute_inverse_dominators(bl::CompilerTools.CFGs.CFG)   Compute the inverse dominators of the CFG.  connect(from,  to,  fallthrough)   Connect the \"from\" input argument basic block to the \"to\" input argument basic block.  connect_finish(state)   Connect the current basic block as a fallthrough to the final invisible basic block (-2).  createFunctionBody(bl::CompilerTools.CFGs.CFG)   Create the array of statements that go in a :body Expr given a CFG \"bl\".  dump_bb(bl::CompilerTools.CFGs.CFG)   Prints a CFG \"bl\" with varying degrees of verbosity from debug level 2 up to 4.  findReachable(reachable,  cur::Int64,  bbs::Dict{Int64, CompilerTools.CFGs.BasicBlock})   Process a basic block and add its successors to the set of reachable blocks  find_top_number(top_number::Int64,  bl::CompilerTools.CFGs.CFG)   Search for a statement with the given number in the CFG \"bl\".  from_ast(ast)   The main entry point to construct a control-flow graph.  from_expr(ast,  callback,  cbdata)   Another entry point to construct a control-flow graph but one that allows you to pass a callback and some opaque object  from_expr(ast::LambdaStaticData,  depth,  state,  top_level,  callback,  cbdata)   The main routine that switches on all the various AST node types.  from_goto(label,  state,  callback,  cbdata)   Process a GotoNode for CFG construction.  from_if(args,  depth,  state,  callback,  cbdata)   Process a :gotoifnot Expr not for CFG construction.  from_label(label,  state,  callback,  cbdata)   Process LabelNode for CFG construction.  from_lambda(ast::Array{Any, 1},  depth,  state,  callback,  cbdata)   To help construct the CFG given a lambda, we recursively process the body of the lambda.  from_return(args,  depth,  state,  callback,  cbdata)   Process a :return Expr for CFG construction.  getBbBodyOrder(bl::CompilerTools.CFGs.CFG)   Determine a valid and reasonable order of basic blocks in which to reconstruct a :body Expr.  getDistinctStatementNum(bl::CompilerTools.CFGs.CFG)   Get a possible new statement number by finding the maximum statement value in any BasicBlock in the given CFG and adding 1.  getMaxBB(bl::CompilerTools.CFGs.CFG)   Returns the maximum basic block label for the given CFG.  getMaxStatementNum(bb::CompilerTools.CFGs.BasicBlock)   Get the maximum statement index for a given BasicBlock.  getMinBB(bl::CompilerTools.CFGs.CFG)   Returns the minimum basic block label for the given CFG.  insertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64)   Given a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,  insertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64,  excludeBackEdge::Bool)   Given a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,  insertBefore(bl::CompilerTools.CFGs.CFG,  after::Int64,  excludeBackEdge::Bool,  back_edge)   Given a CFG in input parameter \"bl\" and a basic block label \"after\" in that CFG,  insertBetween(bl::CompilerTools.CFGs.CFG,  before::Int64,  after::Int64)   Insert a new basic block into the CFG \"bl\" between the basic blocks whose labels are \"before\" and \"after\".  insertStatementAfter(bl::CompilerTools.CFGs.CFG,  block,  stmt_idx,  new_stmt)   For a given CFG \"bl\" and a \"block\" in that CFG, add a new statement \"new_stmt\" to the basic block  insertStatementBefore(bl::CompilerTools.CFGs.CFG,  block,  stmt_idx,  new_stmt)   For a given CFG \"bl\" and a \"block\" in that CFG, add a new statement \"new_stmt\" to the basic block  insertat!(a,  value,  idx)   Insert into an array \"a\" with a given \"value\" at the specified index \"idx\".  not_handled(a,  b)   A default callback that handles no extra AST node types.  removeUselessBlocks(bbs::Dict{Int64, CompilerTools.CFGs.BasicBlock})   This function simplifies the dict of basic blocks \"bbs\".  replaceSucc(cur_bb::CompilerTools.CFGs.BasicBlock,  orig_succ::CompilerTools.CFGs.BasicBlock,  new_succ::CompilerTools.CFGs.BasicBlock)   For a given basic block \"cur_bb\", replace one of its successors \"orig_succ\" with a different successor \"new_succ\".  uncompressed_ast(l::LambdaStaticData)   Convert a compressed LambdaStaticData format into the uncompressed AST format.  update_label(x::Expr,  state::CompilerTools.CFGs.UpdateLabelState,  top_level_number,  is_top_level,  read)   An AstWalk callback that pattern matches GotoNode's and :gotoifnot Expr nodes and determines if the  wrapInConditional(bl::CompilerTools.CFGs.CFG,  cond_gotoifnot::Expr,  first::Int64,  merge::Int64)   Modifies the CFG to create a conditional (i.e., if statement) that wraps a certain region of the CFG whose entry block is  wrapInConditional(bl::CompilerTools.CFGs.CFG,  cond_gotoifnot::Expr,  first::Int64,  merge::Int64,  back_edge::Union{CompilerTools.CFGs.BasicBlock, Void})   Modifies the CFG to create a conditional (i.e., if statement) that wraps a certain region of the CFG whose entry block is  CompilerTools.CFGs.BasicBlock   Data structure to hold information about one basic block in the control-flow graph.  CompilerTools.CFGs.CFG   The main data structure to hold information about the control flow graph.  CompilerTools.CFGs.TopLevelStatement   Data structure to hold the index (relative to the beginning of the body of the function) of a top-level statement  CompilerTools.CFGs.UpdateLabelState   The opaque callback data type for the update_label callback.  CompilerTools.CFGs.expr_state   Collects information about the CFG as it is being constructed.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-compilertoolslambdahandling", 
            "text": "", 
            "title": "MODULE: CompilerTools.LambdaHandling"
        }, 
        {
            "location": "/api-index/#exported_5", 
            "text": "addEscapingVariable(s::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)   Adds a new escaping variable with the given Symbol \"s\", type \"typ\", descriptor \"desc\" in LambdaInfo \"li\".  addEscapingVariable(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo)   Adds a new escaping variable from a VarDef in parameter \"vd\" into LambdaInfo \"li\".  addGenSym(typ,  li::CompilerTools.LambdaHandling.LambdaInfo)   Add a new GenSym to the LambdaInfo in \"li\" with the given type in \"typ\".  addLocalVariable(s::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)   Adds a new local variable with the given Symbol \"s\", type \"typ\", descriptor \"desc\" in LambdaInfo \"li\".  addLocalVariable(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo)   Adds a local variable from a VarDef to the given LambdaInfo.  getBody(lambda::Expr)   Returns the body expression part of a lambda expression.  getDesc(x::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)   Returns the descriptor for a local variable or input parameter \"x\" from LambdaInfo in \"li\".  getRefParams(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo)   Returns an array of Symbols corresponding to those parameters to the method that are going to be passed by reference.  getReturnType(li::CompilerTools.LambdaHandling.LambdaInfo)   Returns the type of the lambda as stored in LambdaInfo \"li\" and as extracted during lambdaExprToLambdaInfo.  getType(x::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)   Returns the type of a Symbol or GenSym in \"x\" from LambdaInfo in \"li\".  getVarDef(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)   Returns the VarDef for a Symbol in LambdaInfo in \"li\"  isEscapingVariable(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)   Returns true if the Symbol in \"s\" is an escaping variable in LambdaInfo in \"li\".  isInputParameter(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)   Returns true if the Symbol in \"s\" is an input parameter in LambdaInfo in \"li\".  isLocalGenSym(s::GenSym,  li::CompilerTools.LambdaHandling.LambdaInfo)   Returns true if the GenSym in \"s\" is a GenSym in LambdaInfo in \"li\".  isLocalVariable(s::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)   Returns true if the Symbol in \"s\" is a local variable in LambdaInfo in \"li\".  lambdaExprToLambdaInfo(lambda::Expr)   Convert a lambda expression into our internal storage format, LambdaInfo.  lambdaInfoToLambdaExpr(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo,  body)   Convert our internal storage format, LambdaInfo, back into a lambda expression.  lambdaTypeinf(lambda::LambdaStaticData,  typs::Tuple)   Force type inference on a LambdaStaticData object.  replaceExprWithDict!(expr::ANY,  dict::Dict{Union{GenSym, Symbol}, Any})   Replace the symbols in an expression \"expr\" with those defined in the  replaceExprWithDict!(expr::ANY,  dict::Dict{Union{GenSym, Symbol}, Any},  AstWalkFunc)   Replace the symbols in an expression \"expr\" with those defined in the  replaceExprWithDict(expr,  dict::Dict{Union{GenSym, Symbol}, Any})   Replace the symbols in an expression \"expr\" with those defined in the  updateAssignedDesc(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo,  symbol_assigns::Dict{Symbol, Int64})   Update the descriptor part of the VarDef dealing with whether the variable is assigned or not in the function.  CompilerTools.LambdaHandling.LambdaInfo   An internal format for storing a lambda expression's args[1] and args[2].  CompilerTools.LambdaHandling.VarDef   Represents the triple stored in a lambda's args[2][1].  SymGen   Type aliases for different unions of Symbol, SymbolNode, and GenSym.", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal_4", 
            "text": "addDescFlag(s::Symbol,  desc_flag::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)   Add one or more bitfields in \"desc_flag\" to the descriptor for a variable.  addInputParameter(vd::CompilerTools.LambdaHandling.VarDef,  li::CompilerTools.LambdaHandling.LambdaInfo)   Add Symbol \"s\" as input parameter to LambdaInfo \"li\".  addInputParameters(collection,  li::CompilerTools.LambdaHandling.LambdaInfo)   Add all variable in \"collection\" as input parameters to LambdaInfo \"li\".  addLocalVar(name::AbstractString,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)   Add a local variable to the function corresponding to LambdaInfo in \"li\" with name (as String), type and descriptor.  addLocalVar(name::Symbol,  typ,  desc::Int64,  li::CompilerTools.LambdaHandling.LambdaInfo)   Add a local variable to the function corresponding to LambdaInfo in \"li\" with name (as Symbol), type and descriptor.  addLocalVariables(collection,  li::CompilerTools.LambdaHandling.LambdaInfo)   Add multiple local variables from some collection type.  count_symbols(x::Symbol,  state::CompilerTools.LambdaHandling.CountSymbolState,  top_level_number,  is_top_level,  read)   Adds symbols and gensyms to their corresponding sets in CountSymbolState when they are seen in the AST.  createMeta(lambdaInfo::CompilerTools.LambdaHandling.LambdaInfo)   Create the args[2] part of a lambda expression given an object of our internal storage format LambdaInfo.  createVarDict(x::Array{Any, 1})   Convert the lambda expression's args[2][1] from Array{Array{Any,1},1} to a Dict{Symbol,VarDef}.  dictToArray(x::Dict{Symbol, CompilerTools.LambdaHandling.VarDef})   Convert the Dict{Symbol,VarDef} internal storage format from a dictionary back into an array of Any triples.  eliminateUnusedLocals!(li::CompilerTools.LambdaHandling.LambdaInfo,  body::Expr)   Eliminates unused symbols from the LambdaInfo var_defs.  eliminateUnusedLocals!(li::CompilerTools.LambdaHandling.LambdaInfo,  body::Expr,  AstWalkFunc)   Eliminates unused symbols from the LambdaInfo var_defs.  getLocalVariables(li::CompilerTools.LambdaHandling.LambdaInfo)   Returns an array of Symbols for local variables.  mergeLambdaInfo(outer::CompilerTools.LambdaHandling.LambdaInfo,  inner::CompilerTools.LambdaHandling.LambdaInfo)   Merge \"inner\" lambdaInfo into \"outer\", and \"outer\" is changed as result.  Note  removeLocalVar(name::Symbol,  li::CompilerTools.LambdaHandling.LambdaInfo)   Remove a local variable from lambda \"li\" given the variable's \"name\".  show(io::IO,  li::CompilerTools.LambdaHandling.LambdaInfo)   Pretty print a LambdaInfo.  CompilerTools.LambdaHandling.CountSymbolState   Holds symbols and gensyms that are seen in a given AST when using the specified callback to handle non-standard Julia AST types.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-compilertoolslivenessanalysis", 
            "text": "", 
            "title": "MODULE: CompilerTools.LivenessAnalysis"
        }, 
        {
            "location": "/api-index/#exported_6", 
            "text": "find_bb_for_statement(top_number::Int64,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)   Search for a basic block containing a statement with the given top-level number in the liveness information.  show(io::IO,  bb::CompilerTools.LivenessAnalysis.BasicBlock)   Overload of Base.show to pretty-print a LivenessAnalysis.BasicBlock.  show(io::IO,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)   Overload of Base.show to pretty-print BlockLiveness type.  show(io::IO,  tls::CompilerTools.LivenessAnalysis.TopLevelStatement)   Overload of Base.show to pretty-print a LivenessAnalysis.TopLevelStatement.  CompilerTools.LivenessAnalysis.BlockLiveness   The main return type from LivenessAnalysis.", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal_5", 
            "text": "TypedExpr(typ,  rest...)   Convenience function to create an Expr and make sure the type is filled in as well.  addUnmodifiedParams(func,  signature::Array{DataType, 1},  unmodifieds,  state::CompilerTools.LivenessAnalysis.expr_state)   Add an entry the dictionary of which arguments can be modified by which functions.  add_access(bb,  sym,  read)   Called when AST traversal finds some Symbol \"sym\" in a basic block \"bb\".  compute_live_ranges(state::CompilerTools.LivenessAnalysis.expr_state,  dfn)   Compute the live_in and live_out information for each basic block and statement.  countSymbolDefs(s,  lives)   Count the number of times that the symbol in \"s\" is defined in all the basic blocks.  create_unmodified_args_dict()   Convert the function_descriptions table into a dictionary that can be passed to  def(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)   Get the def information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.  dump_bb(bl::CompilerTools.LivenessAnalysis.BlockLiveness)   Dump a bunch of debugging information about BlockLiveness.  find_top_number(top_number::Int64,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)   Search for a statement with the given top-level number in the liveness information.  fromCFG(live_res,  cfg::CompilerTools.CFGs.CFG,  callback::Function,  cbdata::ANY)   Extract liveness information from the CFG.  from_assignment(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)   Walk through an assignment expression.  from_call(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)   Walk through a call expression.  from_expr(ast::Expr)   This function gives you the option of calling the ENTRY point from_expr with an ast and several optional named arguments.  from_expr(ast::Expr,  callback)   ENTRY point to liveness analysis.  from_expr(ast::Expr,  callback,  cbdata::ANY)   ENTRY point to liveness analysis.  from_expr(ast::Expr,  callback,  cbdata::ANY,  no_mod)   ENTRY point to liveness analysis.  from_expr(ast::LambdaStaticData,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)   Generic routine for how to walk most AST node types.  from_exprs(ast::Array{Any, 1},  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)   Walk through an array of expressions.  from_if(args,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)   Process a gotoifnot which is just a recursive processing of its first arg which is the conditional.  from_lambda(ast::Expr,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)   Walk through a lambda expression.  from_return(args,  depth::Int64,  state::CompilerTools.LivenessAnalysis.expr_state,  callback::Function,  cbdata::ANY)   Process a return Expr node which is just a recursive processing of all of its args.  getUnmodifiedArgs(func::ANY,  args,  arg_type_tuple::Array{DataType, 1},  state::CompilerTools.LivenessAnalysis.expr_state)   For a given function and signature, return which parameters can be modified by the function.  get_function_from_string(mod::AbstractString,  func::AbstractString)   Takes a module and a function both as Strings. Looks up the specified module as  get_info_internal(x::Union{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.LivenessAnalysis.TopLevelStatement},  bl::CompilerTools.LivenessAnalysis.BlockLiveness,  field)   The live_in, live_out, def, and use routines are all effectively the same but just extract a different field name.  isDef(x::Union{GenSym, Symbol},  live_info)   Query if the symbol in argument \"x\" is defined in live_info which can be a BasicBlock or TopLevelStatement.  isPassedByRef(x,  state::CompilerTools.LivenessAnalysis.expr_state)   Returns true if a parameter is passed by reference.  live_in(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)   Get the live_in information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.  live_out(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)   Get the live_out information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.  not_handled(a,  b)   The default callback that processes no non-standard Julia AST nodes.  recompute_live_ranges(state,  dfn)   Clear the live_in and live_out data corresponding to all basic blocks and statements and then recompute liveness information.  typeOfOpr(x::ANY,  li::CompilerTools.LambdaHandling.LambdaInfo)   Get the type of some AST node.  uncompressed_ast(l::LambdaStaticData)   Convert a compressed LambdaStaticData format into the uncompressed AST format.  use(x,  bl::CompilerTools.LivenessAnalysis.BlockLiveness)   Get the use information for \"x\" where x can be a liveness or CFG basic block or a liveness or CFG statement.  CompilerTools.LivenessAnalysis.AccessSummary   Sometimes if new AST nodes are introduced then we need to ask for their def and use set as a whole  CompilerTools.LivenessAnalysis.BasicBlock   Liveness information for a BasicBlock.  CompilerTools.LivenessAnalysis.TopLevelStatement   Liveness information for a TopLevelStatement in the CFG.  CompilerTools.LivenessAnalysis.expr_state   Holds the state during the AST traversal.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-parallelacceleratorcomprehension", 
            "text": "", 
            "title": "MODULE: ParallelAccelerator.Comprehension"
        }, 
        {
            "location": "/api-index/#exported_7", 
            "text": "@comprehend(ast)   Translate all comprehension in an AST into equivalent code that uses cartesianarray call.", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal_6", 
            "text": "comprehension_to_cartesianarray(ast)   Translate an ast whose head is :comprehension into equivalent code that uses cartesianarray call.  process_node(node,  state,  top_level_number,  is_top_level,  read)   This function is a AstWalker callback.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-parallelacceleratordistributedir", 
            "text": "", 
            "title": "MODULE: ParallelAccelerator.DistributedIR"
        }, 
        {
            "location": "/api-index/#internal_7", 
            "text": "checkParforsForDistribution(state::ParallelAccelerator.DistributedIR.DistIrState)   All arrays of a parfor should distributable for it to be distributable.  get_arr_dist_info(node::Expr,  state,  top_level_number,  is_top_level,  read)   mark sequential arrays", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-parallelacceleratorapicapture", 
            "text": "", 
            "title": "MODULE: ParallelAccelerator.API.Capture"
        }, 
        {
            "location": "/api-index/#internal_8", 
            "text": "process_node(node::Expr,  state,  top_level_number,  is_top_level,  read)   At macro level, we translate function calls and operators that matches operator names", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-parallelacceleratordomainir", 
            "text": "", 
            "title": "MODULE: ParallelAccelerator.DomainIR"
        }, 
        {
            "location": "/api-index/#internal_9", 
            "text": "lookupConstDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})   Look up a definition of a variable only when it is const or assigned once.  lookupConstDefForArg(state::ParallelAccelerator.DomainIR.IRState,  s)   Look up a definition of a variable recursively until the RHS is no-longer just a variable.  lookupDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})   Look up a definition of a variable.  lookupDefInAllScopes(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode})   Look up a definition of a variable throughout nested states until a definition is found.  updateDef(state::ParallelAccelerator.DomainIR.IRState,  s::Union{GenSym, Symbol, SymbolNode},  rhs)   Update the definition of a variable.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-compilertoolsdebugmsg", 
            "text": "", 
            "title": "MODULE: CompilerTools.DebugMsg"
        }, 
        {
            "location": "/api-index/#exported_8", 
            "text": "init()   A module using DebugMsg must call DebugMsg.init(), which expands to several local definitions", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal_10", 
            "text": "PROSPECT_DEV_MODE   When this module is first loaded, we check if PROSPECT_DEV_MODE is set in environment.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-parallelacceleratorparallelir", 
            "text": "", 
            "title": "MODULE: ParallelAccelerator.ParallelIR"
        }, 
        {
            "location": "/api-index/#exported_9", 
            "text": "AstWalk(ast,  callback,  cbdata)   ParallelIR version of AstWalk.  PIRInplace(x)   If set to non-zero, perform the phase where non-inplace maps are converted to inplace maps to reduce allocations.  PIRNumSimplify(x)   Specify the number of passes over the AST that do things like hoisting and other rearranging to maximize fusion.  PIRRunAsTasks(x)   Debugging feature to specify the number of tasks to create and to stop thereafter.  PIRSetFuseLimit(x)   Control how many parfor can be fused for testing purposes.  PIRShortcutArrayAssignment(x)   Enables an experimental mode where if there is a statement a = b and they are arrays and b is not live-out then   PIRTaskGraphMode(x)   Control how blocks of code are made into tasks.  from_exprs(ast::Array{Any, 1},  depth,  state)   Process an array of expressions.  ParallelAccelerator.ParallelIR.PIRLoopNest   Holds the information about a loop in a parfor node.  ParallelAccelerator.ParallelIR.PIRParForAst   The parfor AST node type.  ParallelAccelerator.ParallelIR.PIRReduction   Holds the information about a reduction in a parfor node.", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal_11", 
            "text": "AstWalkCallback(x::Expr,  dw::ParallelAccelerator.ParallelIR.DirWalk,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)   AstWalk callback that handles ParallelIR AST node types.  EquivalenceClassesAdd(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  sym::Symbol)   Add a symbol as part of a new equivalence class if the symbol wasn't already in an equivalence class.  EquivalenceClassesClear(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses)   Clear an equivalence class.  EquivalenceClassesMerge(ec::ParallelAccelerator.ParallelIR.EquivalenceClasses,  merge_to::Symbol,  merge_from::Symbol)   At some point we realize that two arrays must have the same dimensions but up until that point  PIRBbReorder(x)   If set to non-zero, perform the bubble-sort like reordering phase to coalesce more parfor nodes together for fusion.  PIRHoistAllocation(x)   If set to non-zero, perform the rearrangement phase that tries to moves alllocations outside of loops.  TypedExpr(typ,  rest...)   This should pretty always be used instead of Expr(...) to form an expression as it forces the typ to be provided.  addUnknownArray(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)   Given an array whose name is in \"x\", allocate a new equivalence class for this array.  addUnknownRange(x::Array{Any, 1},  state::ParallelAccelerator.ParallelIR.expr_state)   Given an array of RangeExprs describing loop nest ranges, allocate a new equivalence class for this range.  add_merge_correlations(old_sym::Union{GenSym, Symbol},  new_sym::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)   If we somehow determine that two arrays must be the same length then   asArray(x)   Return one element array with element x.  augment_sn(dim::Int64,  index_vars,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})   Make sure the index parameters to arrayref or arrayset are Int64 or SymbolNode.  call_instruction_count(args,  state::ParallelAccelerator.ParallelIR.eic_state,  debug_level)   Generate an instruction count estimate for a call instruction.  checkAndAddSymbolCorrelation(lhs::Union{GenSym, Symbol},  state,  dim_array)   Make sure all the dimensions are SymbolNodes.  convertUnsafe(stmt)   Remove unsafe array access Symbols from the incoming \"stmt\".  convertUnsafeOrElse(stmt)   Try to remove unsafe array access Symbols from the incoming \"stmt\".  If successful, then return the updated  convertUnsafeWalk(x::Expr,  state,  top_level_number,  is_top_level,  read)   The AstWalk callback to find unsafe arrayset and arrayref variants and  copy_propagate(node::ANY,  data::ParallelAccelerator.ParallelIR.CopyPropagateState,  top_level_number,  is_top_level,  read)   In each basic block, if there is a \"copy\" (i.e., something of the form \"a = b\") then put  count_assignments(x,  symbol_assigns::Dict{Symbol, Int64},  top_level_number,  is_top_level,  read)   AstWalk callback to count the number of static times that a symbol is assigne within a method.  create1D_array_access_desc(array::SymbolNode)   Create an array access descriptor for \"array\".  create2D_array_access_desc(array::SymbolNode)   Create an array access descriptor for \"array\".  createInstructionCountEstimate(the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state::ParallelAccelerator.ParallelIR.expr_state)   Takes a parfor and walks the body of the parfor and estimates the number of instruction needed for one instance of that body.  createLoweredAliasMap(dict1)   Take a single-step alias map, e.g., a= b, b= c, and create a lowered dictionary, a= c, b= c, that  createMapLhsToParfor(parfor_assignment,  the_parfor,  is_multi::Bool,  sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  state::ParallelAccelerator.ParallelIR.expr_state)   Creates a mapping between variables on the left-hand side of an assignment where the right-hand side is a parfor  createStateVar(state,  name,  typ,  access)   Add a local variable to the current function's lambdaInfo.  createTempForArray(array_sn::Union{GenSym, Symbol, SymbolNode},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)   Create a temporary variable that is parfor private to hold the value of an element of an array.  createTempForRangeOffset(num_used,  ranges::Array{ParallelAccelerator.ParallelIR.RangeData, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)   Create a variable to hold the offset of a range offset from the start of the array.  createTempForRangedArray(array_sn::Union{GenSym, Symbol, SymbolNode},  range::Array{Union{GenSym, SymbolNode}, 1},  unique_id::Int64,  state::ParallelAccelerator.ParallelIR.expr_state)   Create a temporary variable that is parfor private to hold the value of an element of an array.  create_array_access_desc(array::SymbolNode)   Create an array access descriptor for \"array\".  create_equivalence_classes(node::Expr,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)   AstWalk callback to determine the array equivalence classes.  dfsVisit(swd::ParallelAccelerator.ParallelIR.StatementWithDeps,  vtime::Int64,  topo_sort::Array{ParallelAccelerator.ParallelIR.StatementWithDeps, N})   Construct a topological sort of the dependence graph.  estimateInstrCount(ast::Expr,  state::ParallelAccelerator.ParallelIR.eic_state,  top_level_number,  is_top_level,  read)   AstWalk callback for estimating the instruction count.  extractArrayEquivalencies(node::Expr,  state)   \"node\" is a domainIR node.  Take the arrays used in this node, create an array equivalence for them if they   findSelectedDimensions(inputInfo::Array{ParallelAccelerator.ParallelIR.InputInfo, 1},  state)   Given all the InputInfo for a Domain IR operation being lowered to Parallel IR,  flattenParfor(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst)   Takes a new array of body statements in the process of construction in \"new_body\" and takes a parfor to add to that  from_assertEqShape(node::Expr,  state)   Create array equivalences from an assertEqShape AST node.  from_assignment(lhs,  rhs,  depth,  state)   Process an assignment expression.  from_call(ast::Array{Any, 1},  depth,  state)   Process a call AST node.  from_expr(ast::Expr,  depth,  state::ParallelAccelerator.ParallelIR.expr_state,  top_level)   The main ParallelIR function for processing some node in the AST.  from_lambda(lambda::Expr,  depth,  state)   Process a :lambda Expr.  from_root(function_name,  ast::Expr)   The main ENTRY point into ParallelIR.  fullyLowerAlias(dict::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  input::Union{GenSym, Symbol})   Given an \"input\" Symbol, use that Symbol as key to a dictionary.  While such a Symbol is present  fuse(body,  body_index,  cur,  state)   Test whether we can fuse the two most recent parfor statements and if so to perform that fusion.  generate_instr_count(function_name,  signature)   Try to figure out the instruction count for a given call.  getArrayElemType(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state)   Returns the element type of an Array.  getArrayElemType(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state)   Returns the element type of an Array.  getArrayElemType(atyp::DataType)   Returns the element type of an Array.  getArrayNumDims(array::GenSym,  state::ParallelAccelerator.ParallelIR.expr_state)   Return the number of dimensions of an Array.  getArrayNumDims(array::SymbolNode,  state::ParallelAccelerator.ParallelIR.expr_state)   Return the number of dimensions of an Array.  getConstDims(num_dim_inputs,  inputInfo::ParallelAccelerator.ParallelIR.InputInfo)   In the case where a domain IR operation on an array creates a lower dimensional output,  getCorrelation(sng::Union{GenSym, Symbol, SymbolNode},  state::ParallelAccelerator.ParallelIR.expr_state)   Get the equivalence class of a domain IR input in inputInfo.  getFirstArrayLens(prestatements,  num_dims)   Get the variable which holds the length of the first input array to a parfor.  getIO(stmt_ids,  bb_statements)   Given a set of statement IDs and liveness information for the statements of the function, determine  getInputSet(node::ParallelAccelerator.ParallelIR.PIRParForAst)   Returns a Set with all the arrays read by this parfor.  getLhsFromAssignment(assignment)   Get the left-hand side of an assignment expression.  getLhsOutputSet(lhs,  assignment)   Get the real outputs of an assignment statement.  getMaxLabel(max_label,  stmts::Array{Any, 1})   Scan the body of a function in \"stmts\" and return the max label in a LabelNode AST seen in the body.  getNonBlock(head_preds,  back_edge)   Find the basic block before the entry to a loop.  getOrAddArrayCorrelation(x::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state)   Return a correlation set for an array.  If the array was not previously added then add it and return it.  getOrAddRangeCorrelation(ranges::Array{ParallelAccelerator.ParallelIR.RangeExprs, 1},  state::ParallelAccelerator.ParallelIR.expr_state)   Gets (or adds if absent) the range correlation for the given array of RangeExprs.  getOrAddSymbolCorrelation(array::Union{GenSym, Symbol},  state::ParallelAccelerator.ParallelIR.expr_state,  dims::Array{Union{GenSym, Symbol}, 1})   A new array is being created with an explicit size specification in dims.  getParforCorrelation(parfor,  state)   Get the equivalence class of the first array who length is extracted in the pre-statements of the specified \"parfor\".  getParforNode(node)   Get the parfor object from either a bare parfor or one part of an assignment.  getPrivateSet(body::Array{Any, 1})   Go through the body of a parfor and collect those Symbols, GenSyms, etc. that are assigned to within the parfor except reduction variables.  getPrivateSetInner(x::Expr,  state::Set{Union{GenSym, Symbol, SymbolNode}},  top_level_number::Int64,  is_top_level::Bool,  read::Bool)   The AstWalk callback function for getPrivateSet.  getRhsFromAssignment(assignment)   Get the right-hand side of an assignment expression.  getSName(ssn::Symbol)   Get the name of a symbol whether the input is a Symbol or SymbolNode or :(::) Expr.  get_one(ast::Array{T, N})   Take something returned from AstWalk and assert it should be an array but in this  get_unique_num()   If we need to generate a name and make sure it is unique then include an monotonically increasing number.  hasNoSideEffects(node::Union{GenSym, LambdaStaticData, Number, Symbol, SymbolNode})   Sometimes statements we exist in the AST of the form a=Expr where a is a Symbol that isn't live past the assignment  hasSymbol(ssn::Symbol)   Returns true if the incoming AST node can be interpreted as a Symbol.  hoistAllocation(ast::Array{Any, 1},  lives,  domLoop::CompilerTools.Loops.DomLoops,  state::ParallelAccelerator.ParallelIR.expr_state)   Try to hoist allocations outside the loop if possible.  insert_no_deps_beginning(node,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read)   Works with remove_no_deps below to move statements with no dependencies to the beginning of the AST.  intermediate_from_exprs(ast::Array{Any, 1},  depth,  state)   Process an array of expressions that aren't from a :body Expr.  isArrayType(typ)   Returns true if the incoming type in \"typ\" is an array type.  isArrayType(x::SymbolNode)   Returns true if a given SymbolNode \"x\" is an Array type.  isArrayref(x)   Is a node an arrayref node?  isArrayrefCall(x::Expr)   Is a node a call to arrayref.  isArrayset(x)   Is a node an arrayset node?  isArraysetCall(x::Expr)   Is a node a call to arrayset.  isAssignmentNode(node::Expr)   Is a node an assignment expression node.  isBareParfor(node::Expr)   Is this a parfor node not part of an assignment statement.  isDomainNode(ast::Expr)   Returns true if the given \"ast\" node is a DomainIR operation.  isFusionAssignment(x::Expr)   Check if an assignement is a fusion assignment.  isLoopheadNode(node::Expr)   Is a node a loophead expression node (a form of assignment).  isParforAssignmentNode(node::Expr)   Is a node an assignment expression with a parfor node as the right-hand side.  isSymbolsUsed(vars,  top_level_numbers::Array{Int64, 1},  state)   Returns true if any variable in the collection \"vars\" is used in any statement whose top level number is in \"top_level_numbers\".  is_eliminated_arraylen(x::Expr)   Returns true if the input node is an assignment node where the right-hand side is a call to arraysize.  isbitstuple(a::Tuple)   Returns true if input \"a\" is a tuple and each element of the tuple of isbits type.  iterations_equals_inputs(node::ParallelAccelerator.ParallelIR.PIRParForAst)   Returns true if the domain operation mapped to this parfor has the property that the iteration space  lambdaFromDomainLambda(domain_lambda,  dl_inputs)   Form a Julia :lambda Expr from a DomainLambda.  makePrivateParfor(var_name::Symbol,  state)   Takes an existing variable whose name is in \"var_name\" and adds the descriptor flag ISPRIVATEPARFORLOOP to declare the  makeTasks(start_index,  stop_index,  body,  bb_live_info,  state,  task_graph_mode)   For a given start and stop index in some body and liveness information, form a set of tasks.  maxFusion(bl::CompilerTools.LivenessAnalysis.BlockLiveness)   For every basic block, try to push domain IR statements down and non-domain IR statements up so that domain nodes  mergeLambdaIntoOuterState(state,  inner_lambda::Expr)   Pull the information from the inner lambda into the outer lambda.  merge_correlations(state,  unchanging,  eliminate)   If we somehow determine that two sets of correlations are actually the same length then merge one into the other.  mk_alloc_array_1d_expr(elem_type,  atype,  length)   Return an expression that allocates and initializes a 1D Julia array that has an element type specified by  mk_alloc_array_2d_expr(elem_type,  atype,  length1,  length2)   Return an expression that allocates and initializes a 2D Julia array that has an element type specified by  mk_alloc_array_3d_expr(elem_type,  atype,  length1,  length2,  length3)   Return an expression that allocates and initializes a 3D Julia array that has an element type specified by  mk_arraylen_expr(x::ParallelAccelerator.ParallelIR.InputInfo,  dim::Int64)   Create an expression whose value is the length of the input array.  mk_arraylen_expr(x::Union{GenSym, Symbol, SymbolNode},  dim::Int64)   Create an expression whose value is the length of the input array.  mk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state)   Return an expression that corresponds to getting the index_var index from the array array_name.  mk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1})   Return an expression that corresponds to getting the index_var index from the array array_name.  mk_arrayref1(num_dim_inputs,  array_name,  index_vars,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})   Return an expression that corresponds to getting the index_var index from the array array_name.  mk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state)   Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".  mk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1})   Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".  mk_arrayset1(num_dim_inputs,  array_name,  index_vars,  value,  inbounds,  state::ParallelAccelerator.ParallelIR.expr_state,  range_var::Array{Union{GenSym, SymbolNode}, 1},  range::Array{ParallelAccelerator.ParallelIR.RangeData, 1})   Return a new AST node that corresponds to setting the index_var index from the array \"array_name\" with \"value\".  mk_assignment_expr(lhs::Union{GenSym, Symbol, SymbolNode},  rhs,  state::ParallelAccelerator.ParallelIR.expr_state)   Create an assignment expression AST node given a left and right-hand side.  mk_colon_expr(start_expr,  skip_expr,  end_expr)   Returns an expression to construct a :colon object that contains the start of a range, the end and the skip expression.  mk_convert(new_type,  ex)   Returns an expression that convert \"ex\" into a another type \"new_type\".  mk_gotoifnot_expr(cond,  goto_label)   Returns a :gotoifnot Expr given a condition \"cond\" and a label \"goto_label\".  mk_next_expr(colon_sym,  start_sym)   Returns a :next call Expr that gets the next element of an iteration range from a :colon object.  mk_parallelir_ref(sym)   Create an expression that references something inside ParallelIR.  mk_parallelir_ref(sym,  ref_type)   Create an expression that references something inside ParallelIR.  mk_parfor_args_from_mmap!(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  with_indices,  domain_oprs,  state)   The main routine that converts a mmap! AST node to a parfor AST node.  mk_parfor_args_from_mmap(input_arrays::Array{T, N},  dl::ParallelAccelerator.DomainIR.DomainLambda,  domain_oprs,  state)   The main routine that converts a mmap AST node to a parfor AST node.  mk_parfor_args_from_reduce(input_args::Array{Any, 1},  state)   The main routine that converts a reduce AST node to a parfor AST node.  mk_return_expr(outs)   Given an array of outputs in \"outs\", form a return expression.  mk_start_expr(colon_sym)   Returns an expression to get the start of an iteration range from a :colon object.  mk_svec_expr(parts...)   Make a svec expression.  mk_tuple_expr(tuple_fields,  typ)   Return an expression which creates a tuple.  mk_tupleref_expr(tuple_var,  index,  typ)   Create an expression which returns the index'th element of the tuple whose name is contained in tuple_var.  mk_untyped_assignment(lhs,  rhs)   Only used to create fake expression to force lhs to be seen as written rather than read.  mmapInline(ast::Expr,  lives,  uniqSet)   # If a definition of a mmap is only used once and not aliased, it can be inlined into its  mmapToMmap!(ast,  lives,  uniqSet)   Performs the mmap to mmap! phase.  mustRemainLastStatementInBlock(node::GotoNode)   Returns true if the given AST \"node\" must remain the last statement in a basic block.  nameToSymbolNode(name::Symbol,  sym_to_type)   Forms a SymbolNode given a symbol in \"name\" and get the type of that symbol from the incoming dictionary \"sym_to_type\".  nested_function_exprs(max_label,  domain_lambda,  dl_inputs)   A routine similar to the main parallel IR entry put but designed to process the lambda part of  next_label(state::ParallelAccelerator.ParallelIR.expr_state)   Returns the next usable label for the current function.  oneIfOnly(x)   Returns a single element of an array if there is only one or the array otherwise.  parforToTask(parfor_index,  bb_statements,  body,  state)   Given a parfor statement index in \"parfor_index\" in the \"body\"'s statements, create a TaskInfo node for this parfor.  pirPrintDl(dbg_level,  dl)   Debug print the parts of a DomainLambda.  pir_alias_cb(ast::Expr,  state,  cbdata)   An AliasAnalysis callback (similar to LivenessAnalysis callback) that handles ParallelIR introduced AST node types.  pir_live_cb(ast::Expr,  cbdata::ANY)   A LivenessAnalysis callback that handles ParallelIR introduced AST node types.  pir_live_cb_def(x)   Just call the AST walker for symbol for parallel IR nodes with no state.  printBody(dlvl,  body::Array{Any, 1})   Pretty print the args part of the \"body\" of a :lambda Expr at a given debug level in \"dlvl\".  printLambda(dlvl,  node::Expr)   Pretty print a :lambda Expr in \"node\" at a given debug level in \"dlvl\".  processAndUpdateBody(lambda::Expr,  f::Function,  state)   Apply a function \"f\" that takes the :body from the :lambda and returns a new :body that is stored back into the :lambda.  rangeSize(start,  skip,  last)   Compute size of a range.  rangeToRangeData(range::Expr,  pre_offsets::Array{Expr, 1},  arr,  range_num::Int64,  state)   Convert a :range Expr introduced by Domain IR into a Parallel IR data structure RangeData.  recreateLoops(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  state,  newLambdaInfo)   In threads mode, we can't have parfor_start and parfor_end in the code since Julia has to compile the code itself and so  recreateLoopsInternal(new_body,  the_parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  loop_nest_level,  next_available_label,  state,  newLambdaInfo)   This is a recursive routine to reconstruct a regular Julia loop nest from the loop nests described in PIRParForAst.  rememberTypeForSym(sym_to_type::Dict{Union{GenSym, Symbol}, DataType},  sym::Union{GenSym, Symbol},  typ::DataType)   Add to the map of symbol names to types.  removeAssertEqShape(args::Array{Any, 1},  state)   Implements one of the main ParallelIR passes to remove assertEqShape AST nodes from the body if they are statically known to be in the same equivalence class.  removeNothingStmts(args::Array{Any, 1},  state)   Empty statements can be added to the AST by some passes in ParallelIR.  remove_dead(node,  data::ParallelAccelerator.ParallelIR.RemoveDeadState,  top_level_number,  is_top_level,  read)   An AstWalk callback that uses liveness information in \"data\" to remove dead stores.  remove_extra_allocs(ast)   removes extra allocations  remove_no_deps(node::ANY,  data::ParallelAccelerator.ParallelIR.RemoveNoDepsState,  top_level_number,  is_top_level,  read)   # This routine gathers up nodes that do not use  replaceParforWithDict(parfor::ParallelAccelerator.ParallelIR.PIRParForAst,  gensym_map)   Not currently used but might need it at some point.  run_as_task()   Return true if run_as_task_decrement would return true but don't update the run_as_tasks count.  run_as_task_decrement()   If run_as_tasks is positive then convert this parfor to a task and decrement the count so that only the  selectToRangeData(select::Expr,  pre_offsets::Array{Expr, 1},  state)   Convert the range(s) part of a :select Expr introduced by Domain IR into an array of Parallel IR data structures RangeData.  seqTask(body_indices,  bb_statements,  body,  state)   Form a task out of a range of sequential statements.  show(io::IO,  pnode::ParallelAccelerator.ParallelIR.PIRParForAst)   Overload of Base.show to pretty print for parfor AST nodes.  simpleIndex(dict)   Returns true if all array references use singular index variables and nothing more complicated involving,  sub_arraylen_walk(x::Expr,  replacement,  top_level_number,  is_top_level,  read)   AstWalk callback that does the work of substitute_arraylen on a node-by-node basis.  sub_arrayset_walk(x::Expr,  cbd,  top_level_number,  is_top_level,  read)   AstWalk callback that does the work of substitute_arrayset on a node-by-node basis.  sub_cur_body_walk(x::Expr,  cbd::ParallelAccelerator.ParallelIR.cur_body_data,  top_level_number::Int64,  is_top_level::Bool,  read::Bool)   AstWalk callback that does the work of substitute_cur_body on a node-by-node basis.  substitute_arraylen(x,  replacement)   replacement is an array containing the length of the dimensions of the arrays a part of this parfor.  substitute_arrayset(x,  arrays_set_in_cur_body,  output_items_with_aliases)   Modify the body of a parfor.  substitute_cur_body(x,  temp_map::Dict{Union{GenSym, Symbol}, Union{GenSym, SymbolNode}},  index_map::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  arrays_set_in_cur_body::Set{Union{GenSym, Symbol}},  replace_array_name_in_arrayset::Dict{Union{GenSym, Symbol}, Union{GenSym, Symbol}},  state::ParallelAccelerator.ParallelIR.expr_state)   Make changes to the second parfor body in the process of parfor fusion.  taskableParfor(node)   Returns true if the \"node\" is a parfor and the task limit hasn't been exceeded.  toSNGen(x::Symbol,  typ)   If we have the type, convert a Symbol to SymbolNode.  toSymGen(x::Symbol)   In various places we need a SymGen type which is the union of Symbol and GenSym.  toSymNodeGen(x::Symbol,  typ)   Form a SymbolNode with the given typ if possible or a GenSym if that is what is passed in.  uncompressed_ast(l::LambdaStaticData)   Convert a compressed LambdaStaticData format into the uncompressed AST format.  ParallelAccelerator.ParallelIR.CopyPropagateState   State to aide in the copy propagation phase.  ParallelAccelerator.ParallelIR.DirWalk   Wraps the callback and opaque data passed from the user of ParallelIR's AstWalk.  ParallelAccelerator.ParallelIR.DomainOperation   Holds information about domain operations part of a parfor node.  ParallelAccelerator.ParallelIR.EquivalenceClasses   Holds a dictionary from an array symbol to an integer corresponding to an equivalence class.  ParallelAccelerator.ParallelIR.FusionSentinel   Just used to hold a spot in an array to indicate the this is a special assignment expression with embedded real array output names from a fusion.  ParallelAccelerator.ParallelIR.InProgress   A sentinel in the instruction count estimation process.  ParallelAccelerator.ParallelIR.InputInfo   Type used by mk_parfor_args... functions to hold information about input arrays.  ParallelAccelerator.ParallelIR.InsertTaskNode   A data type containing the information that CGen uses to generate a call to pert_insert_divisible_task.  ParallelAccelerator.ParallelIR.PIRParForStartEnd   After lowering, it is necessary to make the parfor body top-level statements so that basic blocks  ParallelAccelerator.ParallelIR.RangeData   Holds the information from one Domain IR :range Expr.  ParallelAccelerator.ParallelIR.RemoveDeadState   Holds liveness information for the remove_dead AstWalk phase.  ParallelAccelerator.ParallelIR.RemoveNoDepsState   State for the remove_no_deps and insert_no_deps_beginning phases.  ParallelAccelerator.ParallelIR.ReplacedRegion   Store information about a section of a body that will be translated into a task.  ParallelAccelerator.ParallelIR.RhsDead   Marks an assignment statement where the left-hand side can take over the storage from the right-hand side.  ParallelAccelerator.ParallelIR.StatementWithDeps   Type for dependence graph creation and topological sorting.  ParallelAccelerator.ParallelIR.TaskInfo   Structure for storing information about task formation.  ParallelAccelerator.ParallelIR.cur_body_data   Holds the data for substitute_cur_body AST walk.  ParallelAccelerator.ParallelIR.cuw_state   Just to hold the \"found\" Bool that says whether a unsafe variant was replaced with a regular version.  ParallelAccelerator.ParallelIR.expr_state   State passed around while converting an AST from domain to parallel IR.  ParallelAccelerator.ParallelIR.pir_arg_metadata   A Julia representation of the argument metadata that will be passed to the runtime.  ParallelAccelerator.ParallelIR.pir_array_access_desc   Describes an array.  ParallelAccelerator.ParallelIR.pir_grain_size   A Julia representation of the grain size that will be passed to the runtime.  ParallelAccelerator.ParallelIR.pir_range   Translated to pert_range_Nd_t in the task runtime.  ParallelAccelerator.ParallelIR.pir_range_actual   Similar to pir_range but used in circumstances where the expressions must have already been evaluated.  ParallelAccelerator.ParallelIR.sub_arrayset_data   Holds data for modifying arrayset calls.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-compilertoolsoptframework", 
            "text": "", 
            "title": "MODULE: CompilerTools.OptFramework"
        }, 
        {
            "location": "/api-index/#exported_10", 
            "text": "addOptPass(func,  level)   Same as the other addOptPass but with a pass call back function and pass level as input.  addOptPass(pass::CompilerTools.OptFramework.OptPass)   Add an optimization pass. If this is going to be called multiple times then you need some external way of corrdinating the code/modules that are calling this function so that optimization passes are added in some sane order.  @acc(ast1, ast2...)   The @acc macro comes in two forms:  @noacc(ast)   The macro @noacc can be used at call site to specifically run the non-accelerated copy of an accelerated function. It has no effect and gives a warning when the given function is not found to have been accelerated. We do not support nested @acc or @noacc.", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal_12", 
            "text": "TypedExpr(typ,  rest...)   Creates a typed Expr AST node.  cleanupASTLabels(ast)   Clean up the labels in AST by renaming them, and removing duplicates.  convertCodeToLevel(ast::ANY,  sig::ANY,  old_level,  new_level,  func)   convert AST from \"old_level\" to \"new_level\". The input \"ast\" can be either Expr or Function type. In the latter case, the result AST will be obtained from this function using an matching signature \"sig\". The last \"func\" is a skeleton function that is used internally to facility such conversion.  convert_expr(per_site_opt_set,  ast)   When @acc is used at a function's callsite, we use AstWalk to search for callsites via the opt_calls_insert_trampoline callback and to then insert trampolines.  That updated expression containing trampoline calls is then returned as the generated code from the @acc macro.  convert_function(per_site_opt_set,  opt_set,  macros,  ast)   When @acc is used at a function definition, it creates a trampoline function, when called with a specific set of signature types, will try to optimize the original function, and call it with the real arguments.  The input \"ast\" should be an AST of the original function at macro level, which will be   replaced by the trampoline.   create_label_map(x,  state::CompilerTools.OptFramework.lmstate,  top_level_number,  is_top_level,  read)   An AstWalk callback that collects information about labels in an AST.  dumpLevel(level)   pretty print pass level number as string.  evalPerSiteOptSet(per_site_opt_set)   Statically evaluate per-site optimization passes setting, and return the result.  findOriginalFunc(mod::Module,  name::Symbol)   Find the original (before @acc macro) function for a wrapper function in the given module.   findTargetFunc(mod::Module,  name::Symbol)   Find the optimizing target function (after @acc macro) for a wrapper function in the given module.   getCodeAtLevel(func,  sig,  level)   Retrieve the AST of the given function \"func\" and signature \"sig\" for at the given pass \"level\".  identical{T}(t::Type{T},  x::T)   A hack to get around Julia's type inference. This is essentially an identity conversion,  makeWrapperFunc(new_fname::Symbol,  real_fname::Symbol,  call_sig_args::Array{Any, 1},  per_site_opt_set)   Define a wrapper function with the name given by \"new_func\" that when called will try to optimize the \"real_func\" function, and run it with given parameters in \"call_sig_args\". The input \"per_site_opt_set\" can be either nothing, or a quoted Expr that refers to an array of OptPass.  opt_calls_insert_trampoline(x,  per_site_opt_set,  top_level_number,  is_top_level,  read)   An AstWalk callback function.  processFuncCall(func::ANY,  call_sig_arg_tuple::ANY,  per_site_opt_set::ANY)   Takes a function, a signature, and a set of optimizations and applies that set of optimizations to the function,  removeDupLabels(stmts)   Sometimes update_labels creates two label nodes that are the same.  setOptPasses(passes::Array{CompilerTools.OptFramework.OptPass, 1})   Set the default set of optimization passes to apply with the @acc macro.   tfuncPresent(func,  tt)   Makes sure that a newly created function is correctly present in the internal Julia method table.  update_labels(x,  state::CompilerTools.OptFramework.lmstate,  top_level_number,  is_top_level,  read)   An AstWalk callback that applies the label map created during create_label_map AstWalk.  CompilerTools.OptFramework.OptPass   A data structure that holds information about one high-level optimization pass to run.  CompilerTools.OptFramework.lmstate   The callback state variable used by create_label_map and update_labels.  gOptFrameworkDict   A global memo-table that maps both: the triple (function, signature, optPasses) to the trampoline function, and the trampoline function to the real function.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-compilertoolsudchains", 
            "text": "", 
            "title": "MODULE: CompilerTools.UDChains"
        }, 
        {
            "location": "/api-index/#internal_13", 
            "text": "getOrCreate(live::Dict{Symbol, Set{T}},  s::Symbol)   Get the set of definition blocks reaching this block for a given symbol \"s\".  getOrCreate(udchains::Dict{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.UDChains.UDInfo},  bb::CompilerTools.LivenessAnalysis.BasicBlock)   Get the UDInfo for a specified basic block \"bb\" or create one if it doesn't already exist.  getUDChains(bl::CompilerTools.LivenessAnalysis.BlockLiveness)   Get the Use-Definition chains at a basic block level given LivenessAnalysis.BlockLiveness as input in \"bl\".  printLabels(level,  dict)   Print a live in or live out dictionary in a nice way if the debug level is set high enough.  printSet(level,  s)   Print the set part of a live in or live out dictiononary in a nice way if the debug level is set high enough.  printUDInfo(level,  ud)   Print UDChains in a nice way if the debug level is set high enough.  CompilerTools.UDChains.UDInfo   Contains the UDchains for one basic block.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-compilertoolsloops", 
            "text": "", 
            "title": "MODULE: CompilerTools.Loops"
        }, 
        {
            "location": "/api-index/#exported_11", 
            "text": "CompilerTools.Loops.DomLoops   A type that holds information about which basic blocks dominate which other blocks.  CompilerTools.Loops.Loop   A type to hold information about a loop.", 
            "title": "Exported"
        }, 
        {
            "location": "/api-index/#internal_14", 
            "text": "compute_dom_loops(bl::CompilerTools.CFGs.CFG)   Find the loops in a CFGs.CFG in \"bl\".  findLoopInvariants(l::CompilerTools.Loops.Loop,  udinfo::Dict{CompilerTools.LivenessAnalysis.BasicBlock, CompilerTools.UDChains.UDInfo},  bl::CompilerTools.LivenessAnalysis.BlockLiveness)   Finds those computations within a loop that are iteration invariant.  findLoopMembers(head,  back_edge,  bbs)   Find all the members of the loop as specified by the \"head\" basic block and the \"back_edge\" basic block.  flm_internal(cur_bb,  members,  bbs)   Add to the \"members\" of the loop being accumulated given \"cur_bb\" which is known to be a member of the loop.  isInLoop(dl::CompilerTools.Loops.DomLoops,  bb::Int64)   Takes a DomLoops object containing loop information about the function.", 
            "title": "Internal"
        }, 
        {
            "location": "/api-index/#module-parallelaccelerator", 
            "text": "", 
            "title": "MODULE: ParallelAccelerator"
        }, 
        {
            "location": "/api-index/#internal_15", 
            "text": "init ()   Called when the package is loaded to do initialization.  embed()   This version of embed tries to use JULIA_HOME to find the root of the source distribution.  embed(julia_root)   Call this function if you want to embed binary-code of ParallelAccelerator into your Julia build to speed-up @acc compilation time.  getPackageRoot()   Generate a file path to the directory above the one containing this source file.  getPseMode()   Return internal mode number by looking up environment variable \"PROSPECT_MODE\".  getTaskMode()   Return internal mode number by looking up environment variable \"PROSPECT_TASK_MODE\".", 
            "title": "Internal"
        }
    ]
}